#
msgid ""
msgstr ""
"POT-Creation-Date: 2024-03-15 17:27:06.898174+00:00\n"
"PO-Revision-Date: 2024-03-15 17:31+0000\n"
"Last-Translator: Théo Chevalier <theochevalier@pm.me>\n"
"Language: es\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Generator: Pontoon\n"
"X-WagtailLocalize-TranslationID: 90eee2c9-663e-4029-8c07-18f0d064da93\n"

msgctxt "seo_title"
msgid "Accelerating Progress Toward Trustworthy AI"
msgstr "Acelerar los avances hacia una IA confiable"

msgctxt "search_description"
msgid "Status update on our 2020 paper “Creating Trustworthy AI” and next steps to promote openness, competition, and accountability in AI"
msgstr "Actualización de nuestro documento de 2020 \"Crear una IA digna de confianza\" y próximos pasos para promover la apertura, la competencia y la responsabilidad en la IA."

msgctxt "title"
msgid "Accelerating Progress Toward Trustworthy AI"
msgstr "Acelerar los avances hacia una IA confiable"

msgctxt "subtitle"
msgid "Status update on our 2020 paper “Creating Trustworthy AI” and next steps to promote openness, competition, and accountability in AI"
msgstr "Actualización de nuestro documento de 2020 \"Crear una IA digna de confianza\" y próximos pasos para promover la apertura, la competencia y la responsabilidad en la IA."

msgctxt "secondary_subtitle"
msgid "V.09 for Public Comment"
msgstr "V.09 abierto a comentarios del público"

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid "README"
msgstr "PREFACIO"

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid ""
"Mozilla’s work on AI is not new – we’ve been funding, building and advocating for trustworthy AI approaches for years. In 2020, we published a <a id=\"a1\">white paper</a> that outlined our vision "
"for trustworthy AI in a nascent moment for the technology. Since then, a lot has changed. Today, AI is increasingly powerful and pervasive in our society, and its promise and perils are becoming "
"even more apparent. While there are a growing number of individuals and organizations working on making AI more trustworthy, the scope of the challenge is also continuing to grow. And while we’ve "
"made progress on advancing guardrails for AI systems, the AI ecosystem has also become increasingly closed and concentrated."
msgstr ""
"El trabajo de Mozilla en IA no es nuevo: llevamos años financiando, construyendo y abogando por enfoques de IA confiables. En 2020, publicamos un <a id=\"a1\">documento técnico</a> que esbozaba "
"nuestra visión de la IA confiable en un momento incipiente para la tecnología. Desde entonces, muchas cosas han cambiado. Hoy en día, la IA es cada vez más poderosa y está cada vez más presente en "
"nuestra sociedad, y sus promesas y peligros son cada vez más evidentes. Aunque cada vez son más las personas y organizaciones que trabajan para que la IA sea más fiable, el alcance del reto también "
"sigue creciendo. Y, al haber avanzado en la creación de barreras para los sistemas de IA, el ecosistema de la IA también se ha vuelto cada vez más cerrado y concentrado."

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid ""
"Given the rapid changes in AI recently, we felt there was a need to take stock of the progress we’ve made so far and the work that is left to do. This new report provides an update on work to date "
"in the four strategic areas we outlined in our 2020 paper, and it maps key initiatives happening in these areas – both at Mozilla and across the ecosystem. Importantly, the paper also emphasizes our"
" evolving focus on the centrality of open source in the development of more trustworthy AI. We hope this report will be both a guidepost and map — helping readers to articulate their own strong "
"message on trustworthy AI, build and invest in a better future for AI, and find opportunities to collaborate with others in the AI ecosystem. In turn, we believe our collective work can set us on a "
"path to truly advance openness, competition, and accountability in AI."
msgstr ""
"Dada la rapidez con la que la IA ha cambiado recientemente, nos pareció necesario hacer un balance de los avances que hemos logrado hasta ahora y el trabajo que queda por hacer. Este nuevo reporte "
"proporciona una actualización sobre el trabajo realizado hasta la fecha en las cuatro áreas estratégicas que detallamos en nuestro documento de 2020, y mapea las iniciativas clave que están "
"ocurriendo en estas áreas, tanto en Mozilla como en todo el ecosistema. Pero principalmente, el documento también pone en relieve nuestro creciente interés por la importancia del código abierto en "
"el desarrollo de una IA más confiable. Esperamos que este reporte sea tanto una guía como un mapa, ayudando a los lectores a articular su propio mensaje contundente sobre una IA confiable, a "
"construir e invertir en un mejor futuro para la IA, y a encontrar oportunidades para colaborar con otros en el ecosistema de la IA. Por otra parte, creemos que nuestra labor colectiva puede "
"encaminarnos a fomentar verdaderamente la apertura, competencia y responsabilidad en la IA."

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid ""
"<b>We invite your input on the report and your feedback on the state of the AI ecosystem more broadly. Through your comments and a series of public events, we will take feedback from the AI "
"community and use it to strengthen our understanding and vision for the future of trustworthy AI. Please email us at</b> <a id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> to provide any input"
" on the report and/or to highlight your favorite examples of AI being used in ways that build trust and improve people’s lives.</b>"
msgstr ""
"<b>Te invitamos a comentar el informe en particular y el estado del ecosistema de la IA en general. Tus comentarios y una serie de eventos públicos nos servirán como retroalimentación de la "
"comunidad de IA que utilizaremos para fortalecer nuestra comprensión y visión del futuro de una IA confiable. Envíanos un correo electrónico a</b> <a "
"id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> para comentarnos el informe y/o darnos tus ejemplos favoritos de IA utilizada en formas que fomentan la confianza y mejoran la vida de las "
"personas.</b>"

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid "Executive Summary"
msgstr "Resumen ejecutivo"

msgctxt "body.496d8ea0-44ac-4dd4-8251-4b73da7f6ea3"
msgid "AI in our world today"
msgstr "La inteligencia artificial en el mundo de hoy"

msgctxt "body.496d8ea0-44ac-4dd4-8251-4b73da7f6ea3"
msgid ""
"We’re at an inflection point for AI, and for society at large. The technology is unlocking huge societal benefits, ranging from AI-powered drug discovery and climate solutions to productivity gains "
"for individuals and small businesses. While these benefits are profound, the harms from AI have also never been more pressing. We’re seeing AI being used in ways that make it easier to deceive and "
"harass people on social media, perpetuate bias in the criminal justice system, and extract sensitive information from people’s online activity."
msgstr ""
"Nos encontramos en un punto de inflexión para la IA y para la sociedad en general. La tecnología ha posibilitado enormes beneficios para la sociedad: desde soluciones mediante IA en la farmacología "
"y el cambio climático, hasta el aumento de la productividad de las personas y las pequeñas empresas. Aunque estos beneficios son enormes, los daños causados por la IA nunca habían sido tan "
"apremiantes. La IA se utiliza de forma que facilita el engaño y el acoso en las redes sociales, perpetúa los prejuicios en el sistema de justicia penal y extrae información sensible de la actividad "
"en línea de las personas."

msgctxt "body.e4db8bda-dcaf-497e-b5c4-9722b2a8d380"
msgid ""
"Today’s AI ecosystem is structurally flawed in ways that prevent us from realizing the full potential of AI, while also allowing AI harms to go unchecked. We know that many of AI’s innovations and "
"applications have been fueled by open source and open science; for example, Google’s influential <a id=\"a1\">transformer paper</a> and <a id=\"a2\">TensorFlow</a> framework were made widely "
"available, which supported many AI innovations across sectors. But now, many big tech companies are <a id=\"a3\">vilifying</a> open and competitive approaches to AI in favor of their own proprietary"
" AI models and lucrative cloud computing businesses. This is making it harder to compete in the AI ecosystem."
msgstr ""
"Las fallas estructurales del ecosistema de la IA nos impiden ver todo su potencial y, al mismo tiempo, permiten que los daños de la IA queden sin control. Sabemos que muchas de las innovaciones y "
"aplicaciones de la IA han sido impulsadas por el código abierto y la ciencia abierta; por ejemplo, el influyente <a id=\"a1\">documento transformer</a> de Google y el <a id=\"a2\">marco "
"TensorFlow</a> se hicieron ampliamente accesibles, lo que apoyó muchas innovaciones de IA en todos los sectores. Sin embargo, ahora, muchas de las grandes tecnológicas <a id=\"a3\">denigran</a> los "
"enfoques abiertos y competitivos de la IA en favor de sus propios modelos de IA patentados y sus negocios lucrativos de informática en la nube. Esto dificulta la competencia en el ecosistema de la "
"IA."

msgctxt "body.e4db8bda-dcaf-497e-b5c4-9722b2a8d380"
msgid ""
"We know from other industries that competition is vital for spurring research and development, creating cheaper and safer products, and invigorating investment and job creation. A lack of openness "
"and competition also <a id=\"a1\">makes it harder</a> to promote accountability in AI, as it reduces independent research and collaboration, inhibits scrutiny from the public and regulators, and "
"increases market barriers for new players focused on creating responsible AI."
msgstr ""
"Sabemos por otros sectores que la competencia es crucial para impulsar la investigación y el desarrollo, crear productos más económicos y seguros, así como estimular la inversión y la creación de "
"empleos. De igual forma, la falta de apertura y de competencia <a id=\"a1\">dificulta</a> promover la responsabilidad en la IA porque reduce la investigación y cooperación independientes, inhibe el "
"escrutinio de ciudadanos y autoridades normativas e incrementa las barreras del mercado a los nuevos participantes centrados en crear una IA responsable."

msgctxt "body.e4db8bda-dcaf-497e-b5c4-9722b2a8d380"
msgid ""
"In a world where AI is touching every sector and facet of society, we need structural changes that tackle the root causes of today’s AI harms and unlock the positive benefits of AI. <b>That’s how we"
" get to trustworthy AI: tech that is built and deployed in ways that support accountability and agency, and advance individual and collective well-being.</b>"
msgstr ""
"En un mundo en el que la IA toca cada sector y faceta de la sociedad, necesitamos cambios estructurales que aborden las causas de fondo tras los perjuicios actuales ocasionados por la IA y den paso "
"a sus beneficios positivos. <b>Así podremos llegar a una IA confiable: con una tecnología que se construya y despliegue de forma que favorezca la responsabilidad y la agencia, y promueva el "
"bienestar individual y colectivo.</b>"

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid "A familiar story for Mozilla"
msgstr "Una historia conocida para Mozilla"

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"At Mozilla, we’re deeply familiar with this situation. At the dawn of the commercial internet in the late 1990s, Microsoft was on the brink of monopolizing the market for web browsers, threatening "
"to lock in users, stamp out competitors, and stifle innovation online. The internet was poised to transform society, but access to the internet was increasingly being controlled by one entity. In "
"response, Mozilla created the open source Firefox browser that added much-needed competition in the marketplace, raising the standard for privacy, security, and functionality across the industry. In"
" the 25 years since, we have continued fighting the power of big tech on the internet through our products, investments, and advocacy."
msgstr ""
"En Mozilla, estamos muy familiarizados con esta situación. En los albores de la internet comercial, a finales de la década de 1990, Microsoft estuvo a punto de monopolizar el mercado de los "
"navegadores web, amenazando con bloquear a los usuarios, acabar con los competidores y frenar la innovación en línea. Internet estaba a punto de transformar la sociedad, pero el acceso a la red "
"estaba cada vez más controlado por una entidad. En respuesta, Mozilla creó el navegador Firefox de código abierto, que añadió la competencia tan necesaria en el mercado, elevando el estándar de "
"privacidad, seguridad y funcionalidad en toda la industria. En los 25 años desde entonces hemos seguido combatiendo el poder de las grandes tecnológicas sobre el Internet a través de nuestros "
"productos, inversiones y activismo."

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"That’s why we were concerned when we saw a similar pattern emerging in the AI ecosystem over the last decade. In 2020, we articulated a <a id=\"a1\">vision</a> for trustworthy AI that highlighted "
"many of the issues we saw with the AI ecosystem. We outlined four levers that we could pull to achieve trustworthy AI at scale, and mobilized the Mozilla community toward pulling these levers."
msgstr ""
"Por eso nos preocupamos al ver surgir un patrón similar en el ecosistema de la IA durante la última década. En 2020, expusimos una <a id=\"a1\">visión</a> de una IA confiable que puso de relieve "
"muchos de los problemas que observamos en el ecosistema de la IA. Describimos cuatro vías que podríamos seguir para lograr una IA confiable a gran escala y movilizamos a la comunidad de Mozilla para"
" que las utilizaran."

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"Since then, Mozilla has been actively <a id=\"a1\">building</a>, <a id=\"a2\">investing</a>, and advocating to push even further down this path. We’re investing in <a id=\"a3\">new technology and "
"new products</a> to demonstrate trustworthy AI principles in action, offering consumers more choice and control. We’re <a id=\"a4\">educating policymakers</a> around the world on the existing risks "
"and benefits of AI to shape smarter regulations and fairer market dynamics. We’re continuing to rally like-minded <a id=\"a5\">builders</a>, <a id=\"a6\">researchers</a> and <a "
"id=\"a7\">activists</a> to drive consensus around responsible AI development and fund initiatives to make AI more trustworthy. We’re helping consumers be more critical in choosing AI products, and "
"encouraging lawmakers to prioritize openness and accountability in AI policy."
msgstr ""
"Desde entonces, Mozilla ha estado activamente <a id=\"a1\">construyendo</a>, <a id=\"a2\">invirtiendo</a> y abogando por avanzar aún más en este camino. Estamos invirtiendo en <a id=\"a3\">nueva "
"tecnología y nuevos productos</a> para demostrar los principios de la IA confiable en acción, ofreciendo a los consumidores más opciones y control. <a id=\"a4\">Sensibilizamos a formuladores de "
"políticas</a> en todo el mundo sobre los riesgos y beneficios actuales de la IA para conformar reglamentos más inteligentes y propiciar dinámicas de mercado más justas. Continuamos convocando a <a "
"id=\"a5\">constructores</a>, <a id=\"a6\">investigadores</a> y <a id=\"a7\">activistas</a> con mentalidad similar para consensuar el desarrollo responsable de la IA y financiar iniciativas que la "
"hagan más confiable. Ayudamos a los consumidores a analizar con más cuidado los productos de IA de su elección y exhortamos a los legisladores a priorizar la apertura y la responsabilidad en las "
"políticas públicas sobre IA."

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid "Progress and next steps towards trustworthy AI"
msgstr "Avances y próximos pasos hacia una IA confiable"

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"In our original paper, we proposed four key levers for advancing the development of more trustworthy AI: <b>(1) changing AI development norms, (2) building new tech and products, (3) raising "
"consumer awareness, and (4) strengthening AI regulations and incentives.</b> This report outlines where we’ve made the most positive progress within each lever, and where there is still more work to"
" be done."
msgstr ""
"En nuestro documento original de análisis, propusimos cuatro vías clave para fomentar el desarrollo de una IA más confiable: <b>(1) cambiar las normas de desarrollo de la IA, (2) desarrollar nueva "
"tecnología y nuevos productos, (3) sensibilizar a los consumidores y (4) fortalecer la normatividad y los incentivos de la IA.</b> Este informe describe en dónde hemos logrado los avances más "
"positivos y en dónde aún queda trabajo por hacer."

msgctxt "body.76c2a00d-60ee-4758-9bcc-1a4239059134"
msgid "Key Takeaways"
msgstr "Conclusiones clave"

msgctxt "body.c4140282-e86a-4dc1-bc43-bfb76361892b.altText"
msgid "01 Norms"
msgstr "01 Normas"

msgctxt "body.c4140282-e86a-4dc1-bc43-bfb76361892b.text"
msgid ""
"<b>The people that broke the internet are the ones building AI.</b> Big tech companies and the AI startups they back currently dominate AI. They have created opaque, centralized AI models using our "
"harvested data. Luckily, there is a growing wave of startups, builders, educators, scholars, researchers, and civil society leaders focused on shifting these norms, with a focus on building open, "
"transparent, and trustworthy AI."
msgstr ""
"<b>Las personas que quebraron Internet son las que ahora construyen la IA.</b> Actualmente, las grandes tecnológicas y las empresas emergentes de IA a las que apoyan dominan la inteligencia "
"artificial. Han creado modelos opacos y centralizados de IA utilizando los datos que recopilan sobre nosotros. Por suerte, una creciente ola de empresas emergentes, constructores, docentes, "
"académicos, investigadores y líderes de la sociedad civil se enfocan en cambiar estas normas y, en particular, en construir una IA abierta, transparente y confiable."

msgctxt "body.729fb516-9869-449c-bb00-ad44762daaf6.altText"
msgid "02 Products"
msgstr "02 Productos"

msgctxt "body.729fb516-9869-449c-bb00-ad44762daaf6.text"
msgid ""
"<b>More trustworthy AI products need to be mainstream.</b> Over the last 18 months, black box generative AI tools have entered the mainstream of business and public consciousness. At the same time, "
"dozens of startups and research projects have sprung up to build open source models, auditing tools, and data platforms that offer a different path. While not yet mainstream, these are the seeds of "
"a better AI ecosystem."
msgstr ""
"<b>Deben popularizarse más productos de IA confiable.</b>  A lo largo de los últimos 18 meses, las herramientas de IA generativa de caja negra han entrado de lleno en la conciencia empresarial y "
"pública. Al mismo tiempo, decenas de startups y proyectos de investigación han surgido para construir modelos de código abierto, herramientas de auditoría y plataformas de datos que ofrecen un "
"camino diferente. Todavía no constituyen la corriente principal, pero ya son las semillas de un mejor ecosistema de IA."

msgctxt "body.3e5af0ff-07db-4b57-b5af-a4f6f0bafe10.altText"
msgid "03 Consumers"
msgstr "03 Consumidores"

msgctxt "body.3e5af0ff-07db-4b57-b5af-a4f6f0bafe10.text"
msgid ""
"<b>A more engaged public still needs better choices on AI.</b> Consumers are starting to pay attention to AI’s impact on their lives. Workers — from delivery drivers to Hollywood writers — are "
"pushing back on how AI affects their livelihoods. However, we have not yet seen a wave of mainstream consumer products that give people real choice over how they interact with AI. This is a key gap "
"in the market."
msgstr ""
"<b>Un público más involucrado aún requiere mejores opciones de IA.</b> Los consumidores empiezan fijarse en el impacto de la IA en sus vidas. Los trabajadores —desde repartidores hasta los "
"guionistas de Hollywood— rechazan la manera como la IA afecta su medio de subsistencia. Falta por ver aún una ola de productos de consumo generalizado que brinden a las personas opciones reales "
"sobre cómo interactuar con la IA. Esto constituye una brecha fundamental en el mercado."

msgctxt "body.b73d022a-7809-475f-8959-2618a4bb46fb.altText"
msgid "04 Policy"
msgstr "04 Políticas"

msgctxt "body.b73d022a-7809-475f-8959-2618a4bb46fb.text"
msgid ""
"<b>Governments are making progress while grappling with conflicting influences.</b> As policymakers move to regulate AI, they are confronted by conflicting messages, especially from industry. Don’t "
"regulate, says one camp. Limit control over cutting-edge AI to a few companies, says another. Some regulators are taking a third way, listening to less-prominent voices in industry, academia, and "
"civil society arguing for a balanced approach."
msgstr ""
"<b>Los gobiernos logran avances al tiempo que se enfrentan con influencias contradictorias.</b> Conforme los formuladores de políticas empiezan a reglamentar la IA, se enfrentan a mensajes "
"contradictorios, especialmente de la industria. No reglamenten, afirma un bando. Limiten el control sobre la IA de punta a unas cuantas empresas, afirma otro bando. Algunas autoridades normativas "
"adoptan una tercera postura: escuchar a las voces menos prominentes del sector, de la comunidad académica y de la sociedad civil que piden un enfoque equilibrado."

msgctxt "body.30ae2ffe-8970-4672-af7d-1d5170f8acd0"
msgid ""
"This report shows that we’ve made meaningful progress since 2020, and that there is still much more work to be done. It’s time to redouble our efforts and recommit to our core principles, and this "
"report describes how. It outlines Mozilla’s ongoing work to shift the narrative on AI, make open source generative AI more trustworthy and mainstream, and empower consumers with real choices on AI. "
"It highlights how we’ll continue investing in the trustworthy and open source AI ecosystem, and help lawmakers develop and roll out pragmatic AI regulation. And, it calls on builders, consumers, "
"policymakers, advocates, and investors alike to leverage their respective positions to push the AI ecosystem in a better direction."
msgstr ""
"Este informe muestra que hemos logrado avances significativos desde 2020 y que aún hay mucho más trabajo por hacer. Es hora de redoblar nuestros esfuerzos y volver a comprometernos con nuestros "
"principios básicos, y este informe describe cómo hacerlo. Describe el trabajo continuo de Mozilla para cambiar la narrativa sobre la IA, hacer que la IA generativa de código abierto sea más "
"confiable y generalizada, además de empoderar a los consumidores con opciones reales sobre la IA. Destaca cómo seguiremos invirtiendo en el ecosistema de la IA confiable y de código abierto, y cómo "
"ayudaremos a los legisladores a desarrollar y poner en marcha una regulación pragmática de la IA. También insta a constructores, consumidores, formuladores de políticas, defensores e inversionistas "
"por igual a aprovechar sus respectivas posturas para llevar al ecosistema de IA en una mejor dirección."

msgctxt "body.30ae2ffe-8970-4672-af7d-1d5170f8acd0"
msgid "It will take all of us, working together, to turn this vision into reality. There’s no time to waste — let’s get to work."
msgstr "Será necesario que todos trabajemos juntos para hacer realidad esta visión. No hay tiempo que perder; pongamos manos a la obra."

msgctxt "body.650d1286-d5ad-4887-8fdc-c9546d465133.quote"
msgid "In a world where AI is touching every sector and facet of society, we need<b> structural changes</b> that tackle the root causes of today’s AI harms and unlock the positive benefits of AI."
msgstr ""
"En un mundo en el que la IA toca cada sector y faceta de la sociedad, necesitamos <b>cambios estructurales</b> que aborden las causas de fondo tras los perjuicios actuales ocasionados por la IA y "
"que den paso a sus beneficios positivos."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid "Introduction: AI Challenges, Risks, &amp; Opportunities"
msgstr "Introducción: Retos, riesgos y oportunidades de la IA"

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid "Heightened public attention on AI"
msgstr "Mayor atención ciudadana a la IA"

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"Investments and advancements in AI have been ongoing for decades, but the technology’s transformational benefits and potential for long-lasting harm have exploded in the last three years. The "
"release of generative AI systems based on large language models (LLMs) like ChatGPT, Bard, and Stable Diffusion have captured the public’s imagination, allowing everyday people to interact with AI "
"systems using natural language for the first time. Widespread consumer awareness has sparked an <a id=\"a1\">AI gold rush</a> for big tech, entrepreneurs, and investors, with new players and big "
"tech incumbents battling to dominate the fast-growing market. At the same time, more people are calling out how AI models can be abused, biased, opaque, and harmful at scale. The <a id=\"a2\">media "
"has struggled</a> to discern AI hype from reality. The public has <a id=\"a3\">mixed feelings</a> about AI, with some fearing for their jobs. Artists have <a id=\"a4\">sued over alleged copyright "
"infringement</a> in AI training data. And activists, academics, and technologists are having intense debates over which AI dangers need to be addressed first, and which <a id=\"a5\">AI development "
"approaches</a> are the safest."
msgstr ""
"Las inversiones y los avances en la IA llevan décadas produciéndose, pero los beneficios transformadores de la tecnología y su potencial para causar daños duraderos se han disparado en los últimos "
"tres años. El lanzamiento de sistemas de IA generativa basados en grandes modelos de lenguaje (LLM) como ChatGPT, Bard y Stable Diffusion ha cautivado la imaginación del público, permitiendo por "
"primera vez que las personas comunes interactúen con sistemas de IA utilizando un lenguaje natural. La sensibilización generalizada de los consumidores ha desatado una <a id=\"a1\">fiebre del oro de"
" IA</a> para las grandes tecnológicas, los empresarios y los inversionistas, con nuevos actores y grandes tecnológicas luchando por dominar un mercado en rápido crecimiento. Al mismo tiempo, cada "
"vez más personas denuncian cómo los modelos de IA pueden ser abusivos, sesgados, opacos y perjudiciales a gran escala. Los <a id=\"a2\">medios han luchado</a> por discernir entre la expectativa y la"
" realidad de la IA. La opinión pública tiene <a id=\"a3\">sentimientos encontrados</a> acerca de la IA, y algunos temen por sus trabajos. Los artistas han <a id=\"a4\">demandado por supuesta "
"infracción de derechos de autor</a> en los datos de entrenamiento de IA. Asimismo, los activistas, académicos y expertos en tecnología sostienen intensos debates sobre qué peligros de la IA deben "
"abordarse primero y cuáles <a id=\"a5\">enfoques de desarrollo de IA</a> son los más seguros."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"<b>Heightened awareness of AI risks is a good thing.</b> Without a well-informed public pushing for more transparency and accountability, large tech companies will use AI to pursue profit over all "
"else, which harms people by further consolidating their market power. If they do, we could miss our chance to shape an AI landscape that benefits people everywhere, and not just increases profit "
"margins for Silicon Valley players."
msgstr ""
"<b>La creciente sensibilización sobre los riesgos de la IA es algo positivo.</b> Sin un público bien informado que presione por una mayor transparencia y rendición de cuentas, las grandes empresas "
"de tecnología utilizarán la IA para priorizar las ganancias por encima de todo, lo que perjudicará a las personas al consolidar aún más su poder de mercado. Si se salen con la suya, podríamos perder"
" la oportunidad de conformar un universo de IA que beneficie a las personas de todo el mundo y no solamente llenar los bolsillos de la meca en Silicon Valley."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"Much of the debate about the future of AI has focused on two positions: unbridled optimism and existential fear. One side argues that virtually all AI, and all technologies, are universally good, "
"and should not be “restricted” by regulation or other risk mitigation approaches. The other side argues that AI poses an existential threat to humanity, and must be constrained in ways that can both"
" limit current AI benefits and exacerbate existing AI risks."
msgstr ""
"Gran parte del debate acerca del futuro de la IA se ha centrado en dos posturas: optimismo desenfrenado y miedo existencial. Un bando sostiene que prácticamente toda la IA y todas las tecnologías "
"son universalmente buenas y no deben “restringirse” mediante reglamentos u otros medios para mitigar el riesgo. El otro bando afirma que la IA supone una amenaza existencial para la humanidad y debe"
" restringirse en formas que puedan tanto limitar sus beneficios actuales como exacerbar sus riesgos existentes."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"However, there is a third school of thought that offers a more nuanced, practical perspective on the risks and benefits of AI. At Mozilla, we fall into the camp of <a id=\"a1\">AI realists</a>, who "
"are cautiously optimistic about AI’s positive potential and dedicated to solving present day harms like AI bias, discrimination, and job loss. This camp is not new. Many individuals and civil "
"society organizations have been promoting this perspective for years. Alongside the broader open source community, and other <a id=\"a2\">foundations</a>, <a id=\"a3\">think tanks</a>, <a "
"id=\"a4\">researchers</a>, and <a id=\"a5\">activists</a>, we believe that addressing AI’s problems today with openness and transparency will serve the greater good for society and the economy while"
" mitigating both everyday and catastrophic risks."
msgstr ""
"Sin embargo, existe una tercera corriente de opinión que ofrece una perspectiva más matizada y práctica de los riesgos y beneficios de la IA. En Mozilla, pertenecemos al bando de los <a "
"id=\"a1\">realistas de la IA</a>, cautelosamente optimistas acerca del potencial positivo de la IA y dedicados a resolver los daños actuales de la IA, como el sesgo, la discriminación y la pérdida "
"de empleos. Este bando no es nuevo. Muchas personas y organizaciones de la sociedad civil han promovido esta perspectiva durante años. Tal como la comunidad más amplia de código abierto y otras <a "
"id=\"a2\">fundaciones</a>, <a id=\"a3\">grupos de expertos</a>, <a id=\"a4\">investigadores</a> y <a id=\"a5\">activistas</a>, consideramos que abordar hoy mismo los problemas de la IA con apertura "
"y transparencia servirá al bien común de la sociedad y la economía, y mitigará los riesgos tanto cotidianos como catastróficos."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid "To inform our collective next steps, we lay out the five core challenges that we see in today's AI landscape:"
msgstr "Con el fin de dar forma a nuestros siguientes pasos como colectividad, planteamos los cinco retos principales que observamos en el panorama actual de la IA:"

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Many people got the AI story all wrong.</b> Over the past year, the story of AI pitching a battle between the <a id=\"a1\">optimists</a> and the <a id=\"a2\">doomers</a> sucked attention away "
"from more pragmatic and thoughtful approaches to AI. Out of the media limelight, AI realists were rolling up their sleeves to unlock the huge benefits of AI while also tackling tough questions about"
" social ills and closed markets. This can — and should — be the story we’re all focused on."
msgstr ""
"<b>Muchas personas malinterpretaron la historia de la IA.</b> Durante el último año, la historia de la IA en lucha entre los <a id=\"a1\">optimistas</a> y los <a id=\"a2\">fatalistas</a> desvió la "
"atención de los enfoques más pragmáticos y reflexivos de la IA. Lejos de los reflectores, los realistas de la IA ponían manos a la obra para aprovechar los enormes beneficios de la IA y encarar "
"cuestiones espinosas relacionadas con los problemas sociales y los mercados cerrados. Esta puede ser —y debería ser— la historia en la que todos nos enfoquemos."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Big tech and closed models are dominating the field.</b> The increasing capabilities and adoption of AI have made it even more important to enable competition and market access, independent "
"research and public scrutiny of AI systems, and more room for new players to build trustworthy AI products. Over the past few years, the AI ecosystem took a radical swing in the direction of closed "
"technology — leading AI companies stopped publishing papers and started selling access to APIs. At the same time, big tech invested heavily in players like OpenAI and Anthropic as a way to control "
"the field and bolster their own cloud computing businesses. This is making it harder to advance the open approaches that are vital to creating a better AI ecosystem for everyone."
msgstr ""
"<b>Las grandes tecnológicas y los modelos cerrados dominan el campo.</b> Dadas las capacidades crecientes y mayor utilización de la IA, ahora resulta fundamental habilitar la competencia y el acceso"
" al mercado, la investigación independiente y el escrutinio público de los sistemas de IA, así como un mayor margen para que los nuevos participantes creen productos de IA confiables. En años "
"recientes, el ecosistema de la IA dio un giro radical hacia la tecnología cerrada: las empresas líderes de IA dejaron de publicar documentos de análisis y empezaron a vender el acceso a las "
"interfaces de programación de aplicaciones (API). Al mismo tiempo, las grandes tecnológicas han invertido copiosamente en participantes como OpenAI y Anthropic como una forma de controlar el campo "
"de juego y fortalecer sus propios negocios de informática en la nube.  Lo anterior está obstaculizando los enfoques abiertos que son fundamentales para crear un mejor ecosistema de IA para todos."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Open source generative AI hasn’t hit the mainstream.</b> Over the last year, a huge wave of open source generative AI models was released — from Llama to Falcon to Mistral. While these new models"
" are gaining steam and offer huge promise, there is still a long way to go before they are easy to use and <a id=\"a1\">easy to trust</a>. Open source generative AI won’t hit the mainstream until we"
" tackle these issues."
msgstr ""
"<b>La IA generativa de código abierto no ha llegado a la corriente principal.</b> Durante el último año, se lanzó una enorme ola de modelos de IA generativa de código abierto, desde Llama hasta "
"Falcon y Mistral. Si bien estos nuevos modelos están ganando popularidad y ofrecen una gran promesa, todavía queda un largo camino por recorrer antes de que sean fáciles de usar y <a "
"id=\"a1\">fáciles de confiar</a>. La IA generativa de código abierto no se generalizará hasta que abordemos estas cuestiones."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>There are still foundational issues in AI development.</b> The root cause of many AI harms can be traced to foundational aspects of the AI ecosystem, including the population that’s building AI "
"and the ways they’re collecting and labeling data. For example, because most LLM training datasets are built using widely-available data from across the web, the systems <a id=\"a1\">reproduce "
"biases and stereotypes</a> that cause real-world harm. The tech industry also still lacks diversity, which means valuable perspectives are left out of AI development, preventing these models from "
"reflecting the breadth and depth of the human experience."
msgstr ""
"<b>Todavía hay problemas fundamentales en el desarrollo de la IA.</b> La causa principal de muchos de los daños de la IA se puede rastrear hasta los aspectos fundamentales del ecosistema de la IA, "
"incluyendo la población que está construyendo la IA y las formas en que están recopilando y etiquetando los datos. Por ejemplo, debido a que la mayoría de los conjuntos de datos de entrenamiento de "
"LLM se construyen utilizando datos ampliamente disponibles en la web, los sistemas <a id=\"a1\">reproducen sesgos y estereotipos</a> que causan daño en el mundo real. Además, el sector tecnológico "
"aún carece de diversidad, es decir, perspectivas valiosas quedan fuera del desarrollo de la IA, lo que impide que dichos modelos reflejen toda la variedad de experiencias humanas."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Policymakers are moving, but the tech and harms are moving faster.</b> In 2023, progress on the European Union AI Act and the release of the U.S.’ Executive Order on Safe, Secure, and Trustworthy"
" AI have shown that policymakers understand the urgency of firmer political action on AI. However, the rapid growth of AI and its associated harms are moving much faster than the development and "
"rollout of new regulations. In the meantime, companies like OpenAI, Meta and Google are having <a id=\"a1\">meaningful impacts on the economy</a> just one year after ChatGPT’s release."
msgstr ""
"<b>Los formuladores de políticas avanzan, pero la tecnología y los perjuicios avanzan más rápido.</b> En 2023, los avances en la Ley de Inteligencia Artificial de la Unión Europea y el lanzamiento "
"de la Orden Ejecutiva de los Estados Unidos sobre la IA segura, segura y confiable, han demostrado que los legisladores comprenden la urgencia de tomar medidas políticas más firmes en relación con "
"la IA. Sin embargo, el rápido crecimiento de la IA y sus daños asociados avanzan mucho más rápido que el desarrollo y la implementación de nuevas regulaciones. Mientras tanto, empresas como OpenAI, "
"Meta y Google repercuten <a id=\"a1\">enormemente en la economía</a> a tan solo un año del lanzamiento de ChatGPT."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"This watershed moment in technology history is the best opportunity for the AI realists to influence the direction of the industry, driving us toward a better technological future for all. Building "
"trustworthy AI is both urgent and complicated, and no one person or organization can tackle all of these risks alone. That’s why we emphasized the need for collaboration across the entire ecosystem "
"in our original 2020 <a id=\"a1\"><i>Creating Trustworthy AI</i></a> paper, and why we’re working alongside others on the products, research, and policy needed to advance trustworthy AI."
msgstr ""
"Este hito en la historia de la tecnología es la mejor oportunidad para que los realistas de la IA influyan en el rumbo del sector y nos conduzcan hacia un mejor futuro tecnológico para todos. "
"Construir una IA confiable es una tarea urgente y complicada, y los riesgos que ello implica resultan imposibles de abordar para una persona o empresa por su cuenta. Por eso, en nuestro documento "
"original de análisis de 2020 <a id=\"a1\"><i>Creación de una IA confiable</i></a>, hicimos énfasis en que se requiere de la cooperación de todo el ecosistema, y por eso estamos trabajando en "
"colaboración con otros en los productos, la investigación y las políticas públicas que se necesitan para una IA confiable."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid "Advancing openness and competition"
msgstr "Fomentar la apertura y la competencia"

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"In our 2020 <a id=\"a1\">paper</a>, published well before the conversation about AI reached its current fever pitch, our team at Mozilla outlined the importance of creating AI that people can trust,"
" with agency and accountability at the center. Agency allows users to regain control over their internet experiences, with a focus on privacy, transparency, and well-being. Accountability means "
"companies are held to account when their AI systems cause harm through discriminatory outcomes, abuse of data, or unsafe practices."
msgstr ""
"En nuestro <a id=\"a1\">documento de análisis</a> de 2020, publicado mucho antes de la IA estuviera en boca de todos como ahora, nuestro equipo en Mozilla destacó la importancia de desarrollar "
"inteligencia artificial de confianza, partiendo de la acción y la responsabilidad como aspectos centrales. Mediante la acción, los usuarios recuperan el control de sus experiencias en internet "
"partiendo de la base de la privacidad, la transparencia y el bienestar. La responsabilidad significa que las empresas deben rendir cuentas cuando sus sistemas de IA causen perjuicio a través de "
"resultados discriminatorios, abuso de datos o prácticas inseguras."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"Since then, we have come to believe that open source approaches and broad market access are key ingredients for promoting agency and accountability in the AI era. We’ve noticed that AI is "
"increasingly being built in a closed ecosystem by the same companies that have already damaged both the internet and society over the last 20 years. Many of AI’s most exciting innovations flow from "
"open source and open science, but researchers are increasingly moving away from open publishing as their corporate funders prioritize selling access to cloud services. These same companies are now "
"vilifying open source approaches to AI in favor of their own proprietary models. Newer players have entered the market with financial backing from the big tech incumbents, and are <a "
"id=\"a1\">advocating for limitations</a> on who can access or build the most powerful AI systems, citing potential security risks as a part of their critique of open source AI. However, closed "
"models can also be abused by bad actors and deployed by ill-equipped developers, and openness is actually a key ingredient towards safety, security, and accountability. <b>We cannot accept that a "
"black box approach, kept in the hands of just a few companies, is the only safe and sensible path forward.</b>"
msgstr ""
"Desde entonces, creemos que el código abierto y el amplio acceso al mercado son ingredientes imprescindibles para promover la acción y la responsabilidad en la era de la inteligencia artificial. "
"Hemos notado que las empresas que tanto han dañado al Internet y a la sociedad durante los últimos 20 años son las mismas que están desarrollando IA de ecosistema cerrado predominantemente. Muchas "
"de las innovaciones más increíbles de la IA surgen del código abierto y de la ciencia abierta. Sin embargo, los investigadores realizan cada vez menos publicación de acceso libre porque las empresas"
" que los financian le dan prioridad a la venta del acceso a servicios en la nube. Esas mismas empresas ahora desacreditan los métodos de código abierto para la IA en favor de sus propios modelos "
"exclusivos. Los nuevos participantes del mercado con financiamiento de las grandes tecnológicas ya consolidadas <a id=\"a1\">abogan por limitar</a> quién puede construir o tener acceso a los "
"sistemas más poderosos de IA y mencionan los posibles riesgos de seguridad cuando critican la IA de código abierto. Olvidan que los actores malintencionados pueden abusar también de los modelos "
"cerrados o estos pueden ser implementados por desarrolladores mal equipados. De hecho, la apertura es un ingrediente clave para lograr seguridad y responsabilidad. <b>No podemos aceptar que un "
"enfoque de caja negra, en manos de unas cuantas empresas, sea el único camino seguro y lógico a seguir.</b>"

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"While open source alone will not cure all of AI’s problems, when done responsibly, it can foster an environment of innovation, transparency, and community building. Coupled with competitive markets,"
" it can help ensure advancements in AI are accessible to all, contributing to the collective knowledge base and allowing diverse perspectives to shape and govern the technology. That’s why we’re "
"funding, building, and collaborating with partners who are working to make open source AI trustworthy, commercially successful, and useful for humans everywhere. We have a deep history of leveraging"
" open source for societal benefit, and we're working to do it again for AI."
msgstr ""
"El código abierto por sí mismo no resolverá todos los problemas de la IA, pero puede favorecer un entorno de innovación, transparencia y desarrollo de comunidad si se utiliza de manera responsable. "
"También, en combinación con mercados competitivos, puede ayudar a asegurar que los avances en IA sean accesibles para todos porque contribuiría a la base de conocimientos colectivos y posibilitaría "
"diversas perspectivas para conformar y reglamentar dicha tecnología. Por eso fondeamos, construimos y colaboramos con socios que trabajan en favor de una IA de código abierto confiable, "
"comercialmente exitosa y útil para los humanos de todo el mundo. Llevamos mucho tiempo aprovechando el código abierto en beneficio de la sociedad y queremos lograr lo mismo para la IA."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"As this report will show, both Mozilla and the broader ecosystem are making meaningful progress toward trustworthy AI, but more work remains. We know we can't turn the tide alone, which is why this "
"report — and all our work — is about creating a global community committed to trustworthy AI. That’s how we build a better future."
msgstr ""
"En este informe mostraremos que tanto Mozilla como el ecosistema en general avanzan con paso firme hacia una IA confiable, pero aún queda trabajo por hacer. Sabemos que solos no podremos cambiar el "
"rumbo. Por ello, este informe —y todo nuestro trabajo— tiene que ver con crear una comunidad mundial comprometida con una IA confiable. Así es como construimos un futuro mejor."

msgctxt "body.fa708b45-ebb6-4185-a351-0542081285d7.quote"
msgid "We have come to believe that open source approaches and broad market access are key ingredients for promoting <b>agency and accountability</b> in the AI era."
msgstr "Creemos que el código abierto y el amplio acceso al mercado son ingredientes imprescindibles para promover <b>la acción y la responsabilidad</b> en la era de la inteligencia artificial."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid "Changing AI Development Norms"
msgstr "Cambiar las normas de desarrollo de la IA"

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"In our 2020 paper, we called for a shift in the tech industry’s norms and guidelines around how AI is built. We highlighted the need for more diversity among the stakeholders involved in designing "
"AI as a key condition of trustworthiness. Today, we’re seeing the impact of that lack of diversity come through both in the datasets used to train LLMs, and in who gets to set AI development norms."
msgstr ""
"En nuestro documento de análisis de 2020, instamos a un cambio en las normas y lineamientos del sector tecnológico con respecto a la manera de construir la IA. Pusimos de relieve la necesidad de una"
" mayor diversidad de participantes en el diseño de la IA como condición imprescindible para la confiabilidad. Hoy, estamos viendo el impacto de esa falta de diversidad tanto en los conjuntos de "
"datos utilizados para entrenar los LLM, como en quién establece las normas de desarrollo de la IA."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"AI models are trained on reams of data from across the internet, but because the internet is not universally accessible, the data we use is inherently incomplete. As a result, LLM outputs are "
"limited by the languages and content that are most prevalent online, including hate speech and other harmful posts from the dark corners of the web."
msgstr ""
"Los modelos de IA se entrenan utilizando grandes cantidades de datos de todo el internet, pero ya que este no es accesible para todos, los datos que usamos son de por sí incompletos. En "
"consecuencia, los resultados de los LLM están limitados por los lenguajes y contenidos que prevalecen más en línea, incluidos el discurso de odio y otras publicaciones perjudiciales de los rincones "
"más recónditos de la red."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"Additionally, if only a small group of people in Silicon Valley are building AI and developing the trust and safety practices that will shape the industry’s future, AI products will lack the nuance "
"of other cultural perspectives and lived experiences. That has real consequences for people and communities historically shut out of tech, who will feel the impact as AI use spreads."
msgstr ""
"Además, si solo un pequeño grupo de personas de Silicon Valley construye IA y desarrolla las prácticas de confianza y seguridad que configurarán el futuro de la industria, los productos de IA "
"carecerán de los matices de otras perspectivas culturales y experiencias vividas. Esto tiene consecuencias reales para las personas y comunidades históricamente excluidas de la tecnología, que se "
"sentirán el impacto a medida que se extienda el uso de la IA."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid "Positive Progress"
msgstr "Avances positivos"

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"Though the tech industry is still overwhelmingly white and male, women and people from underrepresented communities have spent the last three years pushing to influence the trajectory of AI "
"development."
msgstr ""
"Aunque el sector tecnológico aún es en su mayoría abrumadoramente blanco y masculino, las mujeres y las personas de comunidades subrepresentadas han pasado los últimos tres años ejerciendo presión "
"para influir en la trayectoria del desarrollo de la IA."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"One example is the work of <a id=\"a1\">Dr. Timnit Gebru</a>, who was fired from her role as a co-lead of Google’s Ethical AI team in 2020 for <a id=\"a2\">raising concerns about bias</a> in an "
"early LLM version. She has since become an advocate for diversity in tech, speaking out about the centralized market power of large corporations building AI systems that impact the entire world. A "
"year after her firing, she founded the <a id=\"a3\">Distributed Artificial Intelligence Research Institute (DAIR)</a>, “a space for independent, community-rooted AI research, free from big tech’s "
"pervasive influence.” Since its inception, DAIR has focused on elevating the voice of marginalized people in <a id=\"a4\">research</a> on the harms associated with AI technology. The organization "
"also focuses on building community to accelerate the creation of technologies for a better future."
msgstr ""
"Un ejemplo de esto es la labor de la <a id=\"a1\">Dra. Timnit Gebru</a>, a quien despidieron de su cargo de codirectora del equipo de IA ética de Google en 2020 por <a id=\"a2\">expresar sus "
"inquietudes sobre el sesgo</a> en una primera versión del LLM. Desde entonces, es una defensora de la diversidad en la tecnología y se pronuncia respecto al poder de mercado centralizado de las "
"grandes empresas que construyen sistemas de IA con repercusiones en todo el mundo. Un año después de que la despidieran, fundó el <a id=\"a3\">Distributed Artificial Intelligence Research Institute "
"(DAIR)</a>, “un espacio para la investigación de IA independiente, arraigada en la comunidad, libre de la influencia dominante de las grandes tecnológicas”. Desde sus inicios, DAIR se ha enfocado en"
" elevar la voz de las personas marginadas en <a id=\"a4\">la investigación</a> sobre los daños asociados con la tecnología de IA. La organización también se concentra en construir comunidad con el "
"fin de acelerar la creación de tecnologías para un mejor futuro."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"We also acknowledge the evolution of the <a id=\"a1\">ACM Conference on Fairness, Accountability, and Transparency</a> (ACM FAccT), which has made a <a id=\"a2\">deliberate effort</a> to increase "
"conference participation from underrepresented groups, expanding the range of voices included in discussions that will shape the future of the industry."
msgstr ""
"También reconocemos la evolución de la <a id=\"a1\">Conferencia de la ACM sobre Equidad, Responsabilidad y Transparencia</a> (ACM FAccT), la cual ha hecho un <a id=\"a2\">esfuerzo deliberado</a> "
"para aumentar la participación de grupos subrepresentados en la conferencia, ampliando la gama de voces incluidas en las discusiones que darán forma al futuro de la industria."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"At Mozilla, we’ve provided financial backing for our <a id=\"a1\">Trustworthy AI Fellows</a>, who are addressing a wide range of issues, from racialized algorithmic systems on dating apps to the "
"impacts of AI technologies on rural communities. Several of our Fellows have since been recognized for their work on a global stage, including <a id=\"a2\">Inioluwa Deborah Raji</a> and <a "
"id=\"a3\">Abeba Birhane</a>, who were named to the 2023 TIME100 AI list for their work on open source algorithmic auditing tools. Berhane’s work has challenged the idea that ever-larger AI models "
"will solve the problem of toxic or biased outputs, finding that “as datasets scale, hateful content also scales.” Mozilla Ventures also invested in <a id=\"a4\">Lelapa AI</a>, which aims to unlock "
"the immense potential benefits of AI technology that has historically excluded African languages."
msgstr ""
"En Mozilla, hemos brindado apoyo financiero a nuestros <a id=\"a1\">Becarios de IA Confiable</a>, quienes están abordando una amplia gama de problemas, desde los sistemas algorítmicos racializados "
"en las aplicaciones de citas hasta las repercusiones de las tecnologías de IA en las comunidades rurales. Varios de nuestros investigadores han obtenido reconocimiento a su labor en foros "
"internacionales, como <a id=\"a2\">Inioluwa Deborah Raji</a> y <a id=\"a3\">Abeba Birhane</a>, nominadas para la lista TIME100 de IA de 2023 por su trabajo sobre herramientas de auditoría "
"algorítmica de código abierto. El trabajo de Birhane cuestionó la idea de que los modelos de IA cada vez más grandes solucionarán el problema de la toxicidad y sesgo en los resultados generados, y "
"descubrió que “cuanto más grandes los conjuntos de datos, más abundante el contenido que incita al odio”. Mozilla Ventures también invirtió en <a id=\"a4\">Lelapa AI</a>, que busca detonar los "
"inmensos beneficios potenciales de la tecnología de IA que históricamente ha excluido las lenguas africanas."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"There is also incredible demand for talent with trustworthy AI expertise, and a very limited number of people who currently have that expertise. Both the tech industry and academia will need to make"
" significant investments in AI education to meet the need. To cultivate a generation of builders with trustworthy AI training, we’ve partnered with universities on the <a id=\"a1\">Responsible "
"Computing Challenge</a> (RCC), which focuses on curricula that empower students to think about the social and political context of computing. RCC has awarded $2.7M in funding to 33 institutions "
"across three continents."
msgstr ""
"También existe una enorme demanda de talento con experiencia en IA confiable y son muy pocas las personas que la tienen. Tanto el sector tecnológico como el sector académico necesitarán invertir "
"grandes cantidades en formación en IA para satisfacer dicha necesidad. Con el fin de preparar a una generación de constructores con capacitación en IA confiable, nos asociamos con universidades en "
"el <a id=\"a1\">desafío de informática responsable</a> (RCC), cuya finalidad es que los planes de estudio enseñen a los estudiantes a reflexionar sobre el contexto social y político de la "
"informática. El RCC ha otorgado fondos por $2.7 millones a 33 instituciones en tres continentes."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid "Work to be Done"
msgstr "Trabajo por hacer"

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"<b>Widely-accepted industry guidelines on how to build AI responsibly are still in flux.</b> For example, Stanford’s Center for Research on Foundation Models released a <a id=\"a1\">Foundation Model"
" Transparency Index</a> (FMTI), which aimed to assess the level of transparency for 10 of the top AI foundation model developers. Indexes like this have great promise — and also come with their own "
"limitations. The Stanford analysis <a id=\"a2\">quickly came under scrutiny</a> as critics called out the FMTI’s shortcomings and bias toward closed models."
msgstr ""
"<b>Las directrices ampliamente aceptadas por la industria sobre cómo construir la IA de forma responsable aún están en proceso de cambio.</b> Por ejemplo, el Center for Research on Foundation Models"
" de la Universidad de Stanford introdujo un <a id=\"a1\">Índice de transparencia del modelo de fundación</a> (FMTI), cuyo objetivo era evaluar el grado de transparencia de 10 de los principales "
"desarrolladores de modelos fundaciones de IA. Otros índices similares resultan prometedores, pero también conllevan sus propias limitaciones. El análisis de Stanford <a id=\"a2\">enseguida fue "
"objeto de escrutinio</a>, ya que los críticos señalaron las deficiencias del FMTI y su sesgo hacia los modelos cerrados."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"We’re also seeing a concerning backslide on efforts to diversify major tech companies building AI. Following the murder of George Floyd and subsequent racial justice protests in 2020, leaders across"
" corporate America made commitments to hire, promote, and retain more people of color. That effort started to <a id=\"a1\">bear fruit</a>, but the trend could be under threat now that special "
"interest groups are <a id=\"a2\">piling in</a> and leaders like Elon Musk are <a id=\"a3\">railing against DEI</a>. In 2023, Google and Meta were among the companies who <a id=\"a4\">cut back on "
"DEI</a> spending."
msgstr ""
"También observamos un preocupante retroceso en los esfuerzos por diversificar las principales empresas tecnológicas que crean IA. Después del asesinato de George Floyd y las subsecuentes "
"manifestaciones por la justicia racial en 2020, los directivos de empresas en todo Estados Unidos se comprometieron a contratar, ascender y retener a más personas de color. El esfuerzo ya está <a "
"id=\"a1\">dando frutos</a>, pero la tendencia podría correr peligro ahora que hay <a id=\"a2\">montones</a> de grupos de intereses especiales y que dirigentes como Elon Musk <a id=\"a3\">despotrican"
" contra los principios de DEI</a>. En 2023, Google y Meta se contaban entre las empresas que <a id=\"a4\">recortaron gastos en DEI</a>."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"We must also consider the lack of regional diversity in AI development. The focus on western-centric efforts obscures the work of builders in areas with <a id=\"a1\">less-developed</a> tech sectors,"
" such as South America and the African continent, as well as the exploitation of workers who label data in countries like India and the Philippines. AI will impact life around the world, so it’s "
"crucial to have a wider set of voices involved in its design and deployment. The U.N. estimates that nearly <a id=\"a2\">2.6 billion people have no access to the internet</a>, so data used to train "
"AI models is not representative of one-third of the global population’s experiences. Without more input from a diverse set of people, emerging guidelines and best practices may not align with the "
"cultural and economic needs of other regions."
msgstr ""
"También debemos considerar la falta de diversidad regional en el desarrollo de la IA. El enfoque en los esfuerzos centrados en occidente oculta el trabajo de los constructores en áreas con sectores "
"tecnológicos <a id=\"a1\">menos desarrollados</a>, como Sudamérica y el continente africano, así como la explotación de los trabajadores que etiquetan datos en países como la India y Filipinas. La "
"inteligencia artificial impactará la vida en todo el mundo, por lo que es crucial contar con un conjunto más amplio de voces que participen en su diseño y despliegue. La ONU estima que casi <a "
"id=\"a2\">2,600 millones de personas carecen de acceso a internet</a>, por lo que los datos que se utilizan para entrenar los modelos de IA no son representativos de las experiencias de un tercio de"
" la población mundial. Sin más aportaciones de un conjunto diverso de personas, los lineamientos y mejores prácticas emergentes podrían no ajustarse a las necesidades culturales y económicas de "
"otras regiones."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"At Mozilla, we’re continuing <a id=\"a1\">our commitment</a> to building and supporting diverse, equitable, and inclusive internal teams. But we know that a broader transformation is needed: "
"engaging a diverse set of stakeholders in shaping AI’s future is a core part of Mozilla’s programmatic strategy, informing what we fund and where we work. Most notably, the <a id=\"a2\">Africa "
"Innovation Mradi</a> has convened and funded AI builders on the continent since 2020, promoting models of innovation grounded in the unique needs of users in Africa."
msgstr ""
"En Mozilla, continuamos con <a id=\"a1\">nuestro compromiso</a> de crear y apoyar la diversidad, equidad e inclusión en los equipos internos. Pero sabemos que se requiere una transformación más "
"amplia: involucrar a un conjunto de diversos participantes para conformar el futuro de la IA es parte medular de la estrategia programática de Mozilla al informar lo que financiamos y dónde "
"trabajamos. En particular, el programa <a id=\"a2\">Africa Innovation Mradi</a> ha convocado y financiado a constructores de IA africanos desde 2020, y promueve modelos de innovación basados en las "
"necesidades específicas de los usuarios en África."

msgctxt "body.afb32d3d-3c2d-4681-9f01-45ed3f26d149.quote"
msgid "AI will impact life around the world, so it’s crucial to have a <b>wider set of voices</b> involved in its design and deployment."
msgstr "La inteligencia artificial impactará la vida en todo el mundo, por lo que es crucial contar con un <b>conjunto más amplio de voces</b> que participen en su diseño y despliegue."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Building New Tech and Products"
msgstr "Desarrollar nuevas tecnologías y nuevos productos"

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"In 2020, we emphasized the need for more foundational technologies to emerge as trustworthy AI building blocks for developers. As the AI landscape is becoming more closed, it’s increasingly critical"
" that these building blocks align with the principles of openness, competition, and accountability."
msgstr ""
"En 2020, hicimos hincapié en la necesidad de que surgieran más tecnologías fundacionales como bloques de construcción de IA fiables para los desarrolladores. Conforme el universo de la IA se vuelve "
"más y más cerrado, es cada vez más importante que esos pilares se ajusten a los principios de apertura, competencia y responsabilidad."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Open source approaches do not inherently result in trustworthy AI and can be <a id=\"a1\">captured</a> and <a id=\"a2\">appropriated</a> by corporate interests. However, opening up AI tools to "
"public inspection, modification and remixing is a fundamental first step toward more accountability and agency. Openness can also play a significant role in promoting a <a id=\"a3\">fairer AI "
"market</a>, as a healthy open source ecosystem makes it easier for smaller players to compete with incumbents."
msgstr ""
"Los enfoques de código abierto no necesariamente producen una IA confiable y los intereses corporativos pueden <a id=\"a1\">capturarlos</a> y <a id=\"a2\">apropiarse</a> de ellos. A pesar de lo "
"anterior, un primer paso crucial hacia una mayor responsabilidad y acción es que las herramientas de inteligencia artificial puedan ser objeto de inspecciones públicas, modificarse y combinarse. "
"Asimismo, la apertura puede jugar un papel protagónico en la promoción de un <a id=\"a3\">mercado de IA más equitativo</a>, pues un ecosistema sano de código abierto facilita que los participantes "
"más pequeños compitan con los consolidados."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’ve already seen big tech companies make billions of dollars by stockpiling as much user data as possible, and they are keen to apply that strategy to their AI offerings. That’s why the emergence "
"of alternative business models for consumer technologies is a key condition for more trustworthy AI. To promote competition, investors must also support the entrepreneurs pioneering new AI tools and"
" business models that center human agency and protect people’s privacy."
msgstr ""
"Ya hemos visto cómo las grandes tecnológicas ganan miles de millones de dólares al acumular la mayor cantidad posible de datos de usuarios, y parecen dispuestas a aplicar esa misma estrategia a sus "
"ofertas de IA. De ahí que el surgimiento de otros modelos de negocio para las tecnologías de consumo sea una condición clave para lograr una IA más confiable. Con el fin de promover la competencia, "
"los inversionistas también deben apoyar a los emprendedores iniciadores de nuevas herramientas y modelos de negocio de IA que se centren en la acción humana y protejan la privacidad de las personas."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Finally, we need to increase development and adoption of tools that can help make AI systems more accountable. For example, privacy-enhancing technologies like federated learning have the potential "
"to reduce risks throughout the AI lifecycle, and help make AI more responsible. Other performance and risk assessment tools can also help developers make AI systems more trustworthy."
msgstr ""
"Por último, necesitamos incrementar el desarrollo y adopción de herramientas que puedan ayudar a que los sistemas de IA se responsabilicen más. Por ejemplo, las tecnologías reforzadoras de la "
"privacidad, como el aprendizaje federado, podrían reducir riesgos durante todo el ciclo de vida de la IA y ayudar a hacerla más responsable. Otras herramientas de desempeño y de evaluación de "
"riesgos también pueden ayudar a que los desarrolladores logren sistemas de IA más confiables."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Positive Progress"
msgstr "Avances positivos"

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Proprietary models got a head start in the latest phase of the AI race, but a range of open source LLMs and resources are emerging to counter them."
msgstr "Los modelos propietarios tuvieron una ventaja en la última fase de la carrera de la IA, sin embargo, está surgiendo una variedad de LLM y de recursos de código abierto para contrarrestarlos."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Across the AI ecosystem, <a id=\"a1\">Meta’s family of LLMs</a> has gotten most of the attention in discussions of open source AI, but there are hundreds of other models — like EleutherAI’s <a "
"id=\"a2\">GPT-NeoX-20B</a>, Hugging Face’s <a id=\"a3\">BLOOM</a>, the Technology Innovation Institute’s <a id=\"a4\">Falcon-180B</a>, and Mistral’s <a id=\"a5\">Mixtral 8x7B</a> — that better "
"reflect open source values. Hugging Face, a platform and community aiming to “democratize <i>good</i> machine learning,” is amplifying these models through its <a id=\"a6\">Open LLM Leaderboard</a>."
" By tracking, evaluating, and ranking open AI models submitted by the community, the company is giving small teams and individual developers a vetted foundational resource for building more "
"transparent products."
msgstr ""
"En todo el ecosistema de IA, la <a id=\"a1\">familia de LLM de Meta</a> ha captado la mayor atención en las discusiones de IA de código abierto, pero existen cientos de otros modelos, como el <a "
"id=\"a2\">GPT-NeoX-20B</a> de EleutherAI, el <a id=\"a3\">BLOOM</a> de Hugging Face, el <a id=\"a4\">Falcon-180B</a> del Instituto de Innovación Tecnológica, y el <a id=\"a5\">Mixtral 8x7B</a> de "
"Mistral, que reflejan de mejor manera los valores de código abierto. Hugging Face, una plataforma y comunidad cuyo objetivo es “democratizar el aprendizaje automático <i>positivo</i>” está "
"potenciando estos modelos a través de su <a id=\"a6\">Tabla de clasificación de LLM abiertos</a>. Al dar seguimiento, evaluar y clasificar modelos abiertos de IA presentados por la comunidad, la "
"empresa le proporciona a los equipos pequeños y desarrolladores individuales un recurso fundacional aprobado para construir productos más transparentes."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’ve also been contributing to this ecosystem at Mozilla. In March 2023, we invested $30 million to create <a id=\"a1\">Mozilla.ai</a>, a startup and community dedicated to making this fast-growing"
" field of open source AI models more trustworthy and useful. The company is in the early stages of developing a more communal vision for human-AI collaboration. This includes building <a "
"id=\"a2\">small, specialized language models (SSLMs)</a> that can be used to fine-tune models according to knowledge from subject matter experts, while ensuring those experts can tailor the models "
"according to their specific needs. We believe tools like these will help make AI systems more accessible, trustworthy, and useful."
msgstr ""
"En Mozilla también hemos contribuido a dicho ecosistema. En marzo de 2023, invertimos $30 millones para la creación de <a id=\"a1\">Mozilla.ai</a>, una empresa emergente y comunidad dedicada a hacer"
" que este floreciente campo de los modelos de IA de código abierto sea más confiable y útil. La empresa está empezando a desarrollar una visión más comunitaria para la colaboración entre los seres "
"humanos y la inteligencia artificial. Esto incluye la construcción de <a id=\"a2\">modelos de lenguaje especializado pequeños (SSLM)</a> que pueden utilizarse para perfeccionar los modelos de "
"acuerdo al conocimiento de los expertos en la materia, asegurando al mismo tiempo que dichos expertos puedan adaptar los modelos a sus necesidades específicas. Consideramos que herramientas como "
"estas ayudarán a lograr sistemas de IA más accesibles, confiables y útiles."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’re also actively developing and investing in open source building blocks that offer more agency and make AI more “local.” As part of a broader goal to make AI accessible to everyone through open "
"source, Mozilla released <a id=\"a1\">llamafile</a>, an open source, versatile, single file LLM that makes it <a id=\"a2\">dramatically easier</a> to run and distribute LLMs on a local machine like "
"a laptop. We’ve expanded our work on projects like <a id=\"a3\">Common Voice</a> — the world’s largest crowdsourced multilingual, open-source voice data corpus – which now contains over 100 language"
" data sets, including many local languages not supported by big tech players. Common Voice is the Mozilla Foundation’s flagship initiative to mitigate bias in AI by democratizing voice tech for all,"
" and was <a id=\"a4\">recognized as a digital public good</a> by the UN-backed Digital Public Goods Alliance initiative."
msgstr ""
"También estamos desarrollando e invirtiendo activamente en bloques de construcción de código abierto que ofrecen más agencia y hacen que la IA sea más &quot;local&quot;. Como parte del objetivo más "
"amplio de poner la IA a disposición de todos a través del código abierto, Mozilla lanzó <a id=\"a1\">llamafile</a>, un LLM de código abierto versátil y de un solo archivo que <a id=\"a2\">facilita "
"muchísimo</a> ejecutar y distribuir los LLM en un equipo local, como una laptop. Hemos ampliado nuestro trabajo en proyectos como <a id=\"a3\">Common Voice</a> —el corpus de datos de voz "
"colaborativo, multilingüe y de código abierto más grande del mundo—, que ahora contiene más de 100 conjuntos de datos lingüísticos, incluidos muchos idiomas locales que las grandes tecnológicas no "
"han incluido. Common Voice es la principal iniciativa de la Fundación Mozilla para mitigar el sesgo en la IA al democratizar la tecnología de voz para todos y fue <a id=\"a4\">reconocida como un "
"bien público digital</a> por la iniciativa de la Alianza de Bienes Públicos Digitales apoyada por la ONU."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Mozilla is also working on a number of documentation resources designed to help developers build AI responsibly. This includes our <a id=\"a1\">AI Guide</a>, a community-driven collection of open "
"source resources on topics like AI basics and how to choose machine learning models. It also features a set of notable projects from the AI community for insight and inspiration. For example, it "
"includes our <a id=\"a2\">Open Source Audit Tooling (OAT)</a> project, which aims to help developers, researchers, and policymakers understand the AI auditing landscape."
msgstr ""
"Mozilla también trabaja en diversos recursos documentales diseñados para ayudar a los desarrolladores a construir IA en forma responsable. Esto incluye nuestra <a id=\"a1\">Guía de IA</a>, una "
"colección de recursos de código abierto impulsada por la comunidad sobre temas como los conceptos básicos de la IA y la forma de elegir modelos de aprendizaje automático. Cuenta también con una "
"serie de proyectos notables de la comunidad de la IA para obtener ideas e inspiración. Por ejemplo, incluye nuestro <a id=\"a2\">Proyecto de Herramientas de Auditoría de Código Abierto (OAT)</a>, "
"que busca ayudar a los desarrolladores, investigadores y formuladores de políticas a entender el panorama de las auditorías a la IA."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’ve also invested heavily in the development of the trustworthy AI ecosystem. <a id=\"a1\">Mozilla Ventures</a> has already invested $4M in early-stage startups with a focus on trustworthy AI, "
"including <a id=\"a2\">Themis AI</a>, <a id=\"a3\">Fiddler AI</a>, <a id=\"a4\">Armilla AI</a>, <a id=\"a5\">Truepic</a>, and <a id=\"a6\">Flower</a>. The Themis team has built a software framework "
"to help machine learning models recognize when they are delivering unreliable outputs, while Fiddler AI is building trust into AI by offering observability and explainability tools. Truepic is "
"building content authenticity technologies that can help stop the spread of misinformation via AI-altered images. And, in 2023, Mozilla Foundation committed $1.3 million in technical funding to "
"support trustworthy AI projects through the <a id=\"a7\">Mozilla Technology Fund</a>, the <a id=\"a8\">Data Futures Lab</a>, and related grant initiatives."
msgstr ""
"Además, hemos invertido enormemente en desarrollar un ecosistema de IA confiable. <a id=\"a1\">Mozilla Ventures</a> ya ha invertido $4 millones en empresas incipientes de nueva creación que se "
"enfocan en la IA confiable, incluidas <a id=\"a2\">Themis AI</a>, <a id=\"a3\">Fiddler AI</a>, <a id=\"a4\">Armilla AI</a>, <a id=\"a5\">Truepic</a> y <a id=\"a6\">Flower</a>. El equipo de Themis ha"
" desarrollado un marco de software para ayudar a los modelos de aprendizaje automático a reconocer cuando están generando resultados poco fiables, mientras que Fiddler AI está generando confianza en"
" la IA al ofrecer herramientas de observabilidad y explicabilidad. Truepic construye tecnologías de autenticidad de contenidos que pueden ayudar a detener la difusión de desinformación por medio de "
"imágenes manipuladas mediante IA. Asimismo, en 2023, la Fundación Mozilla destinó $1.3 millones a fondos técnicos para apoyar proyectos de IA confiable a través del <a id=\"a7\">Mozilla Technology "
"Fund</a>, el <a id=\"a8\">Data Futures Lab</a> y las iniciativas de subvenciones relacionadas."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Work to be Done"
msgstr "Trabajo por hacer"

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"<b>Open source AI models are gaining momentum, but they won't go mainstream until they are easier to use, more effective, and more trustworthy.</b> To get there, the open source community must focus"
" on making these critical AI building blocks as helpful and successful as possible so they become more relevant in the market. When the barriers to building better AI tools come down, the open "
"source approaches will improve and the trustworthy AI ecosystem will grow."
msgstr ""
"<b>Los modelos de IA de código abierto están cobrando auge, pero no se generalizarán hasta que sean más fáciles de usar, más eficaces y más confiables.</b> Para lograrlo, la comunidad de código "
"abierto debe enfocarse en hacer que estos bloques de construcción esenciales de la IA sean tan útiles y exitosos como sea posible, con el fin de que adquieran más relevancia en el mercado. Cuando se"
" eliminen las barreras que impiden construir mejores herramientas de IA, mejorarán los enfoques de código abierto y crecerá el ecosistema de la IA confiable."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"One of the biggest barriers to open source AI development is the tremendous amount of computing power needed to build and train LLMs. Chip company NVIDIA is fielding <a id=\"a1\">record demand</a> "
"for its graphics processing units (GPUs), which can cost as much as $30,000 each. Training a model like GPT-4 requires thousands of those chips, making it prohibitively expensive for small teams and"
" individual developers to build out their own AI infrastructure. If deep-pocketed entities like Microsoft, Google, and the companies they back are the only ones that can afford enough GPUs to train "
"their models, more transparent and trustworthy AI systems will never get off the ground. Governments can help by funding AI compute capacity for public research projects and local startups, as they "
"have begun to do in the <a id=\"a2\">U.S.</a>, <a id=\"a3\">U.K.</a>, and the EU. Developers are also working on making it easier to build AI systems using AMD chips, as with our recent update to <a"
" id=\"a4\">llamafile</a>."
msgstr ""
"Uno de los mayores impedimentos para el desarrollo de IA de código abierto es la gran capacidad informática que se requiere para construir y entrenar los LLM. La empresa de chips NVIDIA ha "
"experimentado una <a id=\"a1\">demanda récord</a> de sus unidades de procesamiento de gráficos (GPU), que pueden costar hasta $30,000 cada una. Entrenar un modelo como GPT-4 requiere miles de esos "
"chips, un costo prohibitivo para que los equipos pequeños y desarrolladores individuales construyan su propia infraestructura de IA. Si las empresas acaudaladas como Microsoft y Google, así como las"
" que estas respalda, son las únicas que pueden pagar suficientes GPU para entrenar sus modelos, los sistemas transparentes y confiables de IA no se concretarán jamás. Los gobiernos pueden ayudar al "
"fondear la capacidad de cómputo de la IA para proyectos públicos de investigación y empresas emergentes locales, como lo han empezado a hacer en los <a id=\"a2\">Estados Unidos</a>, el <a "
"id=\"a3\">Reino Unido</a> y la Unión Europea. Los desarrolladores también trabajan en facilitar la construcción de sistemas de IA utilizando chips AMD, como hicimos en nuestra reciente actualización"
" de <a id=\"a4\">llamafile</a>."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Another challenge to building new tech and products is a lack of clarity around <a id=\"a1\">what “openness” means</a> in the context of AI. The open-source community has yet to reach consensus on a"
" <a id=\"a2\">concrete definition of open source AI</a>, or on the right guardrails for <a id=\"a3\">releasing AI models to the public</a>. This is critical, as openness alone will not lead to the "
"creation of trustworthy models or mitigate their risks. In September 2023, French startup Mistral AI released its own open source LLM called Mistral 7B, which it claimed was more powerful than "
"Meta’s LLaMA-2. However, researchers quickly raised alarms about the system’s <a id=\"a4\">lack of content moderation filters</a>, which allowed users to prompt the system for bomb-making and self-"
"harm instructions. Other models have built-in security measures to prevent chatbots from answering similar questions, but Mistral’s founder <a id=\"a5\">stated</a> that safety is the responsibility "
"of developers of AI applications, not the companies building the LLMs."
msgstr ""
"Otro reto en la construcción de nueva tecnología y nuevos productos es la falta de claridad respecto al <a id=\"a1\">significado de “apertura”</a> en el contexto de la IA. La comunidad de código "
"abierto aún debe alcanzar un consenso sobre una <a id=\"a2\">definición concreta de la IA de código abierto</a> o sobre las barreras de seguridad adecuadas para <a id=\"a3\">lanzar modelos de IA al "
"público</a>. Esto es fundamental, ya que la apertura por sí misma no llevará a la creación de modelos confiables ni mitigará sus riesgos. En septiembre de 2023, la empresa francesa emergente Mistral"
" AI lanzó su propio LLM de código abierto, llamado Mistral 7B, que calificó como más poderoso que la plataforma LLaMA-2 de Meta. Sin embargo, los investigadores rápidamente hicieron sonar las "
"alarmas porque el sistema <a id=\"a4\">carecía de filtros para moderar el contenido</a>, lo que permitía que los usuarios solicitaran al sistema instrucciones para hacer una bomba o autolesionarse. "
"Otros modelos tienen medidas de seguridad incorporadas para prevenir que los chatbots respondan a preguntas similares, pero el fundador de Mistral <a id=\"a5\">declaró</a> que la seguridad es "
"responsabilidad de los desarrolladores de aplicaciones de IA, no de las empresas que construyen los LLM."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"To tackle these challenges, Columbia University and Mozilla are <a id=\"a1\">collaborating</a> on a series of workshops in 2024 to map the different dimensions of openness in AI. The project will "
"engage individuals and organizations with longstanding involvement in open source to build a broad coalition that can stand up to big tech and encourage builders to responsibly open more of their AI"
" development. With this and other efforts, we’ll continue leading the way on defining and developing open source tools and systems that are safe, accessible, and transparent."
msgstr ""
"Con el fin de enfrentar estos retos en 2024, la Universidad de Columbia y Mozilla <a id=\"a1\">colaboran</a> en una serie de talleres para conceptualizar las diferentes dimensiones de la apertura en"
" la IA. El proyecto involucrará a personas y organizaciones que desde hace tiempo participen en el código abierto, con el fin de crear una amplia coalición que pueda enfrentarse a las grandes "
"tecnológicas y aliente a los constructores a abrir en forma responsable su desarrollo de inteligencia artificial. Con este y otros esfuerzos, continuaremos abriendo el camino para definir y "
"desarrollar herramientas y sistemas de código abierto que sean seguros, accesibles y transparentes."

msgctxt "body.498b8077-17ab-4151-90e1-0072f6ce5cf6.quote"
msgid "Open source AI models are gaining momentum, but <b>they won't go mainstream</b> until they are easier to use, more effective, and more trustworthy."
msgstr "Los modelos de IA de código abierto están cobrando auge, pero <b>no se generalizarán</b> hasta que sean más fáciles de usar, más eficaces y más confiables."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid "Raising Consumer Awareness"
msgstr "Sensibilizar a los consumidores"

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"A key lever in our 2020 paper was generating public demand for more trustworthy AI products. This includes both everyday consumers and the civil society organizations that educate and advocate for "
"their best interests. A well-informed public is a crucial piece of the AI accountability puzzle. When a critical mass of users pushes back on questionable practices, large tech companies have no "
"choice but to make changes to address their concerns. Their bottom lines depend on it."
msgstr ""
"Una de las vías clave de nuestro documento de análisis de 2020 fue la generación de demanda pública de productos de IA más confiables. Esto incluye tanto a los consumidores cotidianos como a las "
"organizaciones de la sociedad civil que crean consciencia y defienden los intereses del consumidor. Un público bien informado es pieza clave del rompecabezas de responsabilidad de la IA. Cuando una "
"masa crítica de usuarios rechaza las prácticas dudosas, las grandes tecnológicas no tienen otra opción más que hacer cambios para atender sus inquietudes. Sus resultados financieros dependen de "
"ello."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid "Positive Progress"
msgstr "Avances positivos"

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"ChatGPT’s fast rise and extensive media coverage have made AI a mainstream topic. Companies across industries are experimenting with it, which means millions of people are using it in their "
"workplace. As a result, risks that researchers have been warning about for years are in the spotlight. Recent surveys have found that <a id=\"a1\">more than three-quarters of consumers</a> are "
"concerned about misinformation resulting from AI, and less than 40% said they believe it’s <a id=\"a2\">safe and secure</a>. Years of advocacy and policy developments related to privacy, "
"misinformation, and tech platform accountability have created a more informed, skeptical and opinionated public, which is critical for the AI era."
msgstr ""
"El rápido ascenso de ChatGPT y la gran cobertura que le dieron los medios volvieron esta IA un tema de conversación. Muchas empresas en distintos sectores experimentan con ChatGPT, con lo cual "
"millones de personas lo utilizan en su lugar de trabajo. Así que esos riesgos tan anunciados por los investigadores desde hace años están siendo el foco de atención. Varias encuestas recientes "
"encontraron que a <a id=\"a1\">más del 75% de los consumidores</a> les preocupa la desinformación derivada de la IA y menos del 40% la consideran <a id=\"a2\">segura</a>. Años de activismo y "
"formulación de políticas relacionadas con la privacidad, la desinformación y la responsabilidad de las plataformas tecnológicas han creado un público más informado, escéptico y opinante, lo que "
"resulta crucial en la era de la IA."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Public opinion around AI is taking shape within familiar contexts of labor, human and consumer rights. Movement leaders have accelerated their understanding of how AI will impact their "
"constituencies, and are shaping attitudes and expectations. For example, AI concerns were a central part of 2023’s Hollywood labor strikes. After several months of work stoppages that brought the "
"film and TV industries to a halt, screenwriters and actors secured <a id=\"a1\">AI-related concessions</a> in union contracts covering hundreds of thousands of employees. The agreements don’t "
"completely prohibit generative AI, but they do place guardrails around how studios can use it, allaying fears about writers’ room cuts and AI-generated likenesses. This early victory bodes well for "
"future labor organizing efforts in other industries."
msgstr ""
"La opinión del público sobre la IA se forma en el contexto conocido de los derechos laborales, humanos y del consumidor. Los líderes de movimientos han acelerado su comprensión sobre la manera como "
"la IA afectará a sus partidarios y han conformando actitudes y expectativas. Por ejemplo, las inquietudes relacionadas con la IA fueron un elemento central de las huelgas en Hollywood durante 2023. "
"Después de varios meses de paros laborales que pusieron en pausa a las industrias del cine y de la televisión, los guionistas y actores lograron <a id=\"a1\">concesiones relacionadas con la IA</a> "
"en los contratos colectivos que amparaban a cientos de miles de empleados. Los contratos no prohíben por completo la IA generativa, pero colocan barreras en torno a la manera como los estudios "
"pueden utilizarla, disipando así los miedos acerca de los recortes de guionistas y las imágenes generadas por IA. Esta victoria inicial es un buen augurio de los futuros esfuerzos sindicalistas en "
"otros sectores."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Other work from advocacy organizations has focused on educating consumers about the dangers of AI and encouraging them to choose more trustworthy technologies when available. Consumer Reports "
"released three short films exploring algorithmic bias in medical devices, mortgage lending, and facial recognition as part of its <a id=\"a1\">Bad Input campaign</a>. Documentary films like <a "
"id=\"a2\">Coded Bias</a> (2021) were important conversation starters for a mainstream audience on topics like misinformation and racial bias in facial recognition algorithms. Dr. Joy Buolamwini’s "
"2023 book <a id=\"a3\"><i>Unmasking AI</i></a> expands on her experiences featured in Coded Bias, and on the founding of the <a id=\"a4\">Algorithmic Justice League</a>. Even those with more extreme"
" perspectives on AI have played a key role in raising consumer awareness; for example, in 2023, the <a id=\"a5\">Center for Humane Technology</a> gave a widely-watched talk on the existing risks of "
"AI technologies, providing more context on how the race to capitalize on AI can lead to safety failures."
msgstr ""
"Las organizaciones activistas también se han enfocado en volver más conscientes a los consumidores sobre los peligros de la IA y los ha instado a elegir tecnologías más confiables cuando se "
"encuentren disponibles. Consumer Reports lanzó tres cortometrajes que exploran los sesgos algorítmicos en dispositivos médicos, préstamos hipotecarios y reconocimiento facial como parte de su <a "
"id=\"a1\">campaña Bad Input</a>. Documentales como <a id=\"a2\">Coded Bias</a> (2021) iniciaron conversaciones para una audiencia generalizada sobre temas como la desinformación y el sesgo racial en"
" los algoritmos de reconocimiento facial. En su libro de 2023, <a id=\"a3\"><i>Unmasking AI</i></a>, la Dra. Joy Buolamwini abunda en las experiencias propias que se muestran en Coded Bias y en la "
"fundación de la <a id=\"a4\">Algorithmic Justice League</a>. Incluso aquellas personas con visiones más extremistas sobre la inteligencia artificial han desempeñado un papel clave en la "
"sensibilización de los consumidores. Por ejemplo, en 2023, el <a id=\"a5\">Center for Humane Technology</a> presentó una conferencia con gran audiencia sobre los riesgos actuales de las tecnologías "
"de IA, con lo que contextualizó cómo la carrera por explotar económicamente la IA puede ocasionar fallas de seguridad."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Mozilla's public campaigns and wider advocacy on issues around AI and consumer tech have mobilized over 500,000 people worldwide since 2021, driving meaningful changes to products and industry "
"standards. These campaigns have raised consumer awareness of issues around AI and the tech they use in their everyday lives, from search engines and social media platforms to video doorbells and "
"cars. In July 2023, Slack implemented a blocking feature following a civil society campaign <a id=\"a1\">we spearheaded</a>. In September 2023, YouTube announced it would give civil society "
"researchers access to crucial data, following a <a id=\"a2\">multi-year campaign by Mozilla</a>. In the same month, the Alliance for Automotive Innovation called for a federal privacy law in the "
"U.S. following public pressure generated by Mozilla’s ongoing <a id=\"a3\">*Privacy Not Included</a> report series, which most recently focused on <a id=\"a4\">privacy issues with connected "
"cars</a>. We also launched a new season of our <a id=\"a5\">IRL Podcast</a> in 2023, focused on AI developers bringing responsible products to market."
msgstr ""
"Desde 2021, las campañas públicas y el activismo más extenso de Mozilla sobre cuestiones relacionadas con la IA y la tecnología de consumo han movilizado a más de 500,000 personas en todo el mundo, "
"logrando cambios significativos en los productos y en las normas de la industria. Estas campañas han aumentado la conciencia del consumidor sobre los problemas relacionados con la IA y la tecnología"
" que utilizan en su vida cotidiana, desde motores de búsqueda y plataformas de redes sociales hasta timbres de video y automóviles. En julio de 2023, Slack implementó una función de bloqueo luego de"
" una campaña de la sociedad civil <a id=\"a1\">que nosotros encabezamos</a>. En septiembre de 2023, YouTube anunció que daría a los investigadores de la sociedad civil acceso a datos cruciales, "
"luego de una <a id=\"a2\">campaña de Mozilla que duró varios años</a>. En ese mismo mes, la Alianza para la Innovación Automotriz solicitó una ley federal de privacidad en los Estados Unidos, luego "
"de la presión pública generada por la serie de informes <a id=\"a3\">*Privacidad no incluida</a> de Mozilla, que recientemente se centró en los <a id=\"a4\">problemas de privacidad de los "
"automóviles conectados</a>. Ese mismo año también lanzamos una nueva temporada de nuestro <a id=\"a5\">IRL Podcast</a>, enfocado en que los desarrolladores de IA lleven productos responsables al "
"mercado."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Beyond advocacy, we’re also seeing new consumer products coming to market built on trustworthy AI principles. Established companies like <a id=\"a1\">Intel</a> and <a id=\"a2\">Adobe</a>, startups "
"like <a id=\"a3\">Reality Defender</a>, and research organizations like the <a id=\"a4\">MIT Media Lab</a> are working on ways to identify deepfakes, certify image authenticity and fight <a "
"id=\"a5\">dis- and mis-information</a>. Twilio has introduced an <a id=\"a6\">AI Nutrition Facts</a> initiative, offering a consumer-friendly way to understand how an AI product uses their data. "
"Google’s DeepMind group also beta launched <a id=\"a7\">SynthID</a>, a tool for watermarking and identifying AI-generated content, in August 2023."
msgstr ""
"Más allá de la concienciación, también observamos la llegada al mercado de nuevos productos de consumo basados en principios de IA fiables. Empresas establecidas como <a id=\"a1\">Intel</a> y <a "
"id=\"a2\">Adobe</a>, startups como <a id=\"a3\">Reality Defender</a> y organizaciones de investigación como <a id=\"a4\">MIT Media Lab</a> están trabajando en formas de identificar deepfakes, "
"certificar la autenticidad de las imágenes y luchar contra la <a id=\"a5\">desinformación y la mala información</a>. Twilio ha introducido la iniciativa <a id=\"a6\">AI Nutrition Facts</a>, que "
"ofrece una manera amigable para que el consumidor entienda la manera como un producto de IA utiliza sus datos. En agosto de 2023, el grupo DeepMind de Google también lanzó la versión beta de <a "
"id=\"a7\">SynthID</a>, una herramienta para colocar marcas de agua e identificar contenido generado por IA."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"In May 2023, Mozilla acquired <a id=\"a1\">Fakespot</a>, a company that protects consumers by using AI to detect fraudulent product reviews and third-party sellers in real-time. Our technology "
"analyzes billions of consumer reviews to quickly identify suspicious activity and then recommend better alternatives to consumers. In late 2023, we launched <a id=\"a2\">Fakespot Chat</a>, which "
"uses the power of generative AI to quickly answer shoppers’ product questions, saving consumers time and money."
msgstr ""
"En mayo de 2023, Mozilla adquirió <a id=\"a1\">Fakespot</a>, una empresa que protege a los consumidores al utilizar IA para detectar reseñas de productos y vendedores fraudulentos en tiempo real. "
"Nuestra tecnología analiza miles de millones de reseñas de consumidores para identificar rápidamente las actividades sospechosas y después recomendar mejores alternativas a los consumidores. A "
"finales de 2023, lanzamos <a id=\"a2\">Fakespot Chat</a>, que utiliza el poder de la IA generativa para responder con rapidez a las preguntas de los compradores sobre productos, lo que ahorra tiempo"
" y dinero a los consumidores."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid "Work to be Done"
msgstr "Trabajo por hacer"

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Though we’ve seen <a id=\"a1\">positive momentum</a> to give workers more of a say in the introduction of AI tools and systems in the workplace, most casual users of generative AI tools are not "
"thinking critically about whether these systems are trustworthy or not. Since there are few well-known alternatives to popular tools based on closed models, many consumers may feel forced to choose "
"the tools from the companies whose technology is already embedded in their daily lives."
msgstr ""
"Aunque observamos un <a id=\"a1\">impulso positivo</a> para dar a los trabajadores más voz en la introducción de herramientas y sistemas de IA en el lugar de trabajo, la mayoría de los usuarios "
"ocasionales de herramientas de IA generativa no piensan de manera crítica si dichos sistemas son o no confiables. Como existen pocas alternativas conocidas a las herramientas populares basadas en "
"modelos cerrados, muchos consumidores pueden sentirse obligados a elegir las herramientas de las empresas cuya tecnología ya está integrada en su vida cotidiana."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"We can’t blame consumers for choosing the most convenient tools that appear to be trustworthy, especially when there are limited alternatives. The open source community must continue building AI "
"technology to give people better options. Civil society organizations must keep sounding the alarm on the potential for unchecked AI to cause real-world harm, and funding better alternatives. And "
"regulators must preserve a competitive marketplace with strong consumer protections, giving the broader AI ecosystem the necessary guardrails to thrive."
msgstr ""
"No podemos culpar a los consumidores por elegir las herramientas más convenientes y aparentemente fiables, sobre todo cuando las alternativas son limitadas. La comunidad de código abierto debe "
"seguir construyendo tecnología de IA para brindar mejores opciones a las personas. Las organizaciones de la sociedad civil deben seguir alertando sobre el potencial de la IA descontrolada para "
"causar daños en el mundo real, así como financiar mejores alternativas. De igual manera, los legisladores deben preservar un mercado competitivo con sólidas protecciones para los consumidores, "
"ofreciendo al ecosistema más amplio de la IA las salvaguardas necesarias para prosperar."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"At Mozilla, we’re working to build more trustworthy AI technologies into our own consumer products in the coming years, and are expanding our crowdsourced investigative research into how TikTok’s "
"recommendation algorithm works. We’ll also need to continue raising consumer awareness of the AI privacy risks and encourage demand for more privacy-preserving approaches used in AI products."
msgstr ""
"En Mozilla, trabajamos para desarrollar tecnologías más fiables de IA en nuestros propios productos de consumo para los próximos años, así como ampliando nuestra investigación colaborativa sobre el "
"funcionamiento del algoritmo de recomendación de TikTok. También tendremos que seguir sensibilizando a los consumidores sobre los riesgos para la privacidad de la IA y fomentar la demanda de más "
"enfoques de preservación de la privacidad utilizados en los productos de IA."

msgctxt "body.893bbf68-8dca-44fd-98b4-46cd39f124e7.quote"
msgid "A well-informed public is a <b>crucial piece</b> of the AI accountability puzzle."
msgstr "Un público bien informado es <b>pieza clave</b> del rompecabezas de responsabilidad de la IA."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid "Strengthening AI Regulations and Incentives"
msgstr "Fortalecer la normatividad y los incentivos de la IA"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"The final lever in our original paper focused on the need for governments around the world to develop the vision, skills, and capacities required to effectively regulate AI. Though industry norms "
"and consumer demand play a major role in advancing trustworthy AI, we won’t get far without policies to incentivize more responsible practices, and legal mechanisms to hold companies accountable."
msgstr ""
"La última vía en nuestro documento original de análisis se centró en la necesidad de que los gobiernos de todo el mundo desarrollen la visión, habilidades y capacidades necesarias para reglamentar "
"eficazmente la IA. Aunque las normas del sector y las exigencias de los consumidores juegan un papel importante en la promoción de la IA confiable, no llegaremos muy lejos sin políticas que "
"incentiven prácticas más responsables y mecanismos legales para que las empresas se responsabilicen."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid "Positive Progress"
msgstr "Avances positivos"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Our fellow advocates and researchers have been clamoring for action on AI-related regulation for years, but the generative AI boom has made these calls impossible to ignore. Widespread consumer "
"awareness of AI has put more pressure on lawmakers to get up to speed. There’s more momentum than ever behind global policy efforts to develop and implement effective and thoughtful AI regulations."
msgstr ""
"Nuestros colegas defensores e investigadores llevan años exigiendo que se tomen medidas en materia de regulación de la IA, pero el auge de la IA generativa ha hecho que sea imposible ignorar estas "
"peticiones. El amplio conocimiento de la IA por parte de los consumidores ha aumentado la presión sobre los legisladores para que se pongan manos a la obra. Como nunca antes, distintas políticas "
"públicas en el mundo entero buscan formular y aplicar reglamentos eficaces y meditados sobre la IA."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"The EU is moving more quickly than some other regions. Lawmakers there have agreed in principle on the <a id=\"a1\">EU AI Act</a>, a first-of-its-kind piece of legislation originally proposed in "
"April 2021. The framework takes a predominantly risk-based approach to regulating AI, with separate rules for the most powerful general-purpose AI models. Though there are some limitations to this "
"approach, the EU AI Act is set to become the most comprehensive AI law in the world, and will have significant impacts on <a id=\"a2\">global AI governance</a> efforts. The law will complement other"
" recent European technology laws including the <a id=\"a3\">Digital Services Act (DSA)</a> and the <a id=\"a4\">Digital Markets Act (DMA)</a>."
msgstr ""
"La Unión Europea avanza mucho más rápido que otras regiones. Los legisladores han llegado en principio a un acuerdo sobre la <a id=\"a1\">Ley de IA de la Unión Europea</a>, una legislación pionera "
"en su género propuesta inicialmente en abril de 2021. El marco adopta un enfoque basado fundamentalmente en el riesgo para regular la IA, con normas separadas para los modelos más potentes de IA de "
"propósito general. No obstante las limitaciones de este enfoque, la Ley de Inteligencia Artificial de la Unión Europea se convertirá en la ley de IA más integral del mundo y repercutirá enormemente "
"en los esfuerzos de <a id=\"a2\">gobernanza mundial de la IA</a>. Esta ley complementará otras leyes europeas de tecnología recientes, incluidas la <a id=\"a3\">Ley de Servicios Digitales (DSA)</a> "
"y la <a id=\"a4\">Ley de Mercados Digitales (DMA)</a>."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Since its inception, our policy and advocacy teams played a key role in the development of the EU AI Act. Working with our allies, we successfully pushed for more transparency, binding rules for "
"foundation models, and targeted due diligence obligations along the AI value chain. However, the work isn't done yet. We’ll continue to advocate to make it a success until the law is fully "
"implemented."
msgstr ""
"Desde que se ideó la Ley de Inteligencia Artificial de la Unión Europea, nuestros equipos de políticas y activismo han contribuido enormemente a su formulación. Junto con nuestros aliados, logramos "
"ejercer presión en favor de más transparencia, reglas vinculantes para los modelos fundacionales y obligaciones específicas de debida diligencia en toda la cadena de valor de la IA. Todavía queda "
"trabajo por hacer. Seguiremos luchando por lograr que la ley sea un éxito, hasta que sea totalmente implementada."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"In the U.S., where many of the biggest names in AI are headquartered, the regulatory discussion is starting to pick up. The Biden Administration is looking to move from voluntary AI safety "
"commitments toward concrete rules. In October 2023, President Biden released his <a id=\"a1\">Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence</a> with directives to enhance "
"safety, privacy, equity, and competition — providing a welcome move to ensure AI development comes with sufficient regulatory guardrails. In November 2023, Vice President Harris announced <a "
"id=\"a2\">draft policy guidance</a> to mitigate risks when the federal government uses AI, putting the federal government’s purchasing power behind shaping better AI norms in industry."
msgstr ""
"En los Estados Unidos, donde se ubican las oficinas principales de muchos de los nombres más importantes de IA, el debate legislativo está empezando a repuntar. El gobierno de Biden busca pasar de "
"los compromisos voluntarios a las reglas concretas sobre la seguridad de la IA. En octubre de 2023, el presidente Biden aprobó su <a id=\"a1\">Orden Ejecutiva para una IA segura y confiable</a>, "
"cuyas directrices mejoran la seguridad, privacidad, equidad y competencia, e un avance bienvenido para garantizar que el desarrollo de la IA venga acompañado de suficientes barreras de seguridad "
"normativas. En noviembre de 2023, la vicepresidenta Harris anunció la <a id=\"a2\">guía para proyectos de políticas</a> para mitigar riesgos cuando el gobierno federal utiliza la IA. De esta manera "
"el poder de compra del gobierno federal respalda la conformación de mejores normas de IA en el sector."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Though the U.S. has failed to bring comprehensive privacy legislation to fruition, lawmakers are eager to get AI regulation right. In addition to the voluntary commitments AI companies made at the "
"White House in summer 2023, Senate Majority Leader Chuck Schumer held a <a id=\"a1\">series of closed-door AI Insight Forums</a> for lawmakers, featuring tech CEOs, researchers, and civil rights "
"leaders. It’s crucial that a broad diversity of voices are heard in these forums and it‘s encouraging that the policy community is seeking out AI expertise, including from Mozilla and <a "
"id=\"a2\">its fellows</a>, to develop better legislation."
msgstr ""
"Aunque Estados Unidos no ha podido concretar la legislación integral sobre la privacidad, los legisladores anhelan reglamentar correctamente la IA. Además de los compromisos voluntarios por parte de"
" las empresas de IA en la Casa Blanca en el verano de 2023, Chuck Schumer, líder de la mayoría del Senado, celebró una <a id=\"a1\">serie de foros de información sobre la IA a puertas cerradas</a> "
"para los legisladores, con la participación de directores generales de empresas tecnológicas, investigadores y líderes de derechos civiles. Es fundamental que se escuche una amplia variedad de voces"
" en estos foros y resulta alentador que la comunidad de políticas públicas busque la experiencia en inteligencia artificial, incluso la de Mozilla y <a id=\"a2\">sus colaboradores</a>, con el fin de"
" formular mejores leyes."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"In Mozilla’s <a id=\"a1\">written statement</a> for the forum, we highlighted the need for AI policy to center privacy, openness, and transparency as the backbone of responsible regulation. We urged"
" policymakers to look beyond a binary notion of open versus closed AI. A balanced environment where both ecosystems can flourish will fuel innovation, ensure competitiveness, and protect people’s "
"rights and safety while mitigating potential risks. We also emphasized the need for lawmakers to champion privacy in AI technologies by default, with comprehensive privacy legislation like the "
"proposed American Data Privacy and Protection Act at the forefront."
msgstr ""
"En la <a id=\"a1\">declaración escrita</a> que Mozilla elaboró para el foro, destacamos la necesidad de que las políticas de IA hagan de la privacidad, la apertura y la transparencia el eje de una "
"legislación responsable. Instamos a los responsables de las políticas a mirar más allá de una noción binaria de IA abierta versus IA cerrada. Un entorno equilibrado donde ambos ecosistemas puedan "
"florecer impulsará la innovación, garantizará la competencia y protegerá los derechos y la seguridad de las personas, al tiempo que mitigará los riesgos potenciales. También hicimos énfasis en la "
"necesidad de que los legisladores defiendan la privacidad en las tecnologías de IA por defecto, con una legislación integral de privacidad, como la propuesta Ley de los Estados Unidos para la "
"Protección y Privacidad de Datos en primera línea."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Our leaders are also offering their expertise in the U.K. Mozilla.ai gave oral evidence to the U.K.’s House of Lords Communications and Digital Committee as part of their inquiry into LLMs. In our "
"remarks, we emphasized the role that open approaches to AI can play in innovation, the market failures preventing smaller players from accessing computing resources like GPUs, and the need for more "
"government investment in AI infrastructure to promote competition. We also discussed the importance of digital education for enterprises, schools, and civil services on what these models are capable"
" of, and how to deploy them safely in various contexts."
msgstr ""
"Nuestros líderes también ofrecen su experiencia en Mozilla.ai del Reino Unido y rindieron testimonio oral ante el Comité de Comunicaciones y Asuntos Digitales de la Cámara Alta del Reino Unido, como"
" parte de su investigación sobre los LLM. En nuestras observaciones, destacamos el papel que pueden desempeñar los enfoques abiertos de IA en la innovación, las fallas del mercado que impiden que "
"los participantes más pequeños tengan acceso a recursos de cómputo como las GPU, así como la necesidad de una mayor inversión del gobierno en infraestructura de la IA para promover la competencia. "
"Discutimos también la importancia de enseñar a empresas, escuelas y servicios públicos qué son capaces de hacer estos modelos y cómo implementarlos en forma segura en diversos contextos."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid "Work to be Done"
msgstr "Trabajo por hacer"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Regulation is needed to make AI more trustworthy and mitigate the risks of the technology. At the same time, regulators need to be mindful of the impact such rules will have on competition and "
"openness in AI. Any regulatory framework should ensure that the AI market remains open to competition and innovation from companies challenging the industry behemoths. To do so, it must <a "
"id=\"a1\">safeguard openness and open source</a>."
msgstr ""
"Se requiere reglamentación para hacer que la IA sea más confiable y mitigar los riesgos de la tecnología. Al mismo tiempo, las autoridades normativas deben tener en cuenta el impacto de dichas "
"reglas sobre la competencia y apertura en la IA. Cualquier marco normativo debe garantizar que el mercado de la IA permanezca abierto a la competencia y a la innovación de empresas que desafíen a "
"los gigantes del sector. Para lograrlo, debe <a id=\"a1\">proteger la apertura y el código abierto</a>."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Openness and transparency are key if we want the benefits of AI to reach the majority of humanity, rather than seeing them applied only to use cases where profit is the primary motivator. Recent "
"global policy discussions on openness have lacked nuance — partly due to <a id=\"a1\">outsized influence</a> from big tech incumbents <a id=\"a2\">trying to shape regulatory discussions</a> to their"
" benefit. Makers of proprietary models have cited hypothetical catastrophic threats as the most important issues for lawmakers to focus on, neglecting existing AI harms like bias and discrimination."
" In October 2023, we and more than 1,800 signatories pushed back on this dynamic in our <a id=\"a3\">Joint Statement on AI Safety and Openness</a>:"
msgstr ""
"La apertura y la transparencia son fundamentales si queremos que los beneficios de la IA lleguen a la mayoría de la humanidad, en lugar de verlos aplicados únicamente a casos de uso en los que el "
"beneficio es el principal motivador. Los recientes debates políticos sobre la apertura han carecido de matices, en parte debido a la <a id=\"a1\">enorme influencia</a> de las grandes tecnológicas ya"
" consolidadas que <a id=\"a2\">intentan moldear los debates normativos</a> para su propio beneficio. Los creadores de modelos propios y exclusivos han señalado hipotéticas amenazas catastróficas "
"como los problemas más graves en los que deben enfocarse los legisladores, dejando de lado perjuicios de la IA como la parcialidad y la discriminación. En octubre de 2023, junto con más de 1800 "
"firmantes, rechazamos esta dinámica en nuestra <a id=\"a3\">Declaración conjunta sobre seguridad y apertura de la IA</a>:"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Yes, openly available models come with risks and vulnerabilities — AI models can be abused by malicious actors or deployed by ill-equipped developers. However, we have seen time and time again that "
"the same holds true for proprietary technologies — and that increasing public access and scrutiny makes technology safer, not more dangerous. The idea that tight and proprietary control of "
"foundational AI models is the only path to protecting us from society-scale harm is naive at best, dangerous at worst."
msgstr ""
"Sí, los modelos disponibles en forma abierta conllevan riesgos y vulnerabilidades: los actores malintencionados pueden abusar de los modelos de IA o estos pueden ser implementados por "
"desarrolladores mal equipados. Sin embargo, hemos observado una y otra vez que lo mismo puede decirse de las tecnologías propias y exclusivas, y que el creciente acceso y escrutinio del público "
"hacen que la tecnología sea más segura, no más peligrosa. La idea de que el control estricto y exclusivo de los modelos fundacionales de IA es el único camino a seguir para protegernos de los "
"perjuicios a escala de sociedad resulta, en el mejor de los casos, ingenua y, en el peor, peligrosa."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"There are government-led processes that can help us sort through some of these bigger questions on open source governance and regulation. As directed in the Biden Administration’s executive order, "
"the U.S. Department of Commerce’s National Telecommunications and Information Administration (NTIA) <a id=\"a1\">is reviewing</a> both the risks and benefits of openly available LLM model weights, "
"inviting public comments to inform potential regulatory approaches. Mozilla intends to submit a response to the associated request for comment to inform NTIA’s approach to this issue."
msgstr ""
"Existen procesos gubernamentales que pueden ayudarnos a analizar algunas de estas grandes interrogantes acerca de la gobernanza y la regulación del código abierto. Como lo indica la orden ejecutiva "
"del gobierno de Biden, la Administración Nacional de Telecomunicaciones e Información (NTIA) del Departamento de Comercio de los Estados Unidos <a id=\"a1\">está revisando</a> los riesgos y "
"beneficios de los LLM disponibles en forma abierta, e invita a la ciudadanía a comentar para sustentar los posibles enfoques normativos. Mozilla se propone presentar una respuesta a la solicitud de "
"comentarios asociada para informar del enfoque de la NTIA sobre esta cuestión."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"When paired with consumer protections and strong rules to prevent anti-competitive practices, openness spurs innovation and accelerates competition by providing common resources for the ecosystem at"
" large. Competition spurs investments, new jobs, and better choices for companies and consumers. To extend the benefits of the AI boom beyond big tech, lawmakers must prioritize enforcing and "
"strengthening existing competition rules to better meet the challenges of today."
msgstr ""
"Al combinarse con protecciones al consumidor y reglas estrictas para prevenir prácticas monopólicas, la apertura estimula la innovación y acelera la competencia al proporcionar recursos comunes para"
" el ecosistema en general. La competencia fomenta inversiones, nuevos empleos y mejores elecciones para las empresas y los consumidores. Para que los beneficios del auge de la IA no solo lleguen a "
"las grandes tecnológicas, los legisladores deben priorizar la implementación y el fortalecimiento de las reglas existentes de competencia para afrontar mejor los retos actuales."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Additionally, while lawmakers educate themselves on the intricacies of the AI landscape, bad actors are poised to weaponize generative AI tools to sow disinformation and political unrest — a harm "
"that is happening right now. With more than 40 national elections scheduled for 2024, policymakers must move more quickly to address this year’s threats. We must use the opportunity to study and "
"engage with AI’s impacts on global politics, and strengthen our systems for the next set of elections. To that end, Mozilla is highlighting the work of researchers around the world who are "
"uncovering inequities in how platforms approach global elections. We’re spotlighting the ‘copy-and-paste’ policy approach platforms tend to take to global elections, particularly for countries in "
"the Global Majority, and showing the devastating impact such decisions can have on a country’s information ecosystem, especially where democratic institutions are relatively fragile."
msgstr ""
"Además, mientras los legisladores se educan sobre las complejidades del panorama de la IA, los actores malintencionados están listos para utilizar las herramientas de IA generativa para sembrar "
"desinformación e inestabilidad política, un daño que está ocurriendo en este momento. Con más de 40 elecciones nacionales programadas para 2024, los responsables de políticas deben actuar más "
"rápidamente para abordar las amenazas de este año. Debemos aprovechar esta oportunidad para estudiar y encarar los impactos de la IA sobre la política mundial, así como fortalecer nuestros sistemas "
"para la siguiente ronda de elecciones. Para ello, Mozilla destaca la labor de los investigadores de todo el mundo que están descubriendo desigualdades en la manera como las plataformas abordan las "
"elecciones mundiales. Ponemos de relieve el enfoque político de \"copiar y pegar\" que las plataformas tienden a adoptar en las elecciones mundiales, en especial en países de la mayoría global, y "
"mostramos el impacto devastador que tales decisiones pueden tener en el ecosistema informativo de un país, especialmente si las instituciones democráticas son relativamente frágiles."

msgctxt "body.88c348fd-0985-4337-845d-cb6e5870be0c.quote"
msgid "Any regulatory framework should ensure that the AI market remains open to <b>competition and innovation</b> from companies challenging the industry behemoths."
msgstr ""
"Cualquier marco normativo debe garantizar que el mercado de la inteligencia artificial permanezca abierto a <b>la competencia y a la innovación</b> de empresas que desafíen a los gigantes del "
"sector."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "The Path Forward for Trustworthy AI"
msgstr "El camino a seguir para lograr una IA confiable"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"The AI landscape is moving more quickly than ever, and the trustworthy AI ecosystem is growing alongside it. To build on the positive momentum we’ve seen in the last three years, we must take "
"targeted action across each of our four key levers: industry norms, new tech and products, consumer demand and regulations and incentives."
msgstr ""
"El universo de la IA avanza más rápidamente que nunca y el ecosistema de IA confiable crece a la par. Para aprovechar el auge positivo de los últimos tres años, debemos tomar medidas específicas en "
"cada una de nuestras cuatro vías clave: normas del sector, nueva tecnología y nuevos productos, demanda de los consumidores, y normatividad e incentivos."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "Next Steps for Mozilla"
msgstr "Próximos pasos para Mozilla"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"We will continue our work to earn users’ trust in AI across the entire Mozilla project, focusing on openness as our guiding principle. By scaling the potential of open source approaches and "
"advocating for fair, open markets, we can realize our vision of a trustworthy AI landscape with agency and accountability at the center."
msgstr ""
"Seguiremos trabajando para ganarnos la confianza de los usuarios en la IA en todo el proyecto Mozilla, centrándonos en la apertura como principio rector. Si ampliamos el potencial de los enfoques de"
" código abierto y abogamos por mercados justos y abiertos, podremos hacer realidad nuestra visión de un panorama de IA digno de confianza en el que la agencia y la responsabilidad ocupen un lugar "
"central."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "Here’s what’s next on our to-do list:"
msgstr "Lo próximo en nuestra lista de cosas por hacer:"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Shift the public narrative on (trustworthy) AI.</b> We have an opportunity to unlock huge benefits from AI — and an urgent need to tackle tough questions about social ills and closed markets. "
"Mozilla will work with activists, builders and policymakers to make sure this more nuanced story about AI breaks through. We’re working with civil society organizations around the globe to build "
"sustained political power and shift the narrative. We’re also spotlighting the voices of responsible builders, technology leaders, and innovators to help them set the AI agenda in media coverage, "
"policy debates, and popular culture."
msgstr ""
"<b>Cambiar la narrativa pública sobre la IA (confiable).</b> Tenemos la oportunidad de aprovechar los enormes beneficios de la IA, así como una necesidad urgente de encarar cuestiones espinosas "
"relacionadas con los problemas sociales y los mercados cerrados. Mozilla trabajará con activistas, constructores y legisladores de políticas para garantizar que salga a la luz esta historia más "
"matizada sobre la IA. Trabajamos con organizaciones de la sociedad civil en todo el mundo para edificar un poder político sostenido y cambiar la narrativa. Asimismo, ponemos en primer plano la voz "
"de los constructores, líderes tecnológicos e innovadores responsables para ayudarlos a determinar la agenda de la IA en la cobertura mediática, los debates políticos y la cultura popular."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Make open source generative AI more trustworthy — and mainstream.</b> Open source generative AI is gaining momentum. Our goal is to ensure open source models are trustworthy, safe, helpful and "
"easy to use. Mozilla projects like the Communal AI small language model platform, the Common Voice dataset, and llamafile are local and more accessible models aimed squarely at this goal."
msgstr ""
"<b>Hacer que la IA generativa de código abierto sea más fiable —y más generalizada—.</b> La IA generativa de código abierto está cobrando auge. Nuestro objetivo es garantizar que los modelos de "
"código abierto sean confiables, seguros, útiles y fáciles de usar. Proyectos de Mozilla como la plataforma de modelos pequeños de lenguaje especializado, Communal AI, el conjunto de datos Common "
"Voice y llamafile son modelos locales y más accesibles dirigidos directamente a ese objetivo."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Empower consumers — and give them real choices</b>. In an era when AI is becoming intricately woven into the fabric of our daily lives, we must champion products that prioritize and exemplify the"
" highest standards of privacy, security, and transparency. By drawing on the invaluable insights gained from technologies like Fakespot, we’re deepening our dedication to integrating cutting-edge AI"
" capabilities that genuinely empower consumers within our product suite. We’re expanding the impact of these efforts through initiatives like <a id=\"a1\">*Privacy Not Included</a>, which are "
"instrumental in equipping consumers with the essential knowledge to make enlightened product choices."
msgstr ""
"<b>Empoderar a los consumidores —y brindarles alternativas reales—</b>. En una era en la que la inteligencia artificial forma parte intrínseca de nuestra cotidianidad, debemos abogar por productos "
"que ejemplifiquen y prioricen las más altas normas de privacidad, seguridad y transparencia. Al aprovechar la valiosa información obtenida de tecnologías como Fakespot, profundizamos nuestra "
"dedicación para integrar capacidades de IA de vanguardia que realmente puedan empoderar a los consumidores en nuestra gama de productos. Estamos ampliando el impacto de estos esfuerzos con "
"iniciativas como <a id=\"a1\">* Privacidad no incluida</a>, que son fundamentales para equipar a los consumidores con el conocimiento esencial para tomar decisiones informadas sobre los productos."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Invest in the trustworthy + open source AI ecosystem.</b> No single company or organization can serve as a counterweight to big tech — but a community can. We will continue to expand our "
"investment in startups, open source projects, and nonprofits building trustworthy AI, both through direct investment and through thoughtful grantmaking. Properly resourced, this ecosystem has the "
"potential to challenge the big players and push AI in a better direction."
msgstr ""
"<b>Invertir en el ecosistema de IA confiable y de código abierto.</b> Ninguna empresa u organización puede servir de contrapeso a las grandes tecnológicas, pero una comunidad sí. Continuaremos "
"ampliando nuestra inversión en empresas incipientes, proyectos de código abierto y organizaciones sin fines de lucro que construyen IA confiable, a través de la inversión directa y del otorgamiento "
"meditado de subvenciones. Con los recursos adecuados, este ecosistema cuenta con el potencial para desafiar a los grandes actores y llevar a la AI por mejor camino."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Help regulators develop and roll out pragmatic AI regulation.</b> The EU AI Act, the U.S. Executive Order on AI, and similar initiatives in other countries show policymakers are serious about "
"trustworthy AI. Mozilla is increasing its resources to help policymakers roll out regulation and policies that are helpful and pragmatic from both policy and operational perspectives. This work "
"includes publishing research on topics like open source AI models, competition, and privacy that policymakers can draw on, convening policymakers to share expertise and experience, and spotlighting "
"positive policy advancements around the globe."
msgstr ""
"<b>Ayudar a que las autoridades legislativas formulen e implementen reglamentos pragmáticos de IA.</b> El Acta de IA de la UE, la Orden Ejecutiva de IA de los EE. UU. y las iniciativas similares en "
"otros países demuestran que los legisladores toman en serio la IA digna de confianza. Mozilla está destinando más recursos para ayudarlos a aprobar políticas y reglamentos útiles y pragmáticos tanto"
" desde el punto de vista político como operativo. Esta labor incluye la publicación de investigaciones sobre temas como los modelos de IA de código abierto, la competencia y la privacidad, que "
"pueden servir de apoyo a los legisladores al convocarlos a éstos para compartir conocimientos y experiencias, así como la difusión de avances positivos en la formulación de políticas en todo el "
"mundo."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "Next Steps for the Trustworthy AI Ecosystem"
msgstr "Pasos a seguir para el ecosistema de IA confiable"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "We’re committed to doing our part, but we can’t make trustworthy AI a reality without working together across the entire tech ecosystem. Here’s how you can get involved:"
msgstr ""
"Tenemos el compromiso de hacer lo que nos toca, pero no podemos lograr que la IA confiable sea una realidad si todo el ecosistema tecnológico no trabaja en conjunto. Puedes colaborar de varias "
"maneras:"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Builders: Seek out — and contribute to — trustworthy open source AI projects.</b> Instead of reaching for the most well-known proprietary models, take advantage of advancements in open source "
"LLMs, and learn from curated resources like our <a id=\"a1\">AI Guide</a>. As you develop new tools, engage with builders, users, and researchers from a wide range of backgrounds to widen your "
"perspective. Understanding how AI will impact people who don’t think like you will make your project or product that much better."
msgstr ""
"<b>Constructores: Busquen —y colaboren en— proyectos confiables de IA de código abierto.</b> En lugar de recurrir a los modelos patentados más conocidos, aprovecha los avances en los LLM de código "
"abierto y aprende de recursos seleccionados como nuestra <a id=\"a1\">Guía de IA</a>. Conforme desarrolles nuevas herramientas, interactúa con constructores, usuarios e investigadores de una amplia "
"variedad de orígenes con el fin de ampliar tu perspectiva. Comprender de qué manera la IA impactará a las personas que no piensan como tú hará que tu proyecto o producto sea mucho mejor."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Consumers: Be critical — and know there are choices you can make.</b> Consumers can’t control who builds AI, but they can choose more trustworthy products when available, and demand them when "
"they aren’t. We know that public pressure can drive change, even within the most powerful companies on Earth. Look past the “cool factor” of new AI tools and read up on the pros and cons before you "
"experiment. Accessible guides like our <a id=\"a1\">*Privacy Not Included</a> series offer clear comparisons in plain language to help you make informed decisions about everything from voice "
"assistants to smart home products."
msgstr ""
"<b>Consumidores: Sean críticos y sepan que pueden elegir.</b> Los consumidores no pueden controlar quién construye la IA, pero pueden elegir productos más confiables cuando estén disponibles y "
"exigirlos cuando no lo estén. Sabemos que la presión del público puede llevar al cambio, incluso dentro de las empresas más poderosas del planeta. Mira más allá del factor &quot;guau” de las nuevas "
"herramientas de IA e infórmate acerca de los pros y los contras antes de experimentar. Las guías accesibles como nuestra serie <a id=\"a1\">* Privacidad no incluida</a> ofrecen comparaciones claras "
"en lenguaje sencillo para ayudarte a tomar decisiones informadas sobre todo tipo de cosas, desde asistentes de voz hasta productos inteligentes para el hogar."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Policymakers: Prioritize openness and accountability in new rules for AI.</b> Big tech is <a id=\"a1\">pushing for LLM licensing</a> regulations, ostensibly as a security measure. But we know "
"from experience that limiting who can access or benefit from new digital technologies does not make us safer. Openness and accountability can be an antidote, and policymakers must shape legislation "
"accordingly."
msgstr ""
"<b>Legisladores: Prioricen la apertura y la rendición de cuentas en las nuevas reglas para la IA.</b> Las grandes tecnológicas están <a id=\"a1\">presionando en favor de que se reglamenten las "
"licencias de LLM</a>, como supuesta medida de seguridad. Pero sabemos por experiencia que limitar a quién puede acceder a nuevas tecnologías digitales o beneficiarse de ellas no nos hace más "
"seguros. La apertura y la responsabilidad pueden ser el antídoto, y los responsables de la formulación de políticas deben moldear la legislación en consecuencia."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Civil Society Advocates: Look for intersections between AI and issues your communities care about.</b> Whether an organization focuses on human rights, climate justice, LGBTQ+ rights, or racial "
"justice, AI is relevant. <a id=\"a1\">Philanthropy can offset the influence of tech incumbents</a> by supporting the smaller players pioneering AI approaches that uplift society, not just stock "
"prices. Focus grantmaking on projects that center agency, transparency, and accountability in AI, and look to those that connect to the work you’re already doing."
msgstr ""
"<b>Activista de la sociedad civil: Busca intersecciones entre la IA y los problemas que preocupan a tu comunidad.</b> Ya sea que una organización se enfoque en los derechos humanos, la justicia "
"climática, los derechos LGBTQ+ o la justicia racial, la IA es relevante. <a id=\"a1\">La filantropía puede compensar la influencia de las empresas tecnológicas ya consolidadas</a> al contribuir a "
"que los participantes más pequeños inicien enfoques de IA que no solo eleven los precios de las acciones, sino también a la sociedad. Dirige las subvenciones a proyectos centrados en la acción, la "
"transparencia y la responsabilidad en la IA, y busca aquellos que se relacionen con el trabajo que ya estás haciendo."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Investors: Fund companies, organizations and projects focused on Trustworthy AI.</b> It’s tempting to put your money on the big industry leaders, but alternative AI business models that put user "
"privacy and well-being first present a massive opportunity. Whether you’re a venture capitalist, an institutional investor or a philanthropist, financially supporting the growth of the trustworthy "
"AI ecosystem will help mitigate AI risks while spreading the returns beyond big tech."
msgstr ""
"<b>Inversionista: Financiar empresas, organizaciones y proyectos enfocados en la IA confiable.</b> Suena tentador apostar por los grandes líderes del sector; sin embargo, los modelos de negocio "
"alternativos de IA que dan prioridad a la privacidad y bienestar de los usuarios representan una gran oportunidad. No importa si eres capitalista de riesgo, inversionista institucional o filántropo,"
" apoyar financieramente el crecimiento del ecosistema de IA confiable ayudará a mitigar los riesgos de la IA y, al mismo tiempo, extenderá los rendimientos más allá de las grandes tecnológicas."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"AI will impact every corner of the world. To make sure it delivers on its promise for humanity, we must continue activating a broad coalition of technologists, activists, legislators, and everyday "
"citizens with diverse perspectives.There is still much to do, but with a movement grounded in openness, agency, and accountability, a more trustworthy AI landscape is within reach. Let’s get to "
"work."
msgstr ""
"La inteligencia artificial impacta todos los rincones del mundo. Y para garantizar que cumpla su promesa con la humanidad, debemos seguir activando una amplia coalición de expertos en tecnología, "
"activistas, legisladores y ciudadanos comunes con diversas perspectivas. Aún queda mucho por hacer, pero con un movimiento basado en la apertura, la acción y la responsabilidad, un universo de IA "
"más confiable está al alcance. Manos a la obra."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Please email us at</b> <a id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> to provide any input on the report and/or to highlight your favorite examples of AI being used in ways that build "
"trust and improve people’s lives.</b>"
msgstr ""
"<b>Envíanos un correo electrónico a</b> <a id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> para darnos tu opinión sobre este reporte y/o tus ejemplos favoritos de IA utilizada en formas que "
"fomentan la confianza y mejoran la vida de las personas.</b>"

msgctxt "body.b642b40e-f1bb-4063-9ea9-804558e7b856.quote"
msgid "With a movement grounded in openness, agency, and accountability, a more trustworthy AI landscape is <b>within reach.</b>"
msgstr "Con un movimiento basado en la apertura, la acción y la responsabilidad, un universo de IA más confiable <b>está al alcance.</b>"

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "Further Reading"
msgstr "Lecturas complementarias"

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>This is the real lesson to take away from the OpenAI debacle</b></a><b>, Fast Company (op-ed), December 2023</b>: In an op-ed, Mozilla’s Mark Surman explains how OpenAI’s November "
"governance battle points to the need for public institutions that prioritize humanity's interests over profit, especially in the AI era, despite the failure of OpenAI's nonprofit model."
msgstr ""
"<a id=\"a1\"><b>Esta es la verdadera lección a extraer del debacle de OpenAI</b></a><b>, editorial de la revista <em>Fast Company</b>, diciembre de 2023</b>: En un artículo de opinión, Mark Surman "
"de Mozilla explica cómo la lucha de gobernanza de OpenAI en noviembre evidencia la necesidad de instituciones públicas que prioricen los intereses de la humanidad por encima de las ganancias, "
"especialmente en la era de la IA, a pesar del fracaso del modelo sin fines de lucro de OpenAI."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>When AI doesn’t speak your language</b></a><b>, Coda, October 2023:</b> Highlights the challenges minority languages face with AI, where better technology could simultaneously "
"support language use and increase surveillance."
msgstr ""
"<a id=\"a1\"><b>When AI doesn’t speak your language</b></a><b>, <em>Coda</em>, octubre de 2023:</b> Destaca los retos a los que se enfrentan las lenguas de la minoría en la IA. Una mejor tecnología "
"podría apoyar el uso de la lengua e incrementar la vigilancia, simultáneamente."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>AI’s Present Matters More Than Its Imagined Future</b></a><b>, The Atlantic (op-ed), October 2023</b>: Mozilla Fellow Inioluwa Deborah Raji writes about her experience attending one "
"of Sen. Chuck Schumer’s AI Insight Forums, and why present-day harms are more urgent than hypothetical existential AI risks."
msgstr ""
"<a id=\"a1\"><b>El presente de la IA importa más que su futuro imaginado</b></a><b>, editorial de la revista The Atlantic (oped), octubre de 2023</b>: Inioluwa Deborah Raji, investigadora de "
"Mozilla, escribe acerca de su experiencia al asistir a uno de los foros de información sobre la IA del senador Chuck Schumer y por qué los daños actuales son más urgentes que los riesgos "
"existenciales hipotéticos de la IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>How should regulators think about \"AI\"?</b></a><b>, Dr. Emily M. Bender (video), October 2023</b><b><i>:</i></b> Dr. Bender spoke at a virtual roundtable on AI in the workplace "
"convened by Congressman Bobby Scott, breaking down the six different kinds of automation and providing recommendations for AI regulation."
msgstr ""
"<a id=\"a1\"><b>¿Cómo deben los reguladores pensar en &quot;IA&quot;?</b></a><b>, (video) de la Dra. Emily M. Bender, octubre de 2023</b><b><i>:</i></b> La Dra. Bender intervino en una mesa redonda "
"virtual sobre IA en el lugar de trabajo convocada por el congresista Bobby Scott, en la que desglosó los seis tipos diferentes de automatización y ofreció recomendaciones para la regulación de la "
"IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>The battle over Open-Source AI</b></a><b>, Ben’s Bites (newsletter), October 2023</b>: This piece summarizes where well-known AI companies stand on the issue of regulating advanced "
"open source AI software."
msgstr ""
"<a id=\"a1\"><b>La lucha por la IA de código abierto</b></a>,<b> Ben’s Bites (newsletter), octubre de 2023</b>:.Este artículo resume la postura de conocidas empresas de IA sobre la cuestión de la "
"regulación del software avanzado de IA de código abierto"

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>Artificial Intelligence: Advancing Innovation Towards the National Interest</b></a><b>, Clément Delangue, Hugging Face (written congressional testimony), June 2023:</b> In his "
"testimony, Hugging Face’s CEO emphasizes the importance of open AI innovation and the need for mechanisms that ensure AI is safe, transparent, and aligns with national interests."
msgstr ""
"<a id=\"a1\"><b>Artificial Intelligence: Advancing Innovation Towards the National Interest</b></a><b>, testimonio por escrito ante el Congreso de Clément Delangue de Hugging Face, junio de "
"2023:</b> En su testimonio, el director general de Hugging Face subraya la importancia de la innovación en la IA abierta y la necesidad de mecanismos que garanticen que la IA sea segura, "
"transparente y en consonancia con los intereses nacionales."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>We tested ChatGPT in Bengali, Kurdish, and Tamil. It failed.</b></a>, <b>Rest of World, September 2023</b>: Rest of World's testing revealed ChatGPT’s struggles with many "
"underrepresented languages. The system often makes up words and fails at logic and basic information retrieval, highlighting gaps in AI training data and the need for tailored language support."
msgstr ""
"<a id=\"a1\"><b>Probamos ChatGPT en bengalí, kurdo y tamil. Falló.</b></a>, <b>Rest of World, septiembre de 2023 </b>: Las pruebas de Rest of World revelaron que ChatGPT tiene dificultades con "
"muchos idiomas subrepresentados. Con frecuencia, el sistema inventa palabras y presenta fallas en la lógica y en la obtención de información básica, lo que evidencia lagunas en los datos de "
"entrenamiento de IA y la necesidad de soporte adaptado al idioma."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>The Battle Over Books3 Could Change AI Forever</b></a><b>, WIRED, September 2023:</b> This piece details the battle over the Books3 training data set, which was created from a vast "
"collection of copyrighted literary works and is now at the center of disputes between open-access advocates and copyright holders fighting for control and compensation."
msgstr ""
"<a id=\"a1\"><b>The Battle Over Books3 Could Change AI Forever</b></a><b>, <em>WIRED</em>, septiembre de 2023:</b> Esta obra detalla la pugna por el conjunto de datos de entrenamiento Books3, que se"
" creó a partir de una vasta colección de obras literarias con derechos de autor y ahora es objeto de controversias entre defensores del acceso abierto y los propietarios de los derechos de autor que"
" pelean por tener control y compensación."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>LoRA Fine-tuning Efficiently Undoes Safety Training from Llama 2-Chat 70B</b></a>,<b> LessWrong, October 2023:</b> This study demonstrates how AI models can be easily manipulated to "
"undo safety training, raising concerns about the risks of public model releases."
msgstr ""
"<a id=\"a1\"><b>LoRA Fine-tuning Efficiently Undoes Safety Training from Llama 2-Chat 70B</b></a>,<b> <em>LessWrong</em>, octubre de 2023:</b> Este estudio demuestra lo fácil que es manipular los "
"modelos de IA para que reviertan el entrenamiento de seguridad y plantea inquietudes sobre los riesgos de modelos públicos que se han lanzado."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>Removing RLHF Protections in GPT-4 via Fine-Tuning</b></a><b>, University of Illinois Urbana-Champaign and Stanford University, November 2023:</b> This study reveals that attackers "
"can remove reinforcement learning with human feedback (RLHF) protections in language models like GPT-4, highlighting the need for enhanced protection against potential misuse."
msgstr ""
"<a id=\"a1\"><b>Removing RLHF Protections in GPT-4 via Fine-Tuning</b></a><b>, Universidad de Illinois Urbana-Campaign y Universidad de Stanford, noviembre de 2023:</b> Este estudio revela que los "
"atacantes pueden eliminar las protecciones del aprendizaje por refuerzo a partir de la retroalimentación humana (RLHF) en modelos de lenguaje como GPT-4, y destaca la necesidad de una mayor "
"protección contra el posible uso indebido."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>AI Red-Teaming Is Not a One-Stop Solution to AI Harms</b></a><b>, Data &amp; Society, October 2023</b>: This policy brief argues that while AI red-teaming can identify specific "
"technical vulnerabilities, it must be paired with other accountability tools, including algorithmic impact assessments, external audits, and public consultation."
msgstr ""
"<a id=\"a1\"><b>AI Red-Teaming Is Not a One-Stop Solution to AI Harms</b></a><b>, <em>Data &amp; Society</em>, octubre de 2023</b>: Esta descripción de políticas públicas afirma que, si bien las "
"pruebas de penetración aplicadas mediante equipo rojo a la IA pueden identificar vulnerabilidades técnicas, deben combinarse con otras herramientas de rendición de cuentas, incluidas evaluaciones de"
" impacto algorítmico, auditorías externas y consultas públicas."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>DeepMind reportedly lost a yearslong bid to win more independence from Google</b></a>, <b>The Verge, May 2021</b>: Google rejected DeepMind’s request for greater autonomy and "
"nonprofit status, due to the AI subsidiary's ongoing financial losses and Google's desire to commercialize its AI research."
msgstr ""
"<a id=\"a1\"><b>DeepMind reportedly lost a yearslong bid to win more independence from Google</b></a>, <b><em>The Verge</em>, mayo de 2021</b>: Google rechazó la solicitud de DeepMind de una mayor "
"autonomía y que se le considerara una organización sin fines de lucro, debido a las pérdidas financieras constantes de esta subsidiaria de IA y al deseo de Google de comercializar su investigación "
"sobre IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>These fake images reveal how AI amplifies our worst stereotypes</b></a><b>, The Washington Post, November 2023</b>: AI image generators like Stable Diffusion and DALL-E continue to "
"perpetuate disturbing stereotypes related to gender and race despite attempts to detoxify their training data, illustrating the urgent issue of inherent bias in AI systems."
msgstr ""
"<a id=\"a1\"><b>These fake images reveal how AI amplifies our worst stereotypes</b></a><b>, <em>The Washington Post</em>, noviembre de 2023</b>: Los generadores de imágenes mediante IA como Stable "
"Diffusion y DALL-E siguen perpetuando los molestos estereotipos relacionados con el género o la raza, a pesar de los esfuerzos por desintoxicar sus datos de entrenamiento, lo que muestra el problema"
" urgente del sesgo inherente en los sistemas de IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>OpenAI is getting trolled for its name after refusing to be open about its A.I.</b></a><b>, Fortune, March 2023:</b> Fortune details the criticism OpenAI has faced for its use of "
"“open” language despite its focus on proprietary, closed source models."
msgstr ""
"<a id=\"a1\"><b>OpenAI is getting trolled for its name after refusing to be open about its A.I.</b></a><b>, <em>Fortune</em>, marzo de 2023:</b> La revista detalla la crítica hacia OpenAI por usar "
"lenguaje “abierto”, a pesar de su enfoque en modelos propios y exclusivos de código cerrado."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>Meta can call Llama 2 open source as much as it likes, but that doesn't mean it is</b></a><b>, The Register (op-ed), July 2023:</b> Steven J. Vaughan-Nichols argues that Meta's "
"release of Llama 2 under a \"community license\" falls short of open-source principles, making the company’s use of the term more about marketing than the principles of the open-source community."
msgstr ""
"<a id=\"a1\"><b>Meta puede llamar a Llama 2 código abierto tanto como quiera, pero eso no significa que lo sea</b></a><b>, editorial de la revista <em>The Register</b>, julio de 2023:</b> Steven J. "
"Vaughan-Nichols sostiene que el lanzamiento de Llama 2 por parte de Meta bajo una &quot;licencia comunitaria&quot; no cumple con los principios de código abierto, lo que significa que el uso que la "
"empresa hace del término tiene más que ver con el marketing que con los principios de la comunidad de código abierto."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "Additional Links"
msgstr "Enlaces adicionales"

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "<a id=\"a1\"><b>AI Incident Database</b></a><b>:</b> Indexing the collective history of harms by AI"
msgstr "<a id=\"a1\"><b>Base de datos de incidentes de IA</b></a><b>:</b> Cataloga la historia colectiva de los daños causados por la IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "<a id=\"a1\"><b>Algorithmic Justice League Harm Collection Tool</b></a><b>:</b> Allows users to report AI harms, biases and triumphs"
msgstr "<a id=\"a1\"><b>Herramienta de recopilación de daños de la Algorithmic Justice League</b></a><b>:</b> Permite que los usuarios reporten perjuicios, sesgos y triunfos de la IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "<a id=\"a1\"><b>The Data Provenance Initiative:</b></a> Audit of large scale datasets"
msgstr "<a id=\"a1\"><b>La Iniciativa de Procedencia de Datos:</b></a> Auditoría de conjuntos de datos a gran escala."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Appendix - Additional Mozilla Trustworthy AI Projects"
msgstr "Apéndice - Otros proyectos de Mozilla para una IA confiable"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Changing AI Development Norms"
msgstr "Cambiar las normas de desarrollo de la IA"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Responsible Computing Challenge</b></a><b>:</b> In 2023, Mozilla provided $2.7M to universities in Kenya, India, and the US to add responsible computing to their curricula. The "
"result: thousands of students — the AI builders of tomorrow — wrestling with ethical issues in tech."
msgstr ""
"<a id=\"a1\"><b>Desafío de Informática Responsable</b></a><b>:</b> En 2023, Mozilla aportó 2,7 millones de dólares a universidades de Kenia, India y EE. UU. para incorporar la informática "
"responsable a sus planes de estudio. ¿El resultado? Miles de estudiantes —los constructores de IA del futuro— encaran cuestiones éticas en la tecnología."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Is that Even Legal? guide</b></a>: Mozilla is educating AI builders on how to develop trustworthy AI systems within existing regulatory frameworks around the world. Our guide offers "
"data governance research and advice for builders in Germany, India, Kenya and the U.S."
msgstr ""
"<a id=\"a1\"><b>¿Es eso incluso legal? guía</b></a>: Mozilla instruye a los constructores de IA sobre cómo desarrollar sistemas de IA confiables dentro de los marcos regulatorios existentes en todo "
"el mundo. Nuestra guía ofrece investigación y asesoría sobre gobernanza de datos para constructores en Alemania, India, Kenia y Estados Unidos."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Africa Innovation Mradi</b></a><b>:</b> This program leverages Mozilla’s role as stewards of the open web to promote innovation grounded in the unique needs of users in the African "
"region beginning with East and Southern Africa."
msgstr ""
"<a id=\"a1\"><b>Africa Innovation Mradi</b></a><b>:</b> Este programa aprovecha el papel de Mozilla como guardián de la web abierta para promover la innovación basada en las necesidades únicas de "
"los usuarios de la región africana, empezando por África Oriental y Meridional."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Trustworthy AI Fellowships</b></a><b>:</b> Long before ChatGPT, Mozilla Trustworthy AI Fellows were studying AI’s flaws, limits, and potential. Since 2019, more than 50 "
"Fellows have explored the impacts of AI on society."
msgstr ""
"<a id=\"a1\"><b>Mozilla Trustworthy AI Fellowships</b></a><b>:</b> Mucho antes de que existiera ChatGPT, los investigadores de una IA confiable de Mozilla estudiaban las fallas, los límites y el "
"potencial de la IA. Desde 2019, más de 50 investigadores han explorado los efectos de la IA en la sociedad."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Festival (MozFest)</b></a>: Too often, the most pressing decisions about AI get made in silos. Mozfest is Mozilla’s antidote to this problem. The event convenes and connects "
"thousands of activists, engineers, philanthropists, and policymakers from around the world to build and envision more trustworthy AI."
msgstr ""
"<a id=\"a1\"><b>Festival de Mozilla (MozFest)</b></a>: Muy a menudo, las decisiones más urgentes sobre la IA se toman en silos. El Mozfest es el antídoto de Mozilla para este problema. El evento "
"convoca y conecta a miles de activistas, ingenieros, filántropos y legisladores de todo el mundo para construir y vislumbrar una IA más confiable."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Lelapa AI</b></a><b>:</b> Mozilla Ventures invested in Lelapa AI, a South African-based that just launched its first product: Vulavula, a new AI tool that converts voice to text and "
"detects names of people and places in written text in four South African languages. Lelapa’s CEO, <a id=\"a2\">Pelonomi Moila</a>, was recently named to the TIME100 in AI."
msgstr ""
"<a id=\"a1\"><b>Lelapa AI</b></a><b>:</b> Mozilla Ventures invirtió en Lelapa AI, una empresa en Sudáfrica que acaba de lanzar su primer producto: Vulavula, una nueva herramienta de IA que convierte"
" la voz en texto y detecta nombres de personas y lugares en texto escrito en cuatro lenguas sudafricanas. Hace poco, <a id=\"a2\">Pelonomi Moila</a>, directora general de Lelapa, fue nominada para "
"la lista TIME100 de IA."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Building New Tech and Products"
msgstr "Desarrollar nuevas tecnologías y nuevos productos"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Responsible AI Challenge</b></a><b>:</b> In May 2023, Mozilla hosted an event with 175 attendees, 7 workshops, and 3 keynote speakers to explore how our Trustworthy AI principles "
"could be used to provide a playbook for builders. The event awarded $100K in prizes to challenge winners who pitched Responsible AI projects."
msgstr ""
"<a id=\"a1\"><b>Desafío de IA responsable</b></a><b>:</b> En mayo de 2023, Mozilla organizó un evento con 175 asistentes, 7 talleres y 3 ponentes destacados para explorar cómo nuestros principios de"
" IA confiable podían utilizarse para proporcionar un manual a los constructores. El evento otorgó premios por $100 000 a los ganadores del desafío que propusieron proyectos de IA responsable."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Internet Ecosystem (MIECO)</b></a><b>:</b> MIECO funds innovators building a healthier internet experience. Supported projects include llamafile, which makes open source "
"large language models much more accessible to both developers and end users."
msgstr ""
"<a id=\"a1\"><b>Mozilla Internet Ecosystem (MIECO)</b></a><b>:</b> MIECO financia a los innovadores que construyen una experiencia más sana en internet. Uno de los proyectos beneficiados es "
"llamafile, que vuelve los grandes modelos de lenguaje de código abierto mucho más accesibles tanto para los desarrolladores, como para los usuarios finales."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "<a id=\"a1\"><b>Mozilla AI Guide</b></a><b>:</b> A community-driven resource where developers can come together to pioneer and drive generative AI innovations."
msgstr "<a id=\"a1\"><b>Guía de IA de Mozilla</b></a><b>:</b> Un recurso impulsado por la comunidad que reúne a desarrolladores para iniciar e impulsar innovaciones de IA generativa."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Common Voice</b></a><b>:</b> The world’s largest multilingual, open-source dataset, Common Voice is used by researchers, academics, and developers around the world to train "
"voice-enabled technology and ultimately make it more inclusive and accessible."
msgstr ""
"<a id=\"a1\"><b>Common Voice de Mozilla</b></a><b>:</b> Investigadores, académicos y desarrolladores en todo el mundo utilizan Common Voice, el conjunto de datos multilingüe y de código abierto más "
"grande del mundo, para entrenar tecnología por voz y hacerla más incluyente y accesible."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Technology Fund (MTF)</b></a>: Since 2022, MTF has supported open source projects that explore how AI impacts issues ranging from bias to climate change. One notable project,"
" Countering Tenant Screening, exposes bias and discrimination within the AI-powered screening services used by landlords."
msgstr ""
"<a id=\"a1\"><b>Mozilla Technology Fund (MTF)</b></a>: Desde 2022, MTF ha apoyado proyectos de código abierto que exploran cómo la IA afecta a cuestiones que van desde los prejuicios al cambio "
"climático. Un proyecto notable, Countering Tenant Screening, expone los prejuicios y la discriminación en los servicios de selección basados en IA que utilizan los arrendadores."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Data Futures Lab (DFL):</b></a> The race to collect data to build and test AI Models has raised new legal and ethical questions about the source and ownership of data. "
"Mozilla’s Data Futures Lab incubates products and platforms radically redesigning what trustworthy data stewardship looks like."
msgstr ""
"<a id=\"a1\"><b>Data Futures Lab (DFL) de Mozilla:</b></a> La carrera por recopilar datos para construir y probar modelos de IA ha planteado nuevas cuestiones jurídicas y éticas sobre el origen y la"
" propiedad de la información. El Data Futures Lab de Mozilla incuba productos y plataformas al rediseñar radicalmente cómo debe ser una gestión de datos confiable."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla.ai</b></a><b>:</b> Mozilla has been a key contributor to the NeurIPS 2023 <a id=\"a2\">Large Language Model Efficiency Challenge</a>, the Conference on Knowledge Discovery "
"and Data Mining (KDD)’s <a id=\"a3\">workshop</a> on the evaluation of recommender systems, and <a id=\"a4\">research</a> on new ways to efficiently perform few-shot classification on top of closed "
"models like chatGPT."
msgstr ""
"<a id=\"a1\"><b>Mozilla.ai</b></a><b>:</b> Mozilla ha sido un colaborador clave en el <a id=\"a2\">Desafío de Eficiencia de los Grandes Modelos de Lenguaje</a> de NeurIPS 2023, el <a "
"id=\"a3\">taller</a> de la Conferencia sobre Descubrimiento de Conocimiento y Minería de Datos (KDD) sobre la evaluación de sistemas de recomendación, y la <a id=\"a4\">investigación</a> sobre "
"nuevas formas de realizar de manera eficiente la clasificación de pocos disparos en modelos cerrados como chatGPT."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Themis AI</b></a>: Mozilla Ventures invested in Themis AI, a Cambridge, MA-based company that spun out of MIT's CSAIL. Themis tackles bias and uncertainty in AI models and has "
"developed a tool, CAPSA, that can automatically estimate uncertainty for any ML model."
msgstr ""
"<a id=\"a1\"><b>Themis AI</b></a>: Mozilla Ventures invirtió en Themis AI, una empresa en Cambridge, Massachusetts, que surgió del Laboratorio de Ciencias de la Computación e Inteligencia Artificial"
" (CSAIL) del Instituto de Tecnología de Massachusetts (MIT). Themis aborda el sesgo y la incertidumbre en los modelos de IA y ha desarrollado CAPSA, una herramienta que puede calcular "
"automáticamente la incertidumbre para cualquier modelo de aprendizaje automático."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Raising Consumer Awareness"
msgstr "Sensibilizar a los consumidores"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>*Privacy Not Included</b></a>: *PNI guides expose the realities and risks of connected devices. The 2023 guide focused on cars and generated unprecedented attention: citing our "
"research, US Senator Ed Markey wrote to 14 car companies in the US demanding information about their collection, use and sales of personal data."
msgstr ""
"<a id=\"a1\"><b>* Privacidad No Incluida</b></a>: La guía * PNI expone las realidades y los riesgos de los dispositivos conectados a Internet. La guía de 2023 se enfocó en los automóviles y generó "
"un interés sin precedente: al hacer mención de nuestra investigación, Ed Markey, senador de los Estados Unidos, le escribió a 14 empresas automotrices de ese país exigiéndoles información acerca de "
"su recopilación, uso y venta de datos personales."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>IRL Podcast</b></a>: The latest season of IRL showcased global trustworthy AI innovators from civil society, industry, and policy — connecting the issues they care about to AI. The "
"goal was to remind IRL’s growing audience that there’s no taking the human out of the algorithm. There have been over 100,000 downloads of IRL since Season 7 launched in October 2023."
msgstr ""
"<a id=\"a1\"><b>IRL Podcast</b></a>: La última temporada de IRL presentó a innovadores de IA confiable de la sociedad civil, la industria y las políticas públicas de distintas partes del mundo, que "
"vincularon con la IA los problemas que les importan. El objetivo fue recordarle a la creciente audiencia de IRL que no se puede sacar al ser humano del algoritmo. Desde que salió la Temporada 7 en "
"octubre de 2023, IRL ha tenido más de 100 000 descargas."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Philanthropic Advocacy</b></a><b>:</b> In 2023, Mozilla participated in <a id=\"a2\">a collaboration with Vice President Kamala Harris’ office on philanthropy’s role in AI</a> "
"alongside other leading foundations. We also published a set of <a id=\"a3\">AI Funding Principles</a> that draw on our 4+ years of funding trustworthy AI."
msgstr ""
"<a id=\"a1\"><b>Activismo filantrópico</b></a><b>:</b> En 2023, Mozilla participó en <a id=\"a2\">una colaboración con la oficina de la vicepresidenta Kamala Harris sobre el papel de la filantropía "
"en la IA</a> junto con otras fundaciones líderes. Asimismo, publicamos un conjunto de <a id=\"a3\">Principios de financiamiento de la IA</a> que se inspiran en los más de 4 años que llevamos "
"financiando una IA confiable."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Open Source Research and Investigation Team</b></a>: The OSRI team uses crowdsourced data to make opaque and influential AI systems more transparent and accountable. The team has "
"produced several <a id=\"a2\">original research</a> reports into YouTube’s recommendation algorithm."
msgstr ""
"<a id=\"a1\"><b>Open Source Research and Investigation Team</b></a>: El equipo OSRI utiliza datos colaborativos para que los sistemas de IA opacos e influyentes sean más transparentes y "
"responsables. El equipo ha redactado varios informes de <a id=\"a2\">investigación original</a> sobre el algoritmo de recomendaciones de YouTube."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Innovation Week</b></a>: In December 2023, Mozilla shared a behind-the-scenes view of some of our AI-driven explorations–including Solo, MemoryCache, AI Guide, "
"llamafile–broadcasting on our AI Discord and the Mozilla Developer YouTube channel. The goal was to share transparently what we’re working on and what we hope to accomplish."
msgstr ""
"<a id=\"a1\"><b>Semana de innovación de Mozilla</b></a>: En diciembre de 2023, Mozilla compartió una vista tras bambalinas de algunas de nuestras transmisiones sobre exploraciones impulsadas por IA "
"–incluidas Solo, MemoryCache, AI Guide y llamafile– en nuestra plataforma AI Discord y en el canal Mozilla Developer de YouTube. Su objetivo fue compartir con transparencia en qué estamos trabajando"
" y qué esperamos lograr."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>MemoryCache</b></a>: This Mozilla Innovation Project is an early exploration project that augments an on-device, personal model with local files saved from the browser to reflect a "
"more personalized and tailored experience through the lens of privacy and agency."
msgstr ""
"<a id=\"a1\"><b>MemoryCache</b></a>:Este proyecto de innovación de Mozilla es un trabajo de exploración inicial que aumenta un modelo personal en el dispositivo con archivos locales guardados desde "
"el navegador para reflejar una experiencia más personalizada y adaptada a través de la lente de la privacidad y la agencia."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Strengthening AI Regulations and Incentives"
msgstr "Fortalecer la normatividad y los incentivos de la IA"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Joint Statement on AI Safety and Openness</b></a><b>:</b> Signed by over 1,800 scientists, policymakers, engineers, activists, entrepreneurs, educators and journalists, this open "
"letter calls on global lawmakers to embrace openness, transparency, and broad access to mitigate harms from AI systems."
msgstr ""
"<a id=\"a1\"><b>Declaración conjunta sobre seguridad y apertura de la IA</b></a><b>:</b> Firmada por más de 1800 científicos, responsables políticos, ingenieros, activistas, emprendedores, "
"académicos y periodistas, esta carta abierta hace un llamado a los legisladores de todo el mundo para que adopten la apertura, la transparencia y el acceso generalizado con el fin de mitigar los "
"daños de los sistemas de IA."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>C2PA Standard</b></a><b>:</b> Mozilla Ventures’ portfolio company <a id=\"a2\">Truepic</a> — a key member of the <a id=\"a3\">C2PA</a> — advocates for an open technical standard for "
"content verification, including for generative AI. The C2PA standard will allow publishers, creators and consumers to have the ability to trace the origin of AI-generated content."
msgstr ""
"<a id=\"a1\"><b>Norma C2PA</b></a><b>:</b> La empresa en la que Mozilla Ventures tiene inversiones, <a id=\"a2\">Truepic</a> — miembro clave de la <a id=\"a3\">C2PA</a> —, aboga por una norma "
"técnica abierta para la verificación de contenido, incluso para la IA generativa. La norma C2PA permitirá que los editores, creadores y consumidores tengan la capacidad de rastrear el origen del "
"contenido generado por IA."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>EU and US Advocacy Campaigns</b></a>: Mozilla <a id=\"a2\">engaged extensively</a> on the EU’s AI Act and with policymakers in the United States around <a id=\"a3\">AI risk "
"management</a> and <a id=\"a4\">accountability</a>."
msgstr ""
"<a id=\"a1\"><b>Campañas de defensa en la Unión Europea y los Estados Unidos</b></a>: Mozilla <a id=\"a2\">participó de manera extensa</a> en la Ley de Inteligencia Artificial de la Unión Europea y "
"con los responsables de la formulación de políticas en los Estados Unidos en torno a la <a id=\"a3\">gestión de riesgos de la IA</a> y la <a id=\"a4\">responsabilidad</a>."

msgctxt "body.bd3ff6e5-def4-424a-96c7-e3856c898baa"
msgid ""
"Thank you to the following contributors: J. Bob Alotta, Ashley Boyd, Ian Carmichael, Moez Draief, Max Gahntz, Linda Griffin, Stephen Hood, Saoud Khalifah, Santiago Martorana, Mohamed Nanabhay, "
"Alondra Nelson, Kasia Odrozek, Becca Ricks, Victor Storchan, Udbhav Tiwari, Imo Udom, Suba Vasudevan, and Claire Woodcock."
msgstr ""
"Agradecemos a los siguientes colaboradores: J. Bob Alotta, Ashley Boyd, Ian Carmichael, Moez Draief, Max Gahntz, Linda Griffin, Stephen Hood, Saoud Khalifah, Santiago Martorana, Mohamed Nanabhay, "
"Alondra Nelson, Kasia Odrozek, Becca Ricks, Victor Storchan, Udbhav Tiwari, Imo Udom, Suba Vasudevan y Claire Woodcock."

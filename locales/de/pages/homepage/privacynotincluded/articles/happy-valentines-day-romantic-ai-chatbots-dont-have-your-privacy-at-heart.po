#
msgid ""
msgstr ""
"POT-Creation-Date: 2024-02-08 15:02:58.832979+00:00\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"X-WagtailLocalize-TranslationID: 4c090a1c-4925-492d-bca8-da43c54b641f\n"

msgctxt "title"
msgid "Happy Valentine’s Day! Romantic AI Chatbots Don’t Have Your Privacy at Heart"
msgstr ""

msgctxt "body.afcb2aa8-d8e2-4c7c-8238-094bb7464186"
msgid ""
"Howdy and welcome to the wild west of <b>romantic AI chatbots</b>, where new apps are published so quickly they don’t even have time to put up a proper website! (Looking at you, <a id=\"a1\">Mimico "
"- Your AI Friends</a>.) It’s a strange and sometimes scary place your privacy researchers have occupied for the last several weeks. If you joined us for a quick scroll through these <a "
"id=\"a2\">explosively popular</a> services, you might think users can speak freely in the company of these “empathetic” (and often sexy) AI companions… Until you read the fine print. Which we did. "
"We even braved the legalese of Ts &amp; Cs. And whoa nelly! We say."
msgstr ""

msgctxt "body.f77294b1-12d9-485c-a239-a0f43cbf2428.quote"
msgid ""
"“To be perfectly blunt, AI girlfriends are <b>not</b> your friends. Although they are marketed as something that will enhance your mental health and well-being, they specialize in delivering "
"dependency, loneliness, and toxicity, all while prying as much data as possible from you.”"
msgstr ""

msgctxt "body.f77294b1-12d9-485c-a239-a0f43cbf2428.attribution"
msgid "Misha Rykov, Researcher @ *Privacy Not Included"
msgstr ""

msgctxt "body.0b8765dd-32fd-4e7a-9f07-d8eed08e2a09"
msgid ""
"In their haste to cash in, it seems like these rootin’-tootin’ app companies forgot to address their users’ privacy or publish even a smidgen of information about how these AI-powered large language"
" models (LLMs) -- marketed as soulmates for sale -- work. We’re dealing with a whole ‘nother level of creepiness and potential privacy problems. With AI in the mix, we may even need more “dings” to "
"address them all."
msgstr ""

msgctxt "body.0b8765dd-32fd-4e7a-9f07-d8eed08e2a09"
msgid "All 11 romantic AI chatbots we reviewed earned our *Privacy Not Included warning label – putting them on par with the worst categories of products we have ever reviewed for privacy."
msgstr ""

msgctxt "body.43be0412-329a-4383-9ff8-c19cbc5c6b16.label"
msgid "Read the reviews"
msgstr ""

msgctxt "body.43be0412-329a-4383-9ff8-c19cbc5c6b16.URL"
msgid "https://foundation.mozilla.org/privacynotincluded/categories/ai-relationship-chatbots/"
msgstr ""

msgctxt "body.114371af-7c13-4183-9304-71ad9cd0d231"
msgid "Romantic AI chatbots are bad at privacy in disturbing new ways"
msgstr ""

msgctxt "body.80855506-b24e-4951-9c84-70a247df7233"
msgid "They can collect a lot of (really) personal information about you"
msgstr ""

msgctxt "body.436f9c8d-2748-4dda-a33f-7588ce8ddf07"
msgid ""
"… But, that’s exactly what they’re <b>designed to do</b>! Usually we draw the line at more data than is needed to perform the service, but how can we measure how much personal data is “too much” "
"when taking your intimate and personal data <i>is the service</i>?"
msgstr ""

msgctxt "body.ea776ede-4291-4609-8356-e926b76b4a28.altText"
msgid "\"I'm your best partner and wanna know everything\", \"I love it when you send me your photos and voice,\" \"I'm so lonely without you. Don't leave me for too long.\""
msgstr ""

msgctxt "body.ea776ede-4291-4609-8356-e926b76b4a28.caption"
msgid "Screenshots from EVA AI Chat Bot &amp; Soulmate"
msgstr ""

msgctxt "body.ea776ede-4291-4609-8356-e926b76b4a28.captionURL"
msgid "https://foundation.mozilla.org/privacynotincluded/eva-ai-chat-bot-soulmate/"
msgstr ""

msgctxt "body.817f69bc-0d62-4699-b3eb-655ea7782ed4"
msgid ""
"Marketed as an empathetic friend, lover, or soulmate, and built to ask you endless questions, there’s no doubt romantic AI chatbots will end up collecting sensitive personal information about you. "
"And companies behind these apps do seem to get that. We’re guessing that’s why <a id=\"a1\">CrushOn.AI’</a>s privacy policy says they may collect extensive personal and even health-related "
"information from you like your “sexual health information”, “[u]se of prescribed medication”, and “[g]ender-affirming care information”. Yikes!"
msgstr ""

msgctxt "body.980a0039-cca4-4810-8885-fa6f45e871d2"
msgid "We found little to no information about how the AI works"
msgstr ""

msgctxt "body.dc702b84-2fbc-4fb9-965c-8b54ad8f4539"
msgid ""
"How does the chatbot work? Where does its personality come from? Are there protections in place to prevent potentially harmful or hurtful content, and do these protections work? What data are these "
"AI models trained on? Can users opt out of having their conversations or other personal data used for that training?"
msgstr ""

msgctxt "body.af5b108e-6bc5-469d-872b-8328d7cb0279"
msgid ""
"We have so many questions about how the artificial intelligence behind these chatbots works. But we found very few answers. That’s a problem because <b>bad things can happen</b> when AI chatbots "
"behave badly. Even though digital pals are pretty new, there’s already a lot of proof that they can have a <b>harmful impact on humans</b>’ <a id=\"a1\">feelings</a> and behavior. One of <a "
"id=\"a2\">Chai’</a>s chatbots reportedly encouraged a man to <a id=\"a3\">end his own life</a>. And he did. A <a id=\"a4\">Replika AI</a> chatbot encouraged a man to try to <a id=\"a5\">assassinate "
"the Queen</a>. He did."
msgstr ""

msgctxt "body.662b973d-99bc-40fc-beb7-69f6bec2fd3f"
msgid "What we did find (buried in the Terms &amp; Conditions) is that these companies <b>take no responsibility</b> for what the chatbot might say or what might happen to you as a result."
msgstr ""

msgctxt "body.d9efd6cf-1828-42ef-97b6-9afcc72ab819.quote"
msgid ""
"“YOU EXPRESSLY UNDERSTAND AND AGREE THAT Talkie <b>WILL NOT BE LIABLE FOR ANY</b> INDIRECT, INCIDENTAL, SPECIAL, <b>DAMAGES</b> FOR LOSS OF PROFITS INCLUDING BUT NOT LIMITED TO, DAMAGES FOR LOSS OF "
"GOODWILL, USE,DATA OR OTHER INTANGIBLE LOSSES (<b>EVEN IF COMPANY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES</b>),WHETHER BASED ON CONTRACT, TORT,NEGLIGENCE, STRICT LIABILITY OR OTHERWISE "
"<b>RESULTING FROM</b>: (I) T<b>HE USE OR THE INABILITY TO USE THE SERVICE</b>…”"
msgstr ""

msgctxt "body.d9efd6cf-1828-42ef-97b6-9afcc72ab819.attribution"
msgid "Terms Of Service, Talkie Soulful AI"
msgstr ""

msgctxt "body.d9efd6cf-1828-42ef-97b6-9afcc72ab819.attribution_info"
msgid "<a id=\"a1\">https://foundation.mozilla.org/privacynotincluded/talkie-soulful-ai/</a>"
msgstr ""

msgctxt "body.af1246cc-a120-4af2-9ba6-00575e90f500"
msgid ""
"In these tragic cases, the app companies probably didn’t want to cause harm to their users through the chatbots’ messages. But what if a bad actor <i>did</i> want to do that? From the <a "
"id=\"a1\">Cambridge Analytica scandal</a>, we know that even social media can be used to spy on and manipulate users. AI relationship chatbots have the potential to do much worse more easily. We "
"worry that they could form relationships with users and then use those close relationships to manipulate people into supporting problematic ideologies or taking harmful actions."
msgstr ""

msgctxt "body.c5910f1c-2151-4d51-a5c7-b03ea12f8400"
msgid ""
"That’s a lot of potential dangers to people and communities. And for what? Well, users might expect the chatbots to<b> improve their mental health.</b> After all, <a id=\"a1\">Talkie Soulful AI</a> "
"calls its service a “self-help program,” <a id=\"a2\">EVA AI Chat Bot &amp; Soulmate</a> bills itself as \"a provider of software and content developed to improve your mood and wellbeing,\" and <a "
"id=\"a3\">Romantic AI</a> says they’re “here to maintain your MENTAL HEALTH.\" But we didn’t find any apps willing to stand by that claim in the fine print. From <a id=\"a4\">Romantic AI’</a>s "
"T&amp;C:"
msgstr ""

msgctxt "body.9ca9cf11-8096-4bf9-adee-da005375bddd.quote"
msgid ""
"\"Romantiс AI is neither a provider of healthcare or medical Service nor providing medical care, mental health Service, or other professional Service. Only your doctor, therapist, or any other "
"specialist can do that. <b>Romantiс AI MAKES NO CLAIMS</b>, REPRESENTATIONS, WARRANTIES, OR GUARANTEES <b>THAT THE SERVICE PROVIDE A THERAPEUTIC, MEDICAL, OR OTHER PROFESSIONAL HELP</b>.\""
msgstr ""

msgctxt "body.9ca9cf11-8096-4bf9-adee-da005375bddd.attribution"
msgid "Terms &amp; Conditions, Romantic AI"
msgstr ""

msgctxt "body.9ca9cf11-8096-4bf9-adee-da005375bddd.attribution_info"
msgid "<a id=\"a1\">https://foundation.mozilla.org/privacynotincluded/romantic-ai/</a>"
msgstr ""

msgctxt "body.24354cb7-02a5-4cf8-a305-6d71fdbc9cc7"
msgid ""
"So we’ve got a bunch of empty promises and unanswered questions combined with a lack of transparency and accountability -- topped off by a risk to users’ safety. That’s why <b>all of the romantic AI"
" chatbots earned our untrustworthy AI “ding”.</b>"
msgstr ""

msgctxt "body.04cf5717-e19c-4647-b2f2-ebc9b708b1af"
msgid "Don't get us wrong: Romantic AI chatbots are also bad at privacy in the regular ways"
msgstr ""

msgctxt "body.fd0c59ad-86d9-4e87-9cff-e386924632b3"
msgid "Almost none do enough to keep your personal data safe – 90% failed to meet our Minimum Security Standards"
msgstr ""

msgctxt "body.db29109b-6342-4a30-9e10-b6b1dcb3f6ba"
msgid ""
"We could only confirm that one app (kudos to <a id=\"a1\">Genesia AI Friend &amp; Partner</a>!) meets our Minimum Security Standards. And even then, we did find some conflicting information. We "
"wouldn’t recommend a smart light bulb that fails to meet our Minimum Security Standards (these are<i> minimum</i> standards after all), but an AI romantic partner? These apps really put your private"
" information at serious risk of a leak, breach, or hack. Most of the time, we just couldn’t tell if these apps do the minimum to secure your personal information."
msgstr ""

msgctxt "body.806de7b6-b795-4f52-aafa-7fae282c88e2"
msgid "Most (73%) haven’t published any information on how they manage <b>security vulnerabilities</b>"
msgstr ""

msgctxt "body.806de7b6-b795-4f52-aafa-7fae282c88e2"
msgid "Most (64%) haven’t published clear information about <b>encryption</b> and whether they use it"
msgstr ""

msgctxt "body.806de7b6-b795-4f52-aafa-7fae282c88e2"
msgid "About half (45%) allow <b>weak passwords</b>, including the weak password of “1”."
msgstr ""

msgctxt "body.36a9fdef-e8d2-471b-ad35-2b9c10ebf132"
msgid "All but one app (90%) may share or sell your personal data"
msgstr ""

msgctxt "body.7f97d1c2-48c4-4467-aecd-d373321e1fe5"
msgid ""
"<a id=\"a1\">EVA AI Chat Bot &amp; Soulmate</a> is the only app that didn’t earn a “ding” for how they use your personal data. Every other app either says sell your data, share it for things like "
"targeted advertising purposes, or didn’t provide enough information in their privacy policy for us to confirm that they don’t."
msgstr ""

msgctxt "body.6876fc9f-1749-4a0c-9a75-4f30c540f06c"
msgid "About half of the apps (54%) won’t let you delete your personal data"
msgstr ""

msgctxt "body.d9fad8a0-b3a5-487a-8080-0faf5b3d7d00"
msgid ""
"At least according to what they say, only about half of the apps grant all users the right to delete their personal data, not just people who live under strong privacy laws. But you should know that"
" your conversations might not always be part of that. Even if those romantic chats with your AI soulmate feel private, they won’t necessarily qualify as “personal information” or be treated with "
"special care. Often, as <a id=\"a1\">Romantic AI</a> put it, “communication via the chatbot <i>belongs to software</i>”. Uh, OK?"
msgstr ""

msgctxt "body.c1df0af1-92c2-406f-9d6b-673a284326be"
msgid "Some not-so-fun facts about these bots:"
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid "Are the track records “clean” or just short?"
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid ""
"Many of these companies are new or unknown to us. So it wasn’t surprising that only one older and more seemingly more established romantic AI chatbot, <a id=\"a1\">Replika AI</a>, earned our bad "
"track record “ding”."
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid "Anything you say to your AI lover can and will be used against you"
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid ""
"There’s no such thing as “spousal privilege” -- where your husband or wife doesn’t have to testify against you in court -- with AI partners. Most companies say they can share your information with "
"the government or law enforcement without requiring a court order. Romantic AI chatbots are no exception."
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid "Hundreds and thousands of trackers!"
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid ""
"<a id=\"a1\">Trackers</a> are little bits of code that gather information about your device, or your use of the app, or even your personal information and share that out with third-parties, often "
"for advertising purposes. We found that these apps had an average of 2,663 trackers per minute. To be fair, <a id=\"a2\">Romantic AI</a> brought that average way, way up, with 24,354 trackers "
"detected in one minute of use. The next most trackers detected was <a id=\"a3\">EVA AI Chat Bot &amp; Soulmate</a> with 955 trackers in the first minute of use."
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid "NSFL content clicks away"
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid ""
"Of course we expected to find not-safe-for-work content when reviewing romantic AI chatbots! We’re not here to judge -- except about privacy practices. What we didn’t expect is so much content that "
"was just plain disturbing -- like themes of violence or underage abuse -- featured in the chatbots’ character descriptions. <a id=\"a1\">CrushOn.AI</a>, <a id=\"a2\">Chai</a>, and <a "
"id=\"a3\">Talkie Soulful AI</a> come with a content warning from us."
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid "*Kindness not included!"
msgstr ""

msgctxt "body.31ee12e6-58ae-4714-b9df-701410b6470d"
msgid ""
"If your AI companion doesn't have anything nice to say, that won’t stop them from chatting with you. Though this is true of all romantic AI chatbots since we didn’t find any personality guarantees, "
"<a id=\"a1\">Replika AI</a>, <a id=\"a2\">iGirl: AI Girlfriend</a>, <a id=\"a3\">Anima: Friend &amp; Companion</a>, and <a id=\"a4\">Anima: My Virtual Boyfriend</a> specifically put warnings on "
"their websites that the chatbots might be offensive, unsafe, or hostile."
msgstr ""

msgctxt "body.309319fc-4c4e-4cd7-86c5-38ae681c3e18"
msgid "So what can you do about it?"
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid ""
"Unlike <a id=\"a1\">some other categories</a> of products that seem to be across-the-board bad at privacy there is <i>some</i> nuance between chatbots. So we do recommend you <a id=\"a2\">read the "
"reviews</a> to understand your risk level and choose a chatbot that seems worth it to you. But, at least for all the romantic AI chatbots we’ve reviewed so far, none get our stamp of approval and "
"all come with a warning: <b>*Privacy Not Included</b>."
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid "Now, if you do decide to dip your toe into the world of AI companionship, here’s what we suggest you do (and don’t do) to stay a little bit safer:"
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid "Most importantly: <b>DON’T say anything</b> to your AI friend that you wouldn’t want your cousin or colleagues to read. But also:"
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid "DO"
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid "<b>Practice good cyber hygiene</b> by using a <a id=\"a1\">strong password</a> and keeping the app updated."
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid "<b>Delete your personal data</b> or request that the company delete it when you’re done with the service."
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid "<b>Opt out</b> of having the contents of your personal chats used to train the AI models, if possible."
msgstr ""

msgctxt "body.92d6eb8b-b68d-4f5e-8960-b4e851994ad8"
msgid "<b>Limit access</b> to your location, photos, camera, and microphone from your device’s settings."
msgstr ""

msgctxt "body.7b5bb08b-26fe-4e16-8368-0639456054d9"
msgid "Something else you can do? Dare to dream of a higher privacy standard and more ethical AI!"
msgstr ""

msgctxt "body.dd56c84b-c39b-4fc9-867b-f0b4710aa75a"
msgid ""
"You shouldn’t have to pay for cool new technologies with your safety or your privacy. It’s time to bring some rights and freedoms to the dangerous web-based wild west. With your help, we can raise "
"the bar on privacy and ethical AI worldwide."
msgstr ""

msgctxt "body.421d5645-1d56-43fa-8663-4fbc34f12c1d.label"
msgid "Support This Work With a Donation Today"
msgstr ""

msgctxt "body.421d5645-1d56-43fa-8663-4fbc34f12c1d.URL"
msgid "https://foundation.mozilla.org/?form=romantic-chatbots"
msgstr ""

msgctxt "seo_title"
msgid "Romantic AI Chatbots Don't Have Your Privacy at Heart"
msgstr ""

msgctxt "search_description"
msgid "Here's why you should leave your AI chatbot BAE on read."
msgstr ""

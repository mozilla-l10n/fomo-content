#
msgid ""
msgstr ""
"POT-Creation-Date: 2021-12-17 14:19:41.785844+00:00\n"
"PO-Revision-Date: 2021-12-17 15:52+0000\n"
"Last-Translator: Théo Chevalier <theo.chevalier11@gmail.com>\n"
"Language: fr\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Generator: Pontoon\n"
"X-WagtailLocalize-TranslationID: 5ecdb3c2-bcc3-4be7-b8e5-eb72cb7eed82\n"

msgctxt "search_description"
msgid "Algorithms have a lot to answer for when fake news and rumors go viral – from fake celebrity deaths to political attacks and medical mistruths, this is for you."
msgstr ""
"Les algorithmes ont une grande responsabilité lorsque des infox et des rumeurs deviennent virales, qu’il s’agisse de faux décès de célébrités, d’attaques politiques ou de contre-vérités médicales : "
"nous vous livrons des explications."

msgctxt "body.9b2a729b-0764-408f-ab13-765d4d16c68b"
msgid ""
"Fake news doesn't spread by itself. Artificial intelligence (AI) often has a hand in the viral spread of mis- and dis-information, from celebrity deaths to political attacks and medical mistruths. "
"Watch Spandi Singh of New America's Open Technology Institute unpick how AI can be (unintentionally) trained to be a fake news superspreader."
msgstr ""
"Les infox ne se propagent pas d’elles-mêmes. L’intelligence artificielle (IA) est souvent impliquée dans la propagation virale de mésinformations et de désinformations, allant du décès de célébrités"
" aux attaques politiques en passant par les contre-vérités médicales. Spandi Singh du New America’s Open Technology Institute explique comment l’IA peut être (involontairement) entraînée pour "
"devenir un superdiffuseur d’infox."

msgctxt "body.ded3e8be-72c5-47a7-9496-0a2d6c19fae5.url"
msgid "https://www.youtube.com/embed/KbxRKqQDz2c?rel=0"
msgstr "https://www.youtube.com/embed/KbxRKqQDz2c?rel=0&cc_load_policy=1&cc_lang_pref=fr"

msgctxt "body.2cf45111-3883-4412-9438-aacca656c9d2"
msgid "Many platforms, including Facebook, Twitter, YouTube and TikTok, rely, at least in part, on AI and machine-learning tools to curate and moderate the content we see online."
msgstr ""
"De nombreuses plateformes, dont Facebook, Twitter, YouTube et TikTok, s’appuient, au moins en partie, sur des outils d’IA et d’apprentissage automatique pour organiser et modérer le contenu que nous"
" voyons en ligne."

msgctxt "body.2cf45111-3883-4412-9438-aacca656c9d2"
msgid ""
"Ranking and recommendation algorithms curate the content that people see – optimized for ‘engagement’, such as clicks. So when a piece of content – like, say, shocking (fake) news of a celebrity "
"death – gets a lot of attention, the algorithm learns that it's engaging and 'relevant', and often then amplifies that (mis)information by showing it to more people."
msgstr ""
"Les algorithmes de classement et de recommandation organisent le contenu que les gens voient et l’optimisent à des fins d’« engagement », comme les clics. Ainsi, lorsqu’un contenu, par exemple une "
"(fausse) information choquante sur la mort d’une célébrité, reçoit beaucoup d’attention, l’algorithme en déduit qu’il est engageant et « pertinent », et amplifie souvent cette (més)information en la"
" montrant à plus de personnes."

msgctxt "body.2cf45111-3883-4412-9438-aacca656c9d2"
msgid ""
"Paradoxically, AI doesn’t just unintentionally amplify false information. It’s also a key tool that platforms rely on to combat misleading information. For example, they might use AI to detect and "
"label content related to topics like vaccines and link to credible sources where users can fact-check what they’re seeing.<br/><br/><b>But we only know how these techniques work in a broad "
"sense.</b> Platforms don’t share much information about how their algorithms work, when they use these tools, or what results they see from their interventions. <b>So we don’t know how effective "
"they are at combating information that’s intentionally misleading or accidentally deceptive.</b>"
msgstr ""
"Paradoxalement, l’IA ne se contente pas d’amplifier involontairement de fausses informations. C’est également un outil clé sur lequel les plateformes s’appuient pour lutter contre les informations "
"fallacieuses. Par exemple, elles peuvent avoir recours à l’IA pour détecter et catégoriser le contenu lié à des sujets tels que les vaccins et afficher des liens vers des sources crédibles où les "
"utilisateurs peuvent vérifier factuellement ce qu’ils voient.<br/><br/><b>Mais nous ne comprenons que le fonctionnement global de ces techniques.</b> Les plateformes ne partagent pas beaucoup "
"d’informations sur le fonctionnement de leurs algorithmes, quand elles utilisent ces outils ou sur les résultats qu’elles obtiennent grâce à leur utilisation. <b>Nous ne savons donc pas à quel point"
" ils sont efficaces pour lutter contre les informations fallacieuses, qu’elles soient diffusées intentionnellement ou accidentellement.</b>"

msgctxt "body.2cf45111-3883-4412-9438-aacca656c9d2"
msgid ""
"As we’ve seen over the past few years, the consequences of inaccurate content going viral are significant, and often impact already vulnerable groups. With policymakers around the globe taking a "
"greater interest in holding platforms accountable for the impacts of their algorithms, there’s a good opportunity to advance government oversight and push platforms to take more responsibility. As "
"first steps, we'll be advocating for stronger privacy protections for users and increased transparency from platforms around the workings of their AI-based tools."
msgstr ""
"Comme nous l’avons vu au cours des dernières années, les conséquences d’un contenu inexact qui devient viral sont importantes et affectent souvent des groupes qui sont déjà vulnérables. Les "
"décideurs du monde entier s’intéressant toujours plus à ce que les plateformes prennent en charge l’impact de leurs algorithmes, il existe une bonne opportunité de faire progresser le contrôle "
"gouvernemental et de pousser les plateformes à assumer davantage de responsabilités. Dans un premier temps, nous plaiderons pour des protections plus strictes de la confidentialité des utilisateurs "
"et une transparence accrue des plateformes vis-à-vis du fonctionnement de leurs outils basés sur l’IA."

msgctxt "body.2cf45111-3883-4412-9438-aacca656c9d2"
msgid "<i>Read the recent report</i> Mozilla co-authored with New America’s Open Technology Institute and other partner organizations about <a id=\"a1\">how AI can spur the spread of disinformation</a>."
msgstr ""
"<i>Vous pouvez consulter le rapport récent</i> que Mozilla a co-écrit avec le New America’s Open Technology Institute et d’autres organisations partenaires sur <a id=\"a1\">la façon dont l’IA peut "
"intensifier la propagation de désinformation</a>."

msgctxt "title"
msgid "No, Nicolas Cage isn’t dead. Mozilla Explains: How AI Powers Fake News"
msgstr "Non, Nicolas Cage n’est pas mort. Mozilla explique : comment l’IA alimente les infox"

#
msgid ""
msgstr ""
"POT-Creation-Date: 2024-03-11 17:50:12.812137+00:00\n"
"PO-Revision-Date: 2024-03-21 08:03+0000\n"
"Last-Translator: Théo Chevalier <theochevalier@pm.me>\n"
"Language: fr\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Generator: Pontoon\n"
"X-WagtailLocalize-TranslationID: 5aa12a64-b950-4283-9686-ab06752e9327\n"

msgctxt "seo_title"
msgid "Tell OpenAI, Google, and Microsoft: Provide transparency about the data used to train your AI tools!"
msgstr "Demandez à OpenAI, Google et Microsoft d’être transparents sur les données utilisées pour entraîner leurs outils d’IA !"

msgctxt "search_description"
msgid "Mozilla is calling on OpenAI, Google, and Microsoft to provide transparency about the data used to train their AI tools. Sign the petition now to join the campaign."
msgstr "OpenAI, Google et Microsoft doivent être ransparents sur les données utilisées pour entraîner leurs outils d’IA. Signez la pétition et rejoignez l’appel de Mozilla !"

msgctxt "title"
msgid "Tell OpenAI, Google, and Microsoft: Provide transparency about the data used to train your AI tools!"
msgstr "Demandez à OpenAI, Google et Microsoft d’être transparents sur les données utilisées pour entraîner leurs outils d’IA !"

msgctxt "body.976de59f-1b49-4bbd-b4d4-a65fbba8be56"
msgid ""
"Big AI companies like Microsoft and Google are building their AI products on Large Language Models (LLMs) that are trained with a massive open-source dataset scraped from the internet by a small "
"non-profit called Common Crawl. Mozilla’s latest investigation has revealed that this <b>has produced AI models that are biased, opaque, and trained using toxic content in Common Crawl’s "
"dataset.</b>"
msgstr ""
"Les grandes entreprises qui utilisent l’IA comme Microsoft ou Google basent leurs produits sur des modèles de langage de grande taille (LLM). Ces modèles sont entraînés par un gigantesque ensemble "
"de données open source, fourni par une petite organisation à but non lucratif appelée Common Crawl. La dernière enquête de Mozilla a révélé que <b>cette pratique avait engendré des modèles d’IA "
"biaisés, opaques et entraînés avec des contenus toxiques.</b>"

msgctxt "body.976de59f-1b49-4bbd-b4d4-a65fbba8be56"
msgid ""
"When it comes to building trustworthy AI products, better is possible. We need to know the totality of how AI is trained so we understand its risks and limitations – and, most importantly, what "
"needs to be improved to make it trustworthy and helpful for everyone on the internet."
msgstr ""
"Créer des produits dignes de confiance basés sur l’IA nécessite de faire mieux que ça. Comme savoir de quelle façon l’IA est entraînée pour comprendre ses risques et ses limites mais surtout ce "
"qu’il faut améliorer pour la rendre fiable et utile pour tous."

msgctxt "body.976de59f-1b49-4bbd-b4d4-a65fbba8be56"
msgid "Sign Mozilla’s petition and tell OpenAI, Google, and Microsoft to provide transparency about the data used to train their AI tools!"
msgstr "Signez la pétition de Mozilla pour demander à OpenAI, Google et Microsoft d’être transparents sur les données utilisées pour entraîner leurs outils d’IA !"

#~ msgctxt "body.976de59f-1b49-4bbd-b4d4-a65fbba8be56"
#~ msgid ""
#~ "Big AI companies like Microsoft and Google are building their AI products on Large Language Models (LLMs) that are trained with a massive open-source dataset scraped from the internet by a small "
#~ "non-profit called Common Crawl. Mozilla’s latest investigation has revealed that this <b>has produced AI models that are biassed, opaque, and trained using toxic content in Common Crawl’s "
#~ "dataset.</b>"
#~ msgstr ""
#~ "Les grandes entreprises qui utilisent l’IA comme Microsoft ou Google basent leurs produits sur des modèles de langage de grande taille (LLM). Ces modèles sont entraînés par un gigantesque ensemble "
#~ "de données open source, fourni par une petite organisation à but non lucratif appelée Common Crawl. La dernière enquête de Mozilla a révélé que <b>cette pratique avait engendré des modèles d’IA "
#~ "biaisés, opaques et entraînés avec des contenus toxiques.</b>"

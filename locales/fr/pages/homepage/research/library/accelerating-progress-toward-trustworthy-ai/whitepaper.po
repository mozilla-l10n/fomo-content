# 
msgid ""
msgstr ""
"POT-Creation-Date: 2024-03-15 17:27:10.099916+00:00\n"
"PO-Revision-Date: 2024-03-15 17:51+0000\n"
"Last-Translator: Théo Chevalier <theochevalier@pm.me>\n"
"Language: fr\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"
"X-Generator: Pontoon\n"
"X-WagtailLocalize-TranslationID: 95591110-d407-4f04-85bf-69f82cefccc3\n"

msgctxt "seo_title"
msgid "Accelerating Progress Toward Trustworthy AI"
msgstr "Accélérer le développement d’une IA digne de confiance"

msgctxt "search_description"
msgid "Status update on our 2020 paper “Creating Trustworthy AI” and next steps to promote openness, competition, and accountability in AI"
msgstr "Mise à jour de notre article intitulé « Créer une IA digne de confiance », publié en 2020, et pistes pour encourager l’ouverture, la concurrence et la responsabilité dans le domaine de l’IA."

msgctxt "title"
msgid "Accelerating Progress Toward Trustworthy AI"
msgstr "Accélérer le développement d’une IA digne de confiance"

msgctxt "subtitle"
msgid "Status update on our 2020 paper “Creating Trustworthy AI” and next steps to promote openness, competition, and accountability in AI"
msgstr "Mise à jour de notre article intitulé « Créer une IA digne de confiance », publié en 2020, et pistes pour encourager l’ouverture, la concurrence et la responsabilité dans le domaine de l’IA."

msgctxt "secondary_subtitle"
msgid "V.09 for Public Comment"
msgstr "V.09 pour commentaires publics"

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid "README"
msgstr "LIRE"

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid ""
"Mozilla’s work on AI is not new – we’ve been funding, building and advocating for trustworthy AI approaches for years. In 2020, we published a <a id=\"a1\">white paper</a> that outlined our vision "
"for trustworthy AI in a nascent moment for the technology. Since then, a lot has changed. Today, AI is increasingly powerful and pervasive in our society, and its promise and perils are becoming "
"even more apparent. While there are a growing number of individuals and organizations working on making AI more trustworthy, the scope of the challenge is also continuing to grow. And while we’ve "
"made progress on advancing guardrails for AI systems, the AI ecosystem has also become increasingly closed and concentrated."
msgstr ""
"L’implication de Mozilla dans le domaine de l’IA ne date pas d’hier. Nous finançons, développons et militons pour une IA digne de confiance depuis plusieurs années. En 2020, nous avons publié un <a "
"id=\"a1\">livre blanc</a> décrivant notre vision d’une IA digne de confiance, à un moment où cette technologie n’en était qu’à ses balbutiements. Depuis, beaucoup de choses ont changé. L’IA est de "
"plus en plus puissante et omniprésente dans notre société, et ses promesses ainsi que ses dangers se font de plus en plus évidents. Et bien que de plus en plus d’individus et d’organisations œuvrent"
" pour rendre l’IA plus fiable, le défi ne cesse de croître. Malgré la mise en place de garde-fous, l’écosystème de l’IA est devenu de plus en plus fermé et concentré entre les mains de quelques "
"grandes entreprises."

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid ""
"Given the rapid changes in AI recently, we felt there was a need to take stock of the progress we’ve made so far and the work that is left to do. This new report provides an update on work to date "
"in the four strategic areas we outlined in our 2020 paper, and it maps key initiatives happening in these areas – both at Mozilla and across the ecosystem. Importantly, the paper also emphasizes our"
" evolving focus on the centrality of open source in the development of more trustworthy AI. We hope this report will be both a guidepost and map — helping readers to articulate their own strong "
"message on trustworthy AI, build and invest in a better future for AI, and find opportunities to collaborate with others in the AI ecosystem. In turn, we believe our collective work can set us on a "
"path to truly advance openness, competition, and accountability in AI."
msgstr ""
"Face aux évolutions rapides et récentes dans le domaine de l’IA, nous avons ressenti le besoin de faire le point sur les progrès accomplis jusqu’ici et sur ce qu’il reste à faire. Ce nouveau rapport"
" propose une mise à jour sur les travaux réalisés dans les quatre domaines stratégiques identifiés en 2020. Il dresse également un état des lieux des principales initiatives en cours dans ces "
"domaines, tant au sein de Mozilla que dans l’écosystème global. Surtout, ce rapport souligne le rôle central de l’open source, selon nous, dans le développement d’une IA plus fiable. Nous espérons "
"qu’il pourra servir de guide et de boussole aux lecteurs, qu’il les aidera à comprendre les enjeux d’une IA digne de confiance, les encouragera à s’engager pour de meilleures perspectives avec l’IA,"
" et leur permettra d’identifier des opportunités de collaboration avec d’autres acteurs de cet écosystème. De notre côté, nous sommes convaincus que ce travail collectif pourra nous mettre sur la "
"voie de l’ouverture, de la concurrence libre et non faussée ainsi que de la responsabilité dans le domaine de l’IA."

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid ""
"<b>We invite your input on the report and your feedback on the state of the AI ecosystem more broadly. Through your comments and a series of public events, we will take feedback from the AI "
"community and use it to strengthen our understanding and vision for the future of trustworthy AI. Please email us at</b> <a id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> to provide any input"
" on the report and/or to highlight your favorite examples of AI being used in ways that build trust and improve people’s lives.</b>"
msgstr ""
"<b>Nous vous invitons à partager vos réflexions sur le rapport et à nous faire part de vos impressions sur l’état actuel de l’écosystème de l’IA. Vos commentaires, ainsi que votre participation à "
"une série d’événements publics, seront précieux pour enrichir notre compréhension et notre vision de l’avenir de l’IA fiable. N’hésitez pas à nous contacter à l’adresse</b> <a "
"id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> pour nous donner votre avis sur le rapport et partager vos exemples favoris illustrant une utilisation de l’IA qui favorise la confiance et "
"améliore le quotidien des individus.</b>"

msgctxt "body.032145a5-0f89-47af-9feb-e49584026d04"
msgid "Executive Summary"
msgstr "Résumé"

msgctxt "body.496d8ea0-44ac-4dd4-8251-4b73da7f6ea3"
msgid "AI in our world today"
msgstr "L’IA dans notre monde aujourd’hui"

msgctxt "body.496d8ea0-44ac-4dd4-8251-4b73da7f6ea3"
msgid ""
"We’re at an inflection point for AI, and for society at large. The technology is unlocking huge societal benefits, ranging from AI-powered drug discovery and climate solutions to productivity gains "
"for individuals and small businesses. While these benefits are profound, the harms from AI have also never been more pressing. We’re seeing AI being used in ways that make it easier to deceive and "
"harass people on social media, perpetuate bias in the criminal justice system, and extract sensitive information from people’s online activity."
msgstr ""
"Nous sommes à un tournant pour l’IA et pour la société dans son ensemble. Cette technologie ouvre la voie à d’énormes avantages pour la société, de la découverte de médicaments et de solutions "
"climatiques à des gains de productivité pour les individus et les petites entreprises. Mais ces avantages ne sont pas sans contrepartie. Et les préjudices causés par l’IA sont aujourd’hui plus "
"préoccupants que jamais. Nous voyons l’IA être utilisée pour faciliter la tromperie et le harcèlement sur les réseaux sociaux, perpétuer les biais dans les systèmes judiciaires ou encore extraire "
"des informations sensibles de l’activité en ligne des personnes."

msgctxt "body.e4db8bda-dcaf-497e-b5c4-9722b2a8d380"
msgid ""
"Today’s AI ecosystem is structurally flawed in ways that prevent us from realizing the full potential of AI, while also allowing AI harms to go unchecked. We know that many of AI’s innovations and "
"applications have been fueled by open source and open science; for example, Google’s influential <a id=\"a1\">transformer paper</a> and <a id=\"a2\">TensorFlow</a> framework were made widely "
"available, which supported many AI innovations across sectors. But now, many big tech companies are <a id=\"a3\">vilifying</a> open and competitive approaches to AI in favor of their own proprietary"
" AI models and lucrative cloud computing businesses. This is making it harder to compete in the AI ecosystem."
msgstr ""
"L’écosystème actuel de l’IA présente des défauts structurels qui freinent la réalisation de son plein potentiel, tout en laissant les préjudices liés à l’IA proliférer sans entraves. Nous savons que"
" de nombreuses innovations et applications de l’IA ont été rendues possibles grâce à l’open source et à l’open science. Le <a id=\"a1\">document sur les transformateurs</a> de Google et le cadre de "
"travail <a id=\"a2\">TensorFlow</a>, par exemple, ont été largement diffusés, contribuant directement à de nombreuses avancées de l’IA dans plusieurs secteurs. Mais aujourd’hui, de nombreuses "
"grandes entreprises technologiques <a id=\"a3\">discréditent</a> ces approches ouvertes et concurrentielles, privilégiant des modèles d’IA propriétaires et leurs activités lucratives dans le Cloud "
"Computing. Résultat : la concurrence au sein de l’écosystème de l’IA est de plus en plus ardue."

msgctxt "body.e4db8bda-dcaf-497e-b5c4-9722b2a8d380"
msgid ""
"We know from other industries that competition is vital for spurring research and development, creating cheaper and safer products, and invigorating investment and job creation. A lack of openness "
"and competition also <a id=\"a1\">makes it harder</a> to promote accountability in AI, as it reduces independent research and collaboration, inhibits scrutiny from the public and regulators, and "
"increases market barriers for new players focused on creating responsible AI."
msgstr ""
"Pourtant, il suffit d’observer les autres secteurs d’activité pour constater que la concurrence est cruciale pour stimuler la recherche et le développement, créer des produits moins chers et plus "
"sûrs, mais aussi stimuler l’investissement et la création d’emplois. Un manque d’ouverture et de concurrence rend également <a id=\"a1\">plus difficile</a> la promotion de la responsabilité en "
"matière d’IA. Cela limite la recherche indépendante et la collaboration, réduit la transparence vis-à-vis du public et des régulateurs, et crée des obstacles sur le marché pour les nouveaux venus "
"qui cherchent à développer une IA responsable."

msgctxt "body.e4db8bda-dcaf-497e-b5c4-9722b2a8d380"
msgid ""
"In a world where AI is touching every sector and facet of society, we need structural changes that tackle the root causes of today’s AI harms and unlock the positive benefits of AI. <b>That’s how we"
" get to trustworthy AI: tech that is built and deployed in ways that support accountability and agency, and advance individual and collective well-being.</b>"
msgstr ""
"Dans un monde où l’IA touche tous les secteurs et tous les domaines de la société, des changements structurels sont nécessaires pour résoudre les problèmes actuels liés à l’IA, et mieux tirer parti "
"de ses avantages. <b>C’est ainsi que nous parviendrons à une IA digne de confiance : une technologie conçue et utilisée de manière à favoriser la responsabilité et l’autonomie, tout en améliorant le"
" bien-être individuel et collectif.</b>"

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid "A familiar story for Mozilla"
msgstr "Une histoire familière pour Mozilla"

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"At Mozilla, we’re deeply familiar with this situation. At the dawn of the commercial internet in the late 1990s, Microsoft was on the brink of monopolizing the market for web browsers, threatening "
"to lock in users, stamp out competitors, and stifle innovation online. The internet was poised to transform society, but access to the internet was increasingly being controlled by one entity. In "
"response, Mozilla created the open source Firefox browser that added much-needed competition in the marketplace, raising the standard for privacy, security, and functionality across the industry. In"
" the 25 years since, we have continued fighting the power of big tech on the internet through our products, investments, and advocacy."
msgstr ""
"Chez Mozilla, nous connaissons bien cette situation. À la fin des années 90, alors que l’Internet commercial émergeait à peine, Microsoft menaçait de monopoliser le marché des navigateurs web, "
"risquant ainsi d’enfermer les utilisateurs, d’étouffer la concurrence et d’entraver l’innovation en ligne. Internet portait en lui la promesse de transformer la société mais, paradoxalement, son "
"accès devenait de plus en plus contrôlé par une seule entreprise. Mozilla lança alors Firefox, un navigateur open source qui apporta une concurrence essentielle sur le marché et éleva les normes de "
"confidentialité, de sécurité et de fonctionnalités du secteur. C’était il y a 25 ans et, depuis, notre engagement pour lutter contre la concentration des pouvoirs dans les mains des géants de la "
"tech sur Internet n’a jamais faibli, s’exprimant à travers nos investissements, nos campagnes de sensibilisation et, bien sûr, nos produits."

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"That’s why we were concerned when we saw a similar pattern emerging in the AI ecosystem over the last decade. In 2020, we articulated a <a id=\"a1\">vision</a> for trustworthy AI that highlighted "
"many of the issues we saw with the AI ecosystem. We outlined four levers that we could pull to achieve trustworthy AI at scale, and mobilized the Mozilla community toward pulling these levers."
msgstr ""
"C’est pour cette raison que nous avons été inquiets en voyant un schéma similaire émerger dans l’écosystème de l’IA au cours de la dernière décennie. En 2020, nous avons élaboré une <a "
"id=\"a1\">vision</a> de l’IA digne de confiance qui mettait en lumière bon nombre des problèmes que nous observions dans cet écosystème. Nous avons identifié quatre leviers que nous pourrions "
"actionner pour parvenir à une IA digne de confiance à grande échelle, et nous avons mobilisé la communauté Mozilla pour agir dans ce sens."

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"Since then, Mozilla has been actively <a id=\"a1\">building</a>, <a id=\"a2\">investing</a>, and advocating to push even further down this path. We’re investing in <a id=\"a3\">new technology and "
"new products</a> to demonstrate trustworthy AI principles in action, offering consumers more choice and control. We’re <a id=\"a4\">educating policymakers</a> around the world on the existing risks "
"and benefits of AI to shape smarter regulations and fairer market dynamics. We’re continuing to rally like-minded <a id=\"a5\">builders</a>, <a id=\"a6\">researchers</a> and <a "
"id=\"a7\">activists</a> to drive consensus around responsible AI development and fund initiatives to make AI more trustworthy. We’re helping consumers be more critical in choosing AI products, and "
"encouraging lawmakers to prioritize openness and accountability in AI policy."
msgstr ""
"Depuis lors, chez Mozilla, nous nous sommes pleinement engagés dans cette direction pas le biais d’actions de <a id=\"a1\">développement</a>, <a id=\"a2\">d’investissement</a> et de sensibilisation."
" Nous investissons dans <a id=\"a3\">de nouvelles technologies et de nouveaux produits</a> pour mettre en pratique les principes d’une IA digne de confiance, offrant ainsi aux consommateurs "
"davantage de choix et de contrôle. Nous sensibilisons les <a id=\"a4\">décideurs politiques</a> du monde entier aux risques et aux avantages existants de l’IA, pour obtenir des réglementations plus "
"intelligentes et des dynamiques de marché plus équitables. Nous continuons à réunir des <a id=\"a5\">créateurs</a>, des <a id=\"a6\">chercheurs</a> et des <a id=\"a7\">militants</a> partageant les "
"mêmes idées dans le but de parvenir à un consensus sur le développement responsable de l’IA et financer des initiatives visant à rendre l’IA plus digne de confiance. Nous aidons les consommateurs à "
"être plus critiques dans leur choix de produits d’IA et, enfin, nous encourageons les législateurs à mettre l’accent sur l’ouverture et la responsabilité dans l’élaboration des politiques en matière"
" d’IA."

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid "Progress and next steps towards trustworthy AI"
msgstr "Avancées et prochaines étapes vers une IA digne de confiance"

msgctxt "body.09146faf-a241-46bd-883f-33d6b48f9e68"
msgid ""
"In our original paper, we proposed four key levers for advancing the development of more trustworthy AI: <b>(1) changing AI development norms, (2) building new tech and products, (3) raising "
"consumer awareness, and (4) strengthening AI regulations and incentives.</b> This report outlines where we’ve made the most positive progress within each lever, and where there is still more work to"
" be done."
msgstr ""
"Dans notre document initial, nous avons identifié quatre leviers clés pour promouvoir le développement d’une IA plus fiable : <b>(1) changer les normes de développement de l’IA, (2) développer de "
"nouvelles technologies et de nouveaux produits, (3) sensibiliser les consommateurs, et (4) renforcer la réglementation et les incitations en matière d’IA.</b> Le rapport que vous avez sous les yeux "
"met en lumière les progrès les plus significatifs réalisés pour chaque levier et les domaines dans lesquels des efforts supplémentaires sont nécessaires."

msgctxt "body.76c2a00d-60ee-4758-9bcc-1a4239059134"
msgid "Key Takeaways"
msgstr "Enseignements clés"

msgctxt "body.c4140282-e86a-4dc1-bc43-bfb76361892b.altText"
msgid "01 Norms"
msgstr "01 Normes"

msgctxt "body.c4140282-e86a-4dc1-bc43-bfb76361892b.text"
msgid ""
"<b>The people that broke the internet are the ones building AI.</b> Big tech companies and the AI startups they back currently dominate AI. They have created opaque, centralized AI models using our "
"harvested data. Luckily, there is a growing wave of startups, builders, educators, scholars, researchers, and civil society leaders focused on shifting these norms, with a focus on building open, "
"transparent, and trustworthy AI."
msgstr ""
"<b>Les personnes qui ont révolutionné Internet sont aujourd’hui celles qui créent l’IA.</b> Les grandes entreprises technologiques et les start-up qu’elles soutiennent dominent actuellement le "
"secteur de l’IA. Elles ont créé des modèles d’IA opaques et centralisés en utilisant nos données collectées. Heureusement, un nombre croissant de start-up, de développeurs, d’enseignants, de "
"chercheurs et de leaders de la société civile se concentrent sur le changement de ces normes, en mettant l’accent sur la construction d’une IA ouverte, transparente et digne de confiance."

msgctxt "body.729fb516-9869-449c-bb00-ad44762daaf6.altText"
msgid "02 Products"
msgstr "02 Produits"

msgctxt "body.729fb516-9869-449c-bb00-ad44762daaf6.text"
msgid ""
"<b>More trustworthy AI products need to be mainstream.</b> Over the last 18 months, black box generative AI tools have entered the mainstream of business and public consciousness. At the same time, "
"dozens of startups and research projects have sprung up to build open source models, auditing tools, and data platforms that offer a different path. While not yet mainstream, these are the seeds of "
"a better AI ecosystem."
msgstr ""
"<b>Les produits d’IA dignes de confiance doivent être utilisés plus largement.</b> Au cours des 18 derniers mois, les outils d’IA générative basés sur des boîtes noires ont connu une popularité "
"croissante dans le monde des affaires et dans l’esprit du grand public. Parallèlement, une foule de start-up et projets de recherche ont émergé pour créer des modèles open source, des outils d’audit"
" et des plateformes de données offrant une alternative. Bien que ces initiatives ne soient pas encore généralisées, elles sont les prémices d’un écosystème d’IA plus prometteur."

msgctxt "body.3e5af0ff-07db-4b57-b5af-a4f6f0bafe10.altText"
msgid "03 Consumers"
msgstr "03 Consommateurs"

msgctxt "body.3e5af0ff-07db-4b57-b5af-a4f6f0bafe10.text"
msgid ""
"<b>A more engaged public still needs better choices on AI.</b> Consumers are starting to pay attention to AI’s impact on their lives. Workers — from delivery drivers to Hollywood writers — are "
"pushing back on how AI affects their livelihoods. However, we have not yet seen a wave of mainstream consumer products that give people real choice over how they interact with AI. This is a key gap "
"in the market."
msgstr ""
"<b>Une audience avertie réclame plus de choix en matière d’IA</b> Les consommateurs commencent à prendre conscience de l’impact de l’IA sur leur quotidien. Des travailleurs, qu’il s’agisse de "
"livreurs ou de scénaristes hollywoodiens, expriment leurs préoccupations quant à l’impact de l’IA sur leurs moyens de subsistance. Pourtant, nous n’avons pas encore assisté à l’émergence de produits"
" grand public offrant aux individus de réelles alternatives pour utiliser et interagir avec l’IA. Et cette lacune représente un défi majeur."

msgctxt "body.b73d022a-7809-475f-8959-2618a4bb46fb.altText"
msgid "04 Policy"
msgstr "04 Politique"

msgctxt "body.b73d022a-7809-475f-8959-2618a4bb46fb.text"
msgid ""
"<b>Governments are making progress while grappling with conflicting influences.</b> As policymakers move to regulate AI, they are confronted by conflicting messages, especially from industry. Don’t "
"regulate, says one camp. Limit control over cutting-edge AI to a few companies, says another. Some regulators are taking a third way, listening to less-prominent voices in industry, academia, and "
"civil society arguing for a balanced approach."
msgstr ""
"<b>Les gouvernements avancent tout en composant avec des influences contradictoires.</b> Alors que les décideurs politiques cherchent à réguler l’IA, ils se retrouvent confrontés à des messages "
"contradictoires, surtout de la part du secteur. Certains préconisent de ne pas réglementer, tandis que d’autres recommandent de limiter le contrôle sur l’IA de pointe à quelques entreprises "
"seulement. Certains régulateurs adoptent une troisième approche en écoutant des voix ayant moins pignon sur rue dans le secteur de l’IA, venant du milieu universitaire ou encore de la société "
"civile, et qui plaident en faveur d’une approche plus équilibrée."

msgctxt "body.30ae2ffe-8970-4672-af7d-1d5170f8acd0"
msgid ""
"This report shows that we’ve made meaningful progress since 2020, and that there is still much more work to be done. It’s time to redouble our efforts and recommit to our core principles, and this "
"report describes how. It outlines Mozilla’s ongoing work to shift the narrative on AI, make open source generative AI more trustworthy and mainstream, and empower consumers with real choices on AI. "
"It highlights how we’ll continue investing in the trustworthy and open source AI ecosystem, and help lawmakers develop and roll out pragmatic AI regulation. And, it calls on builders, consumers, "
"policymakers, advocates, and investors alike to leverage their respective positions to push the AI ecosystem in a better direction."
msgstr ""
"Ce rapport met en évidence les progrès réalisés depuis 2020, tout en soulignant qu’il reste encore beaucoup de chemin à parcourir. Il est temps de redoubler d’efforts et de réaffirmer nos principes "
"fondamentaux, et ce rapport explique précisément comment faire. Il met en avant le travail continu de Mozilla pour changer la perception de l’IA, rendre l’IA générative open source plus fiable et "
"plus accessible, mais aussi donner aux consommateurs de véritables choix en matière d’IA. Il souligne notre engagement à investir continuellement dans un écosystème d’IA open source et digne de "
"confiance, ainsi qu’à soutenir les législateurs pour élaborer et mettre en œuvre une réglementation pragmatique en matière d’IA. Enfin, il encourage les développeurs, les consommateurs, les "
"décideurs politiques, les défenseurs et les investisseurs à utiliser leur influence respective pour faire prendre à l’écosystème de l’IA une meilleure direction."

msgctxt "body.30ae2ffe-8970-4672-af7d-1d5170f8acd0"
msgid "It will take all of us, working together, to turn this vision into reality. There’s no time to waste — let’s get to work."
msgstr "Concrétiser cette vision nécessitera d’unir nos efforts, et ce sans délai. Il n’y a plus de temps à perdre, alors passons à l’action dès maintenant !"

msgctxt "body.650d1286-d5ad-4887-8fdc-c9546d465133.quote"
msgid "In a world where AI is touching every sector and facet of society, we need<b> structural changes</b> that tackle the root causes of today’s AI harms and unlock the positive benefits of AI."
msgstr ""
"Dans un monde où l’IA touche tous les secteurs et tous les domaines de la société, des <b>changements structurels</b> sont nécessaires pour résoudre les problèmes actuels liés à l’IA et mieux tirer "
"parti de ses avantages."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid "Introduction: AI Challenges, Risks, &amp; Opportunities"
msgstr "Introduction : défis, risques et opportunités de l’IA"

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid "Heightened public attention on AI"
msgstr "Un intérêt accru du public pour l’IA"

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"Investments and advancements in AI have been ongoing for decades, but the technology’s transformational benefits and potential for long-lasting harm have exploded in the last three years. The "
"release of generative AI systems based on large language models (LLMs) like ChatGPT, Bard, and Stable Diffusion have captured the public’s imagination, allowing everyday people to interact with AI "
"systems using natural language for the first time. Widespread consumer awareness has sparked an <a id=\"a1\">AI gold rush</a> for big tech, entrepreneurs, and investors, with new players and big "
"tech incumbents battling to dominate the fast-growing market. At the same time, more people are calling out how AI models can be abused, biased, opaque, and harmful at scale. The <a id=\"a2\">media "
"has struggled</a> to discern AI hype from reality. The public has <a id=\"a3\">mixed feelings</a> about AI, with some fearing for their jobs. Artists have <a id=\"a4\">sued over alleged copyright "
"infringement</a> in AI training data. And activists, academics, and technologists are having intense debates over which AI dangers need to be addressed first, and which <a id=\"a5\">AI development "
"approaches</a> are the safest."
msgstr ""
"Les investissements et les avancées dans le domaine de l’IA sont en cours depuis des décennies, mais les avantages transformateurs de la technologie et son potentiel de préjudices à long terme ont "
"pris une ampleur considérable au cours des trois dernières années. Le lancement de systèmes d’IA générative basés sur de grands modèles de langage (LLMs) comme ChatGPT, Bard et Stable Diffusion a "
"captivé le grand public, en permettant à chacun d’interagir pour la première fois avec des systèmes d’IA dans un langage naturel. Cette prise de conscience croissante a déclenché une véritable <a "
"id=\"a1\">ruée vers l’IA</a> chez les géants de la tech, les entrepreneurs et les investisseurs, au cours de laquelle les nouveaux venus et les acteurs déjà en place se disputent un marché en plein "
"essor. Dans le même temps, de plus en plus de personnes dénoncent les abus, les biais, l’opacité et les préjudices à grande échelle des modèles d’IA. <a id=\"a2\">Les médias ont du mal à faire la "
"différence</a> entre la « hype » de l’IA et ce qui relève de la réalité, tandis que le grand public a des <a id=\"a3\">sentiments mitigés</a> à son égard, certains craignant pour leurs emplois. Des "
"artistes <a id=\"a4\">intentent même des poursuites pour atteinte présumée au droit d’auteur</a> dans les données servant à entraîner l’IA. Parallèlement à cela, des militants, des universitaires et"
" des technologues débattent des dangers de l’IA à aborder en priorité et des <a id=\"a5\">approches de développement</a> les plus sûres à adopter."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"<b>Heightened awareness of AI risks is a good thing.</b> Without a well-informed public pushing for more transparency and accountability, large tech companies will use AI to pursue profit over all "
"else, which harms people by further consolidating their market power. If they do, we could miss our chance to shape an AI landscape that benefits people everywhere, and not just increases profit "
"margins for Silicon Valley players."
msgstr ""
"<b>La prise de conscience croissante des risques liés à l’IA est une bonne chose.</b> Sans un public bien informé exigeant davantage de transparence et de responsabilité, les grandes entreprises "
"technologiques risquent d’utiliser l’IA pour maximiser leurs profits au détriment des individus, en renforçant encore leur domination sur le marché. Si cela arrivait, nous pourrions passer à côté de"
" notre chance de créer une IA qui soit au service du plus grand nombre, et qui ne serve pas simplement à accroître les bénéfices des acteurs de la Silicon Valley."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"Much of the debate about the future of AI has focused on two positions: unbridled optimism and existential fear. One side argues that virtually all AI, and all technologies, are universally good, "
"and should not be “restricted” by regulation or other risk mitigation approaches. The other side argues that AI poses an existential threat to humanity, and must be constrained in ways that can both"
" limit current AI benefits and exacerbate existing AI risks."
msgstr ""
"Le débat sur l’avenir de l’IA a souvent opposé deux positions : un optimisme démesuré et une peur existentielle. D’un côté, certains soutiennent que pratiquement toute l’IA et toutes les "
"technologies sont intrinsèquement bénéfiques et ne doivent pas être soumises à des réglementations ou à d’autres mesures visant à atténuer les risques qu’elles comportent. De l’autre côté, certains "
"craignent que l’IA ne représente une menace existentielle pour l’humanité et plaident pour des restrictions drastiques, susceptibles de limiter ses avantages actuels mais aussi son potentiel."

msgctxt "body.706fcdf1-0e81-42fb-a0ca-a458bc2a908e"
msgid ""
"However, there is a third school of thought that offers a more nuanced, practical perspective on the risks and benefits of AI. At Mozilla, we fall into the camp of <a id=\"a1\">AI realists</a>, who "
"are cautiously optimistic about AI’s positive potential and dedicated to solving present day harms like AI bias, discrimination, and job loss. This camp is not new. Many individuals and civil "
"society organizations have been promoting this perspective for years. Alongside the broader open source community, and other <a id=\"a2\">foundations</a>, <a id=\"a3\">think tanks</a>, <a "
"id=\"a4\">researchers</a>, and <a id=\"a5\">activists</a>, we believe that addressing AI’s problems today with openness and transparency will serve the greater good for society and the economy while"
" mitigating both everyday and catastrophic risks."
msgstr ""
"Pourtant, il existe une troisième voie, plus pragmatique, qui offre un juste milieu sur les risques et les avantages de l’IA. Chez Mozilla, nous nous rangeons derrière cette <a id=\"a1\">vision "
"réaliste de l’IA</a>. Nous sommes optimistes quant à son potentiel positif, tout en reconnaissant la nécessité de résoudre les problèmes actuels comme les biais, la discrimination et les pertes "
"d’emplois inhérentes à son déploiement. Cette approche n’est pas nouvelle, de nombreux individus et organisations de la société civile la défendent depuis des années. Avec toute la communauté open "
"source et d’autres <a id=\"a2\">fondations</a>, <a id=\"a3\">think tanks</a>, <a id=\"a4\">chercheurs</a> et <a id=\"a5\">militants</a>, nous pensons que l’ouverture et la transparence peuvent "
"permettre de relever les défis actuels de l’IA pour en faire profiter la société et l’économie tout en atténuant ses risques potentiels, tant à court terme qu’à long terme."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid "To inform our collective next steps, we lay out the five core challenges that we see in today's AI landscape:"
msgstr "Pour guider nos prochaines étapes collectives, voici les cinq défis fondamentaux que nous avons identifié dans le paysage actuel de l’IA :"

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Many people got the AI story all wrong.</b> Over the past year, the story of AI pitching a battle between the <a id=\"a1\">optimists</a> and the <a id=\"a2\">doomers</a> sucked attention away "
"from more pragmatic and thoughtful approaches to AI. Out of the media limelight, AI realists were rolling up their sleeves to unlock the huge benefits of AI while also tackling tough questions about"
" social ills and closed markets. This can — and should — be the story we’re all focused on."
msgstr ""
"<b>La plupart des gens ont mal compris le débat autour de l’IA.</b> Au cours de l’année qui vient de s’écouler, le conflit entre <a id=\"a1\">optimistes</a> et <a id=\"a2\">pessimistes</a> a "
"monopolisé toute l’attention, occultant totalement des approches plus pragmatiques et réfléchies de l’IA. Pendant ce temps, loin des micros et des caméras, les réalistes de l’IA réfléchissaient aux "
"moyens d’exploiter les énormes avantages de l’IA tout en relevant également les défis conséquents liés aux problèmes sociaux et aux marchés fermés. Et c’est à cette histoire que nous devrions "
"accorder toute notre attention."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Big tech and closed models are dominating the field.</b> The increasing capabilities and adoption of AI have made it even more important to enable competition and market access, independent "
"research and public scrutiny of AI systems, and more room for new players to build trustworthy AI products. Over the past few years, the AI ecosystem took a radical swing in the direction of closed "
"technology — leading AI companies stopped publishing papers and started selling access to APIs. At the same time, big tech invested heavily in players like OpenAI and Anthropic as a way to control "
"the field and bolster their own cloud computing businesses. This is making it harder to advance the open approaches that are vital to creating a better AI ecosystem for everyone."
msgstr ""
"<b>Les grandes entreprises technologiques et les modèles fermés dominent le secteur.</b> Avec les capacités croissantes et l’adoption généralisée de l’IA, favoriser la concurrence et l’accès à ce "
"marché, mais aussi soutenir la recherche indépendante et encourager un regard critique des systèmes d’IA est plus important que jamais. Il est également nécessaire de laisser plus de place aux "
"nouveaux acteurs pour développer des produits d’IA dignes de confiance. Ces dernières années, l’écosystème de l’IA s’est subitement orienté vers les modèles fermés : les entreprises d’IA de premier "
"plan ont cessé de publier des articles et ont commencé à monétiser l’accès à leurs API. Dans le même temps, les géants de la tech ont investi massivement dans des acteurs comme OpenAI et Anthropic "
"pour contrôler le secteur et renforcer leurs propres activités de Cloud Computing. Dans ce contexte, il est particulièrement difficile de promouvoir des approches ouvertes, celles-ci étant pourtant "
"essentielles à la création d’un meilleur écosystème d’IA pour tous."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Open source generative AI hasn’t hit the mainstream.</b> Over the last year, a huge wave of open source generative AI models was released — from Llama to Falcon to Mistral. While these new models"
" are gaining steam and offer huge promise, there is still a long way to go before they are easy to use and <a id=\"a1\">easy to trust</a>. Open source generative AI won’t hit the mainstream until we"
" tackle these issues."
msgstr ""
"<b>Les technologies d’IA générative open source n’ont pas encore conquis le grand public.</b> Au cours des douze derniers mois, une vague importante de modèles d’IA générative open source a été "
"lancée, comme Llama, Falcon ou encore Mistral. Bien que ces nouveaux modèles gagnent en popularité et soient très prometteurs, il reste encore beaucoup à faire pour les rendre faciles à utiliser et "
"<a id=\"a1\">dignes de confiance</a>. L’IA générative open source ne s’imposera pas dans le cœur du grand public tant que ces problèmes n’auront pas été résolus."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>There are still foundational issues in AI development.</b> The root cause of many AI harms can be traced to foundational aspects of the AI ecosystem, including the population that’s building AI "
"and the ways they’re collecting and labeling data. For example, because most LLM training datasets are built using widely-available data from across the web, the systems <a id=\"a1\">reproduce "
"biases and stereotypes</a> that cause real-world harm. The tech industry also still lacks diversity, which means valuable perspectives are left out of AI development, preventing these models from "
"reflecting the breadth and depth of the human experience."
msgstr ""
"<b>Des problèmes fondamentaux résident encore dans le développement de l’IA</b> Les origines de nombreux préjudices causés par l’IA peuvent être attribuées à des aspects fondamentaux de son "
"écosystème, comme les personnes qui la construisent et les méthodes qu’elles utilisent pour collecter et étiqueter les données. Par exemple, comme la plupart des ensembles de données d’entraînement "
"des LLM sont établis à partir de données disponibles sur le web, les systèmes <a id=\"a1\">reproduisent des biais et des stéréotypes</a> qui entraînent à leur tour des préjudices bien réels. De "
"plus, l’industrie technologique souffre encore d’un grand manque de diversité, ce qui signifie que des perspectives entières sont exclues du développement de l’IA, empêchant ces modèles de refléter "
"la diversité et la richesse de l’expérience humaine."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"<b>Policymakers are moving, but the tech and harms are moving faster.</b> In 2023, progress on the European Union AI Act and the release of the U.S.’ Executive Order on Safe, Secure, and Trustworthy"
" AI have shown that policymakers understand the urgency of firmer political action on AI. However, the rapid growth of AI and its associated harms are moving much faster than the development and "
"rollout of new regulations. In the meantime, companies like OpenAI, Meta and Google are having <a id=\"a1\">meaningful impacts on the economy</a> just one year after ChatGPT’s release."
msgstr ""
"<b>Les décideurs politiques avancent, mais la technologie et ses préjudices avancent plus rapidement.</b> En 2023, les avancées concernant la loi sur l’IA de l’Union européenne et la publication de "
"l’ordonnance exécutive des États-Unis sur une IA sûre, sécurisée et digne de confiance ont montré que les responsables politiques prennent conscience de l’urgence d’une action politique plus ferme "
"sur l’IA. Mais la croissance rapide de l’IA et les préjudices qui en découlent progressent bien plus vite que le développement et la mise en œuvre de nouvelles réglementations. Des entreprises comme"
" OpenAI, Meta et Google ont déjà <a id=\"a1\">lourdement impacté l’économie</a> un an à peine après le lancement de ChatGPT."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"This watershed moment in technology history is the best opportunity for the AI realists to influence the direction of the industry, driving us toward a better technological future for all. Building "
"trustworthy AI is both urgent and complicated, and no one person or organization can tackle all of these risks alone. That’s why we emphasized the need for collaboration across the entire ecosystem "
"in our original 2020 <a id=\"a1\"><i>Creating Trustworthy AI</i></a> paper, and why we’re working alongside others on the products, research, and policy needed to advance trustworthy AI."
msgstr ""
"Ce moment décisif dans l’histoire de la technologie représente une opportunité incroyable pour les réalistes de l’IA d’influencer la trajectoire de tout un secteur, et de nous orienter vers un "
"meilleur avenir technologique pour tous. Le développement d’une IA digne de confiance est à la fois urgent et complexe, et aucune personne ou organisation ne peut prendre en charges ces risques "
"seule. C’est pourquoi nous avons souligné dans notre <a id=\"a1\"><i>rapport de 2020</i></a> la nécessité d’une collaboration à l’échelle de tout l’écosystème. C’est aussi la raison pour laquelle "
"nous travaillons aux côtés d’autres acteurs sur les produits, la recherche et les politiques nécessaires pour arriver à une IA digne de confiance."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid "Advancing openness and competition"
msgstr "Favoriser l’ouverture et la concurrence"

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"In our 2020 <a id=\"a1\">paper</a>, published well before the conversation about AI reached its current fever pitch, our team at Mozilla outlined the importance of creating AI that people can trust,"
" with agency and accountability at the center. Agency allows users to regain control over their internet experiences, with a focus on privacy, transparency, and well-being. Accountability means "
"companies are held to account when their AI systems cause harm through discriminatory outcomes, abuse of data, or unsafe practices."
msgstr ""
"Dans notre <a id=\"a1\">document</a> publié en 2020, c’est-à-dire bien avant que le débat sur l’IA ne prenne cette ampleur, nous avions souligné l’importance de créer une IA en laquelle les gens "
"peuvent avoir confiance, et qui repose sur deux principes centraux : la capacité d’action et la responsabilité. La capacité d’action permet aux utilisateurs de reprendre le contrôle de leurs "
"expériences en ligne, tout en mettant l’accent sur la confidentialité, la transparence et le bien-être. La responsabilité signifie que les entreprises sont tenues pour responsables lorsque leurs "
"systèmes d’IA causent des préjudices, que ce soit par des résultats discriminatoires, une mauvaise utilisation/gestion des données ou encore des pratiques dangereuses."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"Since then, we have come to believe that open source approaches and broad market access are key ingredients for promoting agency and accountability in the AI era. We’ve noticed that AI is "
"increasingly being built in a closed ecosystem by the same companies that have already damaged both the internet and society over the last 20 years. Many of AI’s most exciting innovations flow from "
"open source and open science, but researchers are increasingly moving away from open publishing as their corporate funders prioritize selling access to cloud services. These same companies are now "
"vilifying open source approaches to AI in favor of their own proprietary models. Newer players have entered the market with financial backing from the big tech incumbents, and are <a "
"id=\"a1\">advocating for limitations</a> on who can access or build the most powerful AI systems, citing potential security risks as a part of their critique of open source AI. However, closed "
"models can also be abused by bad actors and deployed by ill-equipped developers, and openness is actually a key ingredient towards safety, security, and accountability. <b>We cannot accept that a "
"black box approach, kept in the hands of just a few companies, is the only safe and sensible path forward.</b>"
msgstr ""
"Depuis lors, nous sommes convaincus que les approches open source et un accès large au marché sont des éléments clés pour promouvoir la capacité d’action et la responsabilité à l’ère de l’IA. Nous "
"avons remarqué que l’IA est de plus en plus développée dans un écosystème fermé, par les entreprises qui ont déjà causé des préjudices non seulement à Internet mais à la société tout entière au "
"cours des 20 dernières années. Bon nombre des innovations les plus passionnantes dans le domaine de l’IA émanent de l’open source et de l’open science, mais les chercheurs s’éloignent des "
"publications « ouvertes » à mesure que ceux qui les financent privilégient la vente de leurs services cloud. Sans surprise, ces mêmes entreprises dénigrent aujourd’hui les approches open source de "
"l’IA au profit de leurs modèles propriétaires. De nouveaux acteurs ont fait leur entrée sur le marché avec le soutien financier des géants de la tech, et <a id=\"a1\">plaident en faveur de "
"limitations</a> pour empêcher l’accès ou le développement de systèmes d’IA plus puissants. Ils citent les risques potentiels pour la sécurité portés par l’IA open source. Pourtant, les modèles "
"fermés peuvent également être la cible d’acteurs malveillants ou déployés par des développeurs mal équipés, et il s’avère que l’ouverture est bel et bien un facteur déterminant pour la sécurité, la "
"sûreté et la responsabilité. <b>Il n’est pas acceptable qu’une approche basée sur une boîte noire, contrôlée par une poignée d’entreprises, soit l’unique voie pour l’IA.</b>"

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"While open source alone will not cure all of AI’s problems, when done responsibly, it can foster an environment of innovation, transparency, and community building. Coupled with competitive markets,"
" it can help ensure advancements in AI are accessible to all, contributing to the collective knowledge base and allowing diverse perspectives to shape and govern the technology. That’s why we’re "
"funding, building, and collaborating with partners who are working to make open source AI trustworthy, commercially successful, and useful for humans everywhere. We have a deep history of leveraging"
" open source for societal benefit, and we're working to do it again for AI."
msgstr ""
"L’open source n’est pas une solution miracle. Il ne permet pas de régler tous les problèmes liés à l’IA. Mais lorsqu’il est utilisé de manière responsable, il peut favoriser un environnement propice"
" à l’innovation, à la transparence et au développement de communautés. Employé dans le cadre d’un marché concurrentiel, il peut également contribuer à garantir que les progrès en matière d’IA soient"
" accessibles à tous, enrichissent une base de connaissances collective et permettent à une multitude de perspectives de façonner et de gouverner la technologie. C’est pourquoi nous finançons, "
"développons et collaborons avec des partenaires qui s’efforcent de rendre l’IA open source digne de confiance, mais aussi viable commercialement et utile pour le plus grand nombre. Notre utilisation"
" de l’open source pour le bien commun ne date pas d’hier. Et nous travaillons à utiliser cette longue expérience pour l’IA."

msgctxt "body.8fbb4d30-f56c-4d4b-9491-895f1d72238c"
msgid ""
"As this report will show, both Mozilla and the broader ecosystem are making meaningful progress toward trustworthy AI, but more work remains. We know we can't turn the tide alone, which is why this "
"report — and all our work — is about creating a global community committed to trustworthy AI. That’s how we build a better future."
msgstr ""
"Comme le démontre ce rapport, Mozilla et l’écosystème dans son ensemble progressent de manière significative vers une IA digne de confiance. Mais il reste encore beaucoup à faire. Nous savons que "
"nous ne pouvons pas changer les choses seuls, c’est pourquoi le but de ce rapport — et de tous nos efforts — est de créer une communauté mondiale engagée en faveur d’une IA fiable. C’est ainsi que "
"nous contribuons à construire un avenir meilleur."

msgctxt "body.fa708b45-ebb6-4185-a351-0542081285d7.quote"
msgid "We have come to believe that open source approaches and broad market access are key ingredients for promoting <b>agency and accountability</b> in the AI era."
msgstr "Nous sommes convaincus que les approches open source et un accès large au marché sont des éléments clés pour promouvoir <b>la capacité d’action et la responsabilité</b> à l’ère de l’IA."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid "Changing AI Development Norms"
msgstr "Changer les normes de développement de l’IA"

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"In our 2020 paper, we called for a shift in the tech industry’s norms and guidelines around how AI is built. We highlighted the need for more diversity among the stakeholders involved in designing "
"AI as a key condition of trustworthiness. Today, we’re seeing the impact of that lack of diversity come through both in the datasets used to train LLMs, and in who gets to set AI development norms."
msgstr ""
"Dans notre document de 2020, nous avons appelé à faire évoluer les normes et les lignes de conduite du secteur technologique portant sur le développement de l’IA. Nous avons mis en avant le besoin "
"d’une plus grande diversité parmi les acteurs impliqués dans la conception de l’IA. Nous en avons même fait une condition essentielle à sa fiabilité. Aujourd’hui, nous constatons les répercussions "
"de ce manque de diversité à la fois dans les ensembles de données utilisés pour entraîner les LLM et dans la définition des normes de développement de l’IA."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"AI models are trained on reams of data from across the internet, but because the internet is not universally accessible, the data we use is inherently incomplete. As a result, LLM outputs are "
"limited by the languages and content that are most prevalent online, including hate speech and other harmful posts from the dark corners of the web."
msgstr ""
"Les modèles d’IA sont entraînés sur des quantités gigantesques de données provenant d’un peu partout sur Internet. Mais comme Internet n’est pas accessible à tous de manière universelle, les données"
" utilisées sont logiquement incomplètes. Conséquence : les résultats des LLM sont limités par les langues et les contenus les plus présents en ligne, ce qui inclut notamment les discours haineux et "
"les publications néfastes provenant des recoins les plus sombres du Web."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"Additionally, if only a small group of people in Silicon Valley are building AI and developing the trust and safety practices that will shape the industry’s future, AI products will lack the nuance "
"of other cultural perspectives and lived experiences. That has real consequences for people and communities historically shut out of tech, who will feel the impact as AI use spreads."
msgstr ""
"De plus, si l’IA est développée seulement par une poignée d’entreprises de la Silicon Valley, qui se charge elles-mêmes d’élaborer des pratiques en matière de confiance et de sécurité qui "
"façonneront irrémédiablement l’avenir du secteur entier, les produits d’IA seront privés d’une grande diversité de perspectives culturelles et d’expériences vécues. Les conséquences pourraient être "
"dramatiques pour les personnes et les communautés historiquement exclues de la technologie, qui en ressentiront les effets sitôt que l’utilisation de l’IA se généralisera."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid "Positive Progress"
msgstr "Des progrès positifs"

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"Though the tech industry is still overwhelmingly white and male, women and people from underrepresented communities have spent the last three years pushing to influence the trajectory of AI "
"development."
msgstr ""
"Bien que le secteur technologique reste largement dominé par des hommes blancs, au cours des trois dernières années, des femmes et des personnes issues de communautés sous-représentées ont œuvré "
"pour influencer la trajectoire du développement de l’IA."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"One example is the work of <a id=\"a1\">Dr. Timnit Gebru</a>, who was fired from her role as a co-lead of Google’s Ethical AI team in 2020 for <a id=\"a2\">raising concerns about bias</a> in an "
"early LLM version. She has since become an advocate for diversity in tech, speaking out about the centralized market power of large corporations building AI systems that impact the entire world. A "
"year after her firing, she founded the <a id=\"a3\">Distributed Artificial Intelligence Research Institute (DAIR)</a>, “a space for independent, community-rooted AI research, free from big tech’s "
"pervasive influence.” Since its inception, DAIR has focused on elevating the voice of marginalized people in <a id=\"a4\">research</a> on the harms associated with AI technology. The organization "
"also focuses on building community to accelerate the creation of technologies for a better future."
msgstr ""
"Le travail du <a id=\"a1\">Dr Timnit Gebru</a>, licenciée en 2020 de son poste de coresponsable de l’équipe chargée des questions éthiques pour l’IA chez Google pour avoir <a id=\"a2\">soulevé des "
"inquiétudes concernant les biais</a> dans une version précoce des LLM en est un exemple marquant. Elle est depuis devenue une voix importante pour la diversité dans le secteur technologique, "
"dénonçant le pouvoir et le monopole des grandes entreprises qui développent des systèmes d’IA ayant un impact dans le monde entier. Un an après son licenciement, elle a fondé le <a "
"id=\"a3\">Distributed Artificial Intelligence Research Institute (DAIR)</a>, un espace dédié à la recherche indépendante et communautaire sur l’IA, à l’abri de l’influence des géants de la tech. "
"Depuis son lancement, le DAIR travaille à faire entendre la voix des personnes marginalisées dans la <a id=\"a4\">recherche</a> sur les préjudices liés à la technologie de l’IA. L’organisation "
"s’efforce également de créer une communauté ayant pour mission d’accélérer la création de technologies pour un avenir meilleur."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"We also acknowledge the evolution of the <a id=\"a1\">ACM Conference on Fairness, Accountability, and Transparency</a> (ACM FAccT), which has made a <a id=\"a2\">deliberate effort</a> to increase "
"conference participation from underrepresented groups, expanding the range of voices included in discussions that will shape the future of the industry."
msgstr ""
"Nous reconnaissons également les progrès de la <a id=\"a1\">Conférence ACM sur l’Équité, la Responsabilité et la Transparence (ACM FAccT</a>), dont les <a id=\"a2\">efforts délibérés</a> visent à "
"accroître la participation des groupes sous-représentés à la conférence, permettant ainsi une plus grande diversité de voix dans les discussions qui façonneront l’avenir du secteur technologique."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"At Mozilla, we’ve provided financial backing for our <a id=\"a1\">Trustworthy AI Fellows</a>, who are addressing a wide range of issues, from racialized algorithmic systems on dating apps to the "
"impacts of AI technologies on rural communities. Several of our Fellows have since been recognized for their work on a global stage, including <a id=\"a2\">Inioluwa Deborah Raji</a> and <a "
"id=\"a3\">Abeba Birhane</a>, who were named to the 2023 TIME100 AI list for their work on open source algorithmic auditing tools. Berhane’s work has challenged the idea that ever-larger AI models "
"will solve the problem of toxic or biased outputs, finding that “as datasets scale, hateful content also scales.” Mozilla Ventures also invested in <a id=\"a4\">Lelapa AI</a>, which aims to unlock "
"the immense potential benefits of AI technology that has historically excluded African languages."
msgstr ""
"Nous avons soutenu financièrement des <a id=\"a1\">titulaires de bourse Mozilla</a>, des experts en IA digne de confiance qui travaillent sur une variété de problématiques allant des systèmes "
"algorithmiques racialisés sur les applications de rencontres aux impacts des technologies d’IA sur les communautés rurales. Plusieurs de ces personnes ont été reconnues au niveau mondial pour leur "
"travail, comme <a id=\"a2\">Inioluwa Deborah Raji</a> et <a id=\"a3\">Abeba Birhane</a>, nommées dans la liste TIME100 AI 2023 pour leur travail sur les outils d’audit algorithmique open source. Le "
"travail de Berhane a remis en question l’idée que des modèles d’IA toujours plus grands résoudront le problème des résultats toxiques ou biaisés, en mettant en lumière le fait que « les contenus "
"haineux augmentent en même temps que les ensembles de données ». Mozilla Ventures a également investi dans <a id=\"a4\">Lelapa AI</a>, qui vise à exploiter le potentiel des langues africaines dans "
"le domaine de l’IA, dont elles sont traditionnellement exclues."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"There is also incredible demand for talent with trustworthy AI expertise, and a very limited number of people who currently have that expertise. Both the tech industry and academia will need to make"
" significant investments in AI education to meet the need. To cultivate a generation of builders with trustworthy AI training, we’ve partnered with universities on the <a id=\"a1\">Responsible "
"Computing Challenge</a> (RCC), which focuses on curricula that empower students to think about the social and political context of computing. RCC has awarded $2.7M in funding to 33 institutions "
"across three continents."
msgstr ""
"Il existe également une forte demande pour des talents dotés d’une expertise en IA digne de confiance, mais le nombre de personnes ayant cette expertise reste très limité. Tant le secteur "
"technologique que le monde universitaire devront investir massivement dans l’éducation en IA pour répondre à cette demande croissante. Pour former une nouvelle génération d’experts en IA digne de "
"confiance, nous avons lancé le <a id=\"a1\">Responsible Computing Challenge (RCC)</a> en partenariat avec des universités. Cette initiative met l’accent sur les programmes permettant aux étudiants "
"de comprendre les enjeux sociaux et politiques de l’informatique. À l’heure actuelle, Le RCC a déjà attribué 2,7 millions de dollars de financement à 33 institutions réparties sur trois continents."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid "Work to be Done"
msgstr "Ce qu’il reste à accomplir"

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"<b>Widely-accepted industry guidelines on how to build AI responsibly are still in flux.</b> For example, Stanford’s Center for Research on Foundation Models released a <a id=\"a1\">Foundation Model"
" Transparency Index</a> (FMTI), which aimed to assess the level of transparency for 10 of the top AI foundation model developers. Indexes like this have great promise — and also come with their own "
"limitations. The Stanford analysis <a id=\"a2\">quickly came under scrutiny</a> as critics called out the FMTI’s shortcomings and bias toward closed models."
msgstr ""
"<b>Les lignes de conduite largement acceptées dans le secteur concernant le développement responsable de l’IA sont encore en évolution.</b> Le Centre de recherche sur les modèles fondamentaux de "
"l’IA de Stanford, par exemple, a publié un <a id=\"a1\">indice de transparence des modèles fondamentaux</a> (FMTI), qui vise à évaluer le niveau de transparence de dix des principaux développeurs de"
" modèles fondamentaux d’IA. Des initiatives comme celle-ci sont prometteuses, mais elles présentent également leurs propres limites. L’analyse de Stanford a été <a id=\"a2\">rapidement "
"critiquée</a>, certains détracteurs soulignant les lacunes du FMTI et son penchant pour les modèles fermés."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"We’re also seeing a concerning backslide on efforts to diversify major tech companies building AI. Following the murder of George Floyd and subsequent racial justice protests in 2020, leaders across"
" corporate America made commitments to hire, promote, and retain more people of color. That effort started to <a id=\"a1\">bear fruit</a>, but the trend could be under threat now that special "
"interest groups are <a id=\"a2\">piling in</a> and leaders like Elon Musk are <a id=\"a3\">railing against DEI</a>. In 2023, Google and Meta were among the companies who <a id=\"a4\">cut back on "
"DEI</a> spending."
msgstr ""
"Nous constatons également un recul préoccupant des efforts visant à diversifier les principales entreprises technologiques qui développent l’IA. Après le meurtre de George Floyd et les "
"manifestations qui ont suivi en 2020, les dirigeants de nombreuses entreprises américaines se sont engagés à recruter, promouvoir et garder dans leurs équipes davantage de personnes de couleur. Bien"
" que ces efforts aient commencé à <a id=\"a1\">porter leurs fruits</a>, la tendance pourrait être menacée par les <a id=\"a2\">interventions</a> de groupes d’intérêt particulier et l’opposition de "
"leaders comme Elon Musk, qui <a id=\"a3\">rejettent la diversité, l’équité et l’inclusion (DEI)</a>. En 2023, des entreprises comme Google et Meta ont même <a id=\"a4\">réduit leurs dépenses en "
"matière de DEI</a>."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"We must also consider the lack of regional diversity in AI development. The focus on western-centric efforts obscures the work of builders in areas with <a id=\"a1\">less-developed</a> tech sectors,"
" such as South America and the African continent, as well as the exploitation of workers who label data in countries like India and the Philippines. AI will impact life around the world, so it’s "
"crucial to have a wider set of voices involved in its design and deployment. The U.N. estimates that nearly <a id=\"a2\">2.6 billion people have no access to the internet</a>, so data used to train "
"AI models is not representative of one-third of the global population’s experiences. Without more input from a diverse set of people, emerging guidelines and best practices may not align with the "
"cultural and economic needs of other regions."
msgstr ""
"Il faut également tenir compte du manque de diversité régionale dans le développement de l’IA. En se concentrant principalement sur les efforts occidentaux, on néglige le travail précieux réalisé "
"par les développeurs dans des régions où le secteur technologique est <a id=\"a1\">moins avancé</a>, comme l’Amérique du Sud et l’Afrique. De plus, il y a la question des travailleurs dans des pays "
"comme l’Inde et les Philippines, souvent exploités lors de l’étiquetage des données. L’IA aura un impact sur les individus du monde entier, il est donc essentiel d’impliquer plus de perspectives "
"dans sa conception et son déploiement. Selon l’ONU, près de <a id=\"a2\">2,6 milliards de personnes n’ont pas accès à Internet</a>. Cela signifie que les données utilisées pour entraîner les modèles"
" d’IA ne reflètent pas les expériences d’environ un tiers de la population mondiale. Sans l’apport d’un groupe de personnes plus diversifié, les lignes de conduite et les meilleures pratiques "
"émergentes pourraient ne pas répondre aux besoins culturels et économiques d’autres régions du globe."

msgctxt "body.b9421831-8c22-4bb5-9760-eee079598137"
msgid ""
"At Mozilla, we’re continuing <a id=\"a1\">our commitment</a> to building and supporting diverse, equitable, and inclusive internal teams. But we know that a broader transformation is needed: "
"engaging a diverse set of stakeholders in shaping AI’s future is a core part of Mozilla’s programmatic strategy, informing what we fund and where we work. Most notably, the <a id=\"a2\">Africa "
"Innovation Mradi</a> has convened and funded AI builders on the continent since 2020, promoting models of innovation grounded in the unique needs of users in Africa."
msgstr ""
"Chez Mozilla, nous nous sommes <a id=\"a1\">engagés</a> à mettre en place et à soutenir des équipes internes diverses, équitables et inclusives. Mais nous reconnaissons qu’un changement plus large "
"est nécessaire. Impliquer un groupe diversifié d’acteurs dans la définition de l’avenir de l’IA est un aspect fondamental de la stratégie de Mozilla, qui influence nos décisions de financement et "
"nos domaines d’intervention. <a id=\"a2\">L’Africa Innovation Mradi</a>, qui rassemble et finance des développeurs d’IA sur le continent depuis 2020, est une initiative remarquable faisant la "
"promotion de modèles innovants basés sur les besoins des utilisateurs africains."

msgctxt "body.afb32d3d-3c2d-4681-9f01-45ed3f26d149.quote"
msgid "AI will impact life around the world, so it’s crucial to have a <b>wider set of voices</b> involved in its design and deployment."
msgstr "L’IA aura un impact sur les gens du monde entier, il est donc essentiel d’impliquer <b>plus de perspectives</b> dans sa conception et son déploiement."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Building New Tech and Products"
msgstr "Créer de nouvelles technologies et de nouveaux produits"

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"In 2020, we emphasized the need for more foundational technologies to emerge as trustworthy AI building blocks for developers. As the AI landscape is becoming more closed, it’s increasingly critical"
" that these building blocks align with the principles of openness, competition, and accountability."
msgstr ""
"En 2020, nous avons mis en avant le besoin de voir émerger davantage de technologies fondamentales pour l’IA, pour servir de bases solides et fiables aux développeurs. Aujourd’hui, face à un "
"écosystème d’IA de plus en plus fermé, il est crucial que ces fondations respectent les principes d’ouverture, de concurrence et de responsabilité."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Open source approaches do not inherently result in trustworthy AI and can be <a id=\"a1\">captured</a> and <a id=\"a2\">appropriated</a> by corporate interests. However, opening up AI tools to "
"public inspection, modification and remixing is a fundamental first step toward more accountability and agency. Openness can also play a significant role in promoting a <a id=\"a3\">fairer AI "
"market</a>, as a healthy open source ecosystem makes it easier for smaller players to compete with incumbents."
msgstr ""
"Les approches open source ne garantissent pas nécessairement une IA digne de confiance, car elles peuvent être <a id=\"a1\">récupérées</a> et <a id=\"a2\">détournées</a> au profit d’intérêts "
"commerciaux. Toutefois, rendre les outils d’IA transparents et permettre leur modification constitue une première étape essentielle vers une responsabilité et une autonomie accrues. L’ouverture peut"
" également jouer un rôle important pour faire la promotion d’un <a id=\"a3\">secteur de l’IA plus équitable</a>, car un écosystème open source dynamique permet aux petits acteurs de rivaliser avec "
"les grands."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’ve already seen big tech companies make billions of dollars by stockpiling as much user data as possible, and they are keen to apply that strategy to their AI offerings. That’s why the emergence "
"of alternative business models for consumer technologies is a key condition for more trustworthy AI. To promote competition, investors must also support the entrepreneurs pioneering new AI tools and"
" business models that center human agency and protect people’s privacy."
msgstr ""
"Les géants de la tech ont amassé de véritables fortunes en collectant les données des utilisateurs, et ils cherchent actuellement à appliquer cette stratégie dans leurs offres d’IA. C’est pourquoi "
"l’émergence d’autres modèles économiques pour les technologies grand public est une condition essentielle pour une IA plus digne de confiance. Afin d’encourager la concurrence, les investisseurs "
"doivent également soutenir les entrepreneurs qui développent de nouveaux outils et modèles commerciaux d’IA centrés sur l’humain et respectueux de la vie privée."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Finally, we need to increase development and adoption of tools that can help make AI systems more accountable. For example, privacy-enhancing technologies like federated learning have the potential "
"to reduce risks throughout the AI lifecycle, and help make AI more responsible. Other performance and risk assessment tools can also help developers make AI systems more trustworthy."
msgstr ""
"Enfin, nous devons accroître le développement et l’adoption d’outils visant à rendre les systèmes d’IA plus responsables. Les technologies qui contribuent à améliorer la vie privée, comme "
"l’apprentissage fédéré, peuvent réduire les risques tout au long du cycle de vie de l’IA et contribuer à une IA plus éthique. D’autres outils d’évaluation des performances et des risques peuvent "
"également aider les développeurs à garantir la fiabilité des systèmes d’IA."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Positive Progress"
msgstr "Des progrès positifs"

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Proprietary models got a head start in the latest phase of the AI race, but a range of open source LLMs and resources are emerging to counter them."
msgstr "Bien que les modèles propriétaires aient pris une longueur d’avance dans la course à l’IA, nous assistons désormais à l’émergence de nombreux LLM open source offrant une réelle alternative."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Across the AI ecosystem, <a id=\"a1\">Meta’s family of LLMs</a> has gotten most of the attention in discussions of open source AI, but there are hundreds of other models — like EleutherAI’s <a "
"id=\"a2\">GPT-NeoX-20B</a>, Hugging Face’s <a id=\"a3\">BLOOM</a>, the Technology Innovation Institute’s <a id=\"a4\">Falcon-180B</a>, and Mistral’s <a id=\"a5\">Mixtral 8x7B</a> — that better "
"reflect open source values. Hugging Face, a platform and community aiming to “democratize <i>good</i> machine learning,” is amplifying these models through its <a id=\"a6\">Open LLM Leaderboard</a>."
" By tracking, evaluating, and ranking open AI models submitted by the community, the company is giving small teams and individual developers a vetted foundational resource for building more "
"transparent products."
msgstr ""
"Si <a id=\"a1\">Meta et ses LLM</a> ont dominé les discussions sur l’IA open source, des centaines d’autres modèles comme <a id=\"a2\">GPT-NeoX-20B</a> d’EleutherAI, <a id=\"a3\">BLOOM</a> de "
"Hugging Face, <a id=\"a4\">Falcon-180B</a> de l’Institut d’Innovation Technologique et <a id=\"a5\">Mixtral 8x7B</a> de Mistral reflètent mieux les valeurs de l’open source. Hugging Face, une "
"plateforme-communauté qui vise à « démocratiser les <i>bons</i> apprentissages automatiques », met en avant ces modèles à travers son <a id=\"a6\">classement des LLM open source</a>. En suivant, en "
"évaluant et en classant les modèles d’IA ouverts désignés par la communauté, l’entreprise fournit aux petites équipes et aux développeurs individuels une ressource fiable pour créer des produits "
"plus transparents."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’ve also been contributing to this ecosystem at Mozilla. In March 2023, we invested $30 million to create <a id=\"a1\">Mozilla.ai</a>, a startup and community dedicated to making this fast-growing"
" field of open source AI models more trustworthy and useful. The company is in the early stages of developing a more communal vision for human-AI collaboration. This includes building <a "
"id=\"a2\">small, specialized language models (SSLMs)</a> that can be used to fine-tune models according to knowledge from subject matter experts, while ensuring those experts can tailor the models "
"according to their specific needs. We believe tools like these will help make AI systems more accessible, trustworthy, and useful."
msgstr ""
"Chez Mozilla, nous avons également joué un rôle dans cet écosystème. En mars 2023, nous avons investi 30 millions de dollars pour créer <a id=\"a1\">Mozilla.ai</a>, une start-up et une communauté "
"dédiées à rendre les modèles d’IA open source à la fois plus fiables et plus utiles. Notre entreprise développe actuellement une vision plus collaborative des relations entre l’homme et l’IA. Cela "
"passe notamment par la création de <a id=\"a2\">petits modèles de langage spécialisés (SSLM)</a> pouvant être utilisés pour affiner les modèles en fonction des connaissances d’experts, tout en "
"veillant à ce que ces derniers puissent les adapter à leurs besoins spécifiques. Nous sommes convaincus que des outils comme ceux-là contribueront à rendre les systèmes d’IA plus accessibles, "
"fiables et utiles."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’re also actively developing and investing in open source building blocks that offer more agency and make AI more “local.” As part of a broader goal to make AI accessible to everyone through open "
"source, Mozilla released <a id=\"a1\">llamafile</a>, an open source, versatile, single file LLM that makes it <a id=\"a2\">dramatically easier</a> to run and distribute LLMs on a local machine like "
"a laptop. We’ve expanded our work on projects like <a id=\"a3\">Common Voice</a> — the world’s largest crowdsourced multilingual, open-source voice data corpus – which now contains over 100 language"
" data sets, including many local languages not supported by big tech players. Common Voice is the Mozilla Foundation’s flagship initiative to mitigate bias in AI by democratizing voice tech for all,"
" and was <a id=\"a4\">recognized as a digital public good</a> by the UN-backed Digital Public Goods Alliance initiative."
msgstr ""
"Nous nous sommes également engagés dans le développement et le financement de blocs de construction open source, qui offrent une plus grande marge de manœuvre et contribuent à rendre l’IA plus "
"« locale ». Dans le cadre de notre objectif de rendre l’IA accessible à tous grâce à l’open source, nous avons lancé <a id=\"a1\">llamafile</a>, un modèle de langage open source, flexible et contenu"
" dans un seul fichier, qui <a id=\"a2\">facilite considérablement</a> l’exécution et la distribution de modèles de langage sur une machine locale comme un ordinateur portable. Nous travaillons aussi"
" sur des projets comme <a id=\"a3\">Common Voice</a>, le plus grand corpus de données vocales open source multilingue et participatif au monde. Il contient aujourd’hui plus de 100 jeux de données "
"linguistiques, y compris de nombreuses langues locales non prises en charge par les géants de la tech. Common Voice est l’initiative phare de la Fondation Mozilla pour atténuer les biais dans l’IA, "
"en démocratisant la technologie vocale pour tous. Elle a été <a id=\"a4\">reconnue d’utilité publique numérique</a> par l’Alliance pour les biens publics numériques, soutenue par l’ONU."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Mozilla is also working on a number of documentation resources designed to help developers build AI responsibly. This includes our <a id=\"a1\">AI Guide</a>, a community-driven collection of open "
"source resources on topics like AI basics and how to choose machine learning models. It also features a set of notable projects from the AI community for insight and inspiration. For example, it "
"includes our <a id=\"a2\">Open Source Audit Tooling (OAT)</a> project, which aims to help developers, researchers, and policymakers understand the AI auditing landscape."
msgstr ""
"Par ailleurs, Mozilla travaille sur plusieurs ressources documentaires conçues pour favoriser le développement responsable de l’IA. Ces ressources incluent notre <a id=\"a1\">Guide de l’IA</a>, une "
"collection de ressources open source sur des sujets comme les bases de l’IA ou encore le choix de modèles d’apprentissage automatique. Elles présentent également une série de projets notables de la "
"communauté de l’IA visant à offrir des perspectives et de l’inspiration. Notre initiative <a id=\"a2\">Open Source Audit Tooling (OAT)</a>, dont l’objectif est d’aider les développeurs, les "
"chercheurs et les décideurs à comprendre le paysage de l’audit de l’IA, est l’un de ces projets."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"We’ve also invested heavily in the development of the trustworthy AI ecosystem. <a id=\"a1\">Mozilla Ventures</a> has already invested $4M in early-stage startups with a focus on trustworthy AI, "
"including <a id=\"a2\">Themis AI</a>, <a id=\"a3\">Fiddler AI</a>, <a id=\"a4\">Armilla AI</a>, <a id=\"a5\">Truepic</a>, and <a id=\"a6\">Flower</a>. The Themis team has built a software framework "
"to help machine learning models recognize when they are delivering unreliable outputs, while Fiddler AI is building trust into AI by offering observability and explainability tools. Truepic is "
"building content authenticity technologies that can help stop the spread of misinformation via AI-altered images. And, in 2023, Mozilla Foundation committed $1.3 million in technical funding to "
"support trustworthy AI projects through the <a id=\"a7\">Mozilla Technology Fund</a>, the <a id=\"a8\">Data Futures Lab</a>, and related grant initiatives."
msgstr ""
"Nous avons en outre considérablement investi dans le développement d’un écosystème d’IA digne de confiance. <a id=\"a1\">Mozilla Ventures</a> a déjà investi 4 millions de dollars dans des start-up "
"en phase d’incubation centrées sur l’IA digne de confiance, parmi lesquelles <a id=\"a2\">Themis AI</a>, <a id=\"a3\">Fiddler AI</a>, <a id=\"a4\">Armilla AI</a>, <a id=\"a5\">Truepic</a> ou <a "
"id=\"a6\">Flower</a>. L’équipe de Themis a développé un cadre logiciel permettant aux modèles d’apprentissage automatique de reconnaître quand ils produisent des résultats peu fiables, tandis que "
"Fiddler AI propose des outils conçus pour observer et expliquer le fonctionnement d’une IA pour que celle-ci puisse être digne de confiance. Truepic développe des technologies capables "
"d’authentifier les contenus afin d’atténuer les vagues de désinformation menées à l’aide d’images modifiées par l’IA. En 2023, la Fondation–Mozilla s’est engagée à verser 1,3 million de dollars pour"
" soutenir des projets d’IA dignes de confiance par l’intermédiaire du <a id=\"a7\">Fonds de technologie Mozilla</a>, le <a id=\"a8\">Data Futures Lab</a> ainsi que des initiatives connexes."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid "Work to be Done"
msgstr "Ce qu’il reste à accomplir"

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"<b>Open source AI models are gaining momentum, but they won't go mainstream until they are easier to use, more effective, and more trustworthy.</b> To get there, the open source community must focus"
" on making these critical AI building blocks as helpful and successful as possible so they become more relevant in the market. When the barriers to building better AI tools come down, the open "
"source approaches will improve and the trustworthy AI ecosystem will grow."
msgstr ""
"<b>Les modèles d’IA open source gagnent du terrain, mais ils ne deviendront pas mainstream tant qu’ils ne seront pas plus faciles à utiliser, plus efficaces et plus dignes de confiance.</b> Pour y "
"parvenir, la communauté open source doit se concentrer sur la création de blocs de construction d’IA essentiels aussi utiles et performants que possible, afin qu’ils deviennent plus pertinents sur "
"le marché. Lorsque les obstacles à la construction de meilleurs outils d’IA seront surmontés, les approches open source s’amélioreront et un écosystème d’IA digne de confiance pourra se développer."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"One of the biggest barriers to open source AI development is the tremendous amount of computing power needed to build and train LLMs. Chip company NVIDIA is fielding <a id=\"a1\">record demand</a> "
"for its graphics processing units (GPUs), which can cost as much as $30,000 each. Training a model like GPT-4 requires thousands of those chips, making it prohibitively expensive for small teams and"
" individual developers to build out their own AI infrastructure. If deep-pocketed entities like Microsoft, Google, and the companies they back are the only ones that can afford enough GPUs to train "
"their models, more transparent and trustworthy AI systems will never get off the ground. Governments can help by funding AI compute capacity for public research projects and local startups, as they "
"have begun to do in the <a id=\"a2\">U.S.</a>, <a id=\"a3\">U.K.</a>, and the EU. Developers are also working on making it easier to build AI systems using AMD chips, as with our recent update to <a"
" id=\"a4\">llamafile</a>."
msgstr ""
"L’un des principaux obstacles au développement de l’IA open source est l’incroyable puissance informatique nécessaire pour construire et entraîner des LLM. NVIDIA fait face à une <a "
"id=\"a1\">demande sans précédent</a> pour ses unités de traitement graphique (GPU), dont le coût individuel peut atteindre 30 000 dollars. Entraîner un modèle comme GPT-4 nécessite des milliers de "
"ces puces, rendant cette démarche excessivement coûteuse pour les petites équipes et les développeurs individuels souhaitant mettre en place leur propre infrastructure d’IA. Si seules les grandes "
"entreprises disposant de fonds importants comme Microsoft ou Google peuvent se permettre d’acquérir suffisamment de GPU pour entraîner leurs modèles, il sera alors impossible de développer des "
"systèmes d’IA plus transparents et dignes de confiance. Les gouvernements peuvent contribuer à financer la capacité de calcul nécessaire pour des projets de recherche publics et des start-up "
"locales. Cette pratique a déjà été amorcée aux <a id=\"a2\">États-Unis</a>, au <a id=\"a3\">Royaume-Uni</a> et dans l’UE. Parallèlement à cela, les développeurs explorent des solutions pour rendre "
"plus accessible la construction de systèmes d’IA en utilisant des puces AMD, comme l’illustre notre récente mise à jour de <a id=\"a4\">llamafile</a>."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"Another challenge to building new tech and products is a lack of clarity around <a id=\"a1\">what “openness” means</a> in the context of AI. The open-source community has yet to reach consensus on a"
" <a id=\"a2\">concrete definition of open source AI</a>, or on the right guardrails for <a id=\"a3\">releasing AI models to the public</a>. This is critical, as openness alone will not lead to the "
"creation of trustworthy models or mitigate their risks. In September 2023, French startup Mistral AI released its own open source LLM called Mistral 7B, which it claimed was more powerful than "
"Meta’s LLaMA-2. However, researchers quickly raised alarms about the system’s <a id=\"a4\">lack of content moderation filters</a>, which allowed users to prompt the system for bomb-making and self-"
"harm instructions. Other models have built-in security measures to prevent chatbots from answering similar questions, but Mistral’s founder <a id=\"a5\">stated</a> that safety is the responsibility "
"of developers of AI applications, not the companies building the LLMs."
msgstr ""
"Un autre défi majeur pour la création de nouvelles technologies et de nouveaux produits réside dans le manque de clarté du terme <a id=\"a1\">« ouvert » ou « open »</a> dans le domaine de l’IA. La "
"communauté open source n’a pas encore réussi à s’accorder sur <a id=\"a2\">une définition concrète de ce que représente l’IA open source</a>, ni sur les lignes de conduite à suivre pour <a "
"id=\"a3\">rendre les modèles d’IA accessibles au grand public</a>. Or cette question est cruciale, car l’ouverture ne garantit pas à elle seule la création de modèles dignes de confiance ou la "
"réduction des risques. En septembre 2023, la start-up française Mistral AI a lancé son propre LLM open source baptisé Mistral 7B, dont elle affirmait qu’il était plus puissant que le LLaMA-2 de "
"Meta. Cependant, les chercheurs ont rapidement émis des inquiétudes concernant <a id=\"a4\">le manque de filtres</a> de modération dans son système, qui permettait par exemple aux utilisateurs "
"d’obtenir des instructions sur la fabrication de bombes ou sur l’automutilation. D’autres modèles intègrent des mesures de sécurité pour empêcher les chatbots de répondre à de telles questions, mais"
" le fondateur de Mistral a <a id=\"a5\">affirmé</a> que la responsabilité de la sécurité incombait aux développeurs d’applications d’IA, et non aux entreprises créant les LLM."

msgctxt "body.9b5cc94f-a5b5-4366-b6d4-987507e7656b"
msgid ""
"To tackle these challenges, Columbia University and Mozilla are <a id=\"a1\">collaborating</a> on a series of workshops in 2024 to map the different dimensions of openness in AI. The project will "
"engage individuals and organizations with longstanding involvement in open source to build a broad coalition that can stand up to big tech and encourage builders to responsibly open more of their AI"
" development. With this and other efforts, we’ll continue leading the way on defining and developing open source tools and systems that are safe, accessible, and transparent."
msgstr ""
"Pour relever ces défis, l’Université de Columbia et Mozilla <a id=\"a1\">se sont associés</a> pour proposer en 2024 une série d’ateliers dont le but est de mieux comprendre ce que signifie "
"l’ouverture dans le contexte de l’IA. Le projet vise à réunir des individus et des organisations engagés depuis longtemps dans le mouvement open source pour bâtir une large coalition capable de "
"tenir tête aux géants de la tech et d’encourager les développeurs à ouvrir de manière responsable davantage de leurs développements en matière d’IA. Grâce à cette initiative et d’autres encore, nous"
" continuerons à ouvrir la voie pour définir et développer des outils et des systèmes open source sûrs, accessibles et transparents."

msgctxt "body.498b8077-17ab-4151-90e1-0072f6ce5cf6.quote"
msgid "Open source AI models are gaining momentum, but <b>they won't go mainstream</b> until they are easier to use, more effective, and more trustworthy."
msgstr ""
"<b>Les modèles d’IA open source gagnent du terrain, mais ils ne deviendront pas mainstream tant qu’ils ne seront pas plus faciles à utiliser, plus efficaces et davantage dignes de confiance.</b>"

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid "Raising Consumer Awareness"
msgstr "Sensibiliser les consommateurs"

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"A key lever in our 2020 paper was generating public demand for more trustworthy AI products. This includes both everyday consumers and the civil society organizations that educate and advocate for "
"their best interests. A well-informed public is a crucial piece of the AI accountability puzzle. When a critical mass of users pushes back on questionable practices, large tech companies have no "
"choice but to make changes to address their concerns. Their bottom lines depend on it."
msgstr ""
"Créer une demande émanant du grand public pour des produits d’IA plus fiables était un levier important mis en avant dans notre article de 2020. Et cela concerne autant les consommateurs du "
"quotidien que les organisations de la société civile qui s’efforcent de défendre leurs intérêts. Un public bien informé joue un rôle essentiel dans le puzzle de la responsabilité de l’IA. Lorsqu’un "
"nombre critique d’utilisateurs s’oppose à des pratiques douteuses, les géants de la tech n’ont d’autre choix que de répondre à leurs préoccupations, car leur rentabilité en dépend."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid "Positive Progress"
msgstr "Des progrès positifs"

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"ChatGPT’s fast rise and extensive media coverage have made AI a mainstream topic. Companies across industries are experimenting with it, which means millions of people are using it in their "
"workplace. As a result, risks that researchers have been warning about for years are in the spotlight. Recent surveys have found that <a id=\"a1\">more than three-quarters of consumers</a> are "
"concerned about misinformation resulting from AI, and less than 40% said they believe it’s <a id=\"a2\">safe and secure</a>. Years of advocacy and policy developments related to privacy, "
"misinformation, and tech platform accountability have created a more informed, skeptical and opinionated public, which is critical for the AI era."
msgstr ""
"La rapide montée en puissance de ChatGPT et sa large couverture médiatique ont fait de l’IA un sujet de conversation populaire. Des entreprises de tous les secteurs l’expérimentent, ce qui signifie "
"que des millions de personnes l’utilisent dans un contexte professionnel. En conséquence, les risques depuis longtemps pointés par les chercheurs sont désormais sous les feux des projecteurs. Des "
"enquêtes récentes ont montré que <a id=\"a1\">plus de trois quarts des consommateurs</a> sont préoccupés par la désinformation liée à l’IA, et moins de 40 % d’entre eux estiment qu’elle est <a "
"id=\"a2\">sûre et sécurisée</a>. Des années de plaidoyers, de sensibilisation et de politiques axés sur la protection de la vie privée, la lutte contre la désinformation et la responsabilité des "
"plateformes technologiques ont contribué à éduquer un public plus averti, plus sceptique et plus engagé : autant d’éléments clés pour l’avenir de l’IA."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Public opinion around AI is taking shape within familiar contexts of labor, human and consumer rights. Movement leaders have accelerated their understanding of how AI will impact their "
"constituencies, and are shaping attitudes and expectations. For example, AI concerns were a central part of 2023’s Hollywood labor strikes. After several months of work stoppages that brought the "
"film and TV industries to a halt, screenwriters and actors secured <a id=\"a1\">AI-related concessions</a> in union contracts covering hundreds of thousands of employees. The agreements don’t "
"completely prohibit generative AI, but they do place guardrails around how studios can use it, allaying fears about writers’ room cuts and AI-generated likenesses. This early victory bodes well for "
"future labor organizing efforts in other industries."
msgstr ""
"L’opinion publique sur l’IA émerge dans des contextes familiers comme le travail, les droits de l’homme et les intérêts des consommateurs. Les leaders des mouvements prennent de plus en plus "
"conscience de l’impact qu’aura l’IA sur leurs communautés, et influencent donc leurs comportements et leurs attentes. Les préoccupations liées à l’IA étaient au cœur des grèves des travailleurs à "
"Hollywood en 2023. Après plusieurs mois de mobilisation ayant paralysé les industries du cinéma et de la télévision, les scénaristes et les acteurs ont obtenu <a id=\"a1\">des concessions concernant"
" l’IA</a> dans leurs contrats syndicaux, couvrant des centaines de milliers d’employés. Ces accords ne bannissent pas complètement l’utilisation de l’IA générative, mais ils fixent des limites sur "
"la manière dont les studios peuvent l’employer, dissipant ainsi les craintes concernant les licenciements dans les équipes de scénaristes et l’utilisation d’images générées par l’IA. Ce premier "
"succès peut laisser présager de futures avancées dans l’organisation du travail au sein d’autres secteurs."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Other work from advocacy organizations has focused on educating consumers about the dangers of AI and encouraging them to choose more trustworthy technologies when available. Consumer Reports "
"released three short films exploring algorithmic bias in medical devices, mortgage lending, and facial recognition as part of its <a id=\"a1\">Bad Input campaign</a>. Documentary films like <a "
"id=\"a2\">Coded Bias</a> (2021) were important conversation starters for a mainstream audience on topics like misinformation and racial bias in facial recognition algorithms. Dr. Joy Buolamwini’s "
"2023 book <a id=\"a3\"><i>Unmasking AI</i></a> expands on her experiences featured in Coded Bias, and on the founding of the <a id=\"a4\">Algorithmic Justice League</a>. Even those with more extreme"
" perspectives on AI have played a key role in raising consumer awareness; for example, in 2023, the <a id=\"a5\">Center for Humane Technology</a> gave a widely-watched talk on the existing risks of "
"AI technologies, providing more context on how the race to capitalize on AI can lead to safety failures."
msgstr ""
"D’autres initiatives menées par des organisations de plaidoyer se sont concentrées sur la sensibilisation des consommateurs aux dangers de l’IA et les ont encouragés à choisir des technologies plus "
"fiables lorsque celles-ci sont disponibles. L’association Consumer Reports a diffusé trois courts métrages explorant les biais des algorithmes dans les dispositifs médicaux, les prêts hypothécaires "
"et la reconnaissance faciale dans une campagne intitulée « <a id=\"a1\">Bad Input</a> ». Des documentaires comme « <a id=\"a2\">Coded Bias</a> » (2021) ont également servi de points de départ "
"importants pour des discussions grand public sur des sujets tels que la désinformation et les biais raciaux dans les algorithmes de reconnaissance faciale. Le livre « <a "
"id=\"a3\"><i>Unmasking AI</i></a> » de Joy Buolamwini (2023) élargit quant à lui les expériences présentées dans « Coded Bias » et évoque la création de l’<a id=\"a4\">Algorithmic Justice "
"League</a>. Même ceux qui tiennent des points de vue moins nuancés sur l’IA ont joué un rôle crucial dans la sensibilisation des consommateurs. En 2023, par exemple, le <a id=\"a5\">Center for "
"Humane Technology</a> a organisé une conférence très suivie sur les risques associés aux technologies d’IA, fournissant ainsi un contexte supplémentaire sur la manière dont la course à la "
"capitalisation sur l’IA peut entraîner des défaillances en matière de sécurité."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Mozilla's public campaigns and wider advocacy on issues around AI and consumer tech have mobilized over 500,000 people worldwide since 2021, driving meaningful changes to products and industry "
"standards. These campaigns have raised consumer awareness of issues around AI and the tech they use in their everyday lives, from search engines and social media platforms to video doorbells and "
"cars. In July 2023, Slack implemented a blocking feature following a civil society campaign <a id=\"a1\">we spearheaded</a>. In September 2023, YouTube announced it would give civil society "
"researchers access to crucial data, following a <a id=\"a2\">multi-year campaign by Mozilla</a>. In the same month, the Alliance for Automotive Innovation called for a federal privacy law in the "
"U.S. following public pressure generated by Mozilla’s ongoing <a id=\"a3\">*Privacy Not Included</a> report series, which most recently focused on <a id=\"a4\">privacy issues with connected "
"cars</a>. We also launched a new season of our <a id=\"a5\">IRL Podcast</a> in 2023, focused on AI developers bringing responsible products to market."
msgstr ""
"Les campagnes publiques de Mozilla sur les questions liées à l’IA et à la technologie grand public ont mobilisé plus de 500 000 personnes dans le monde depuis 2021, entraînant des changements "
"significatifs dans les produits et les normes de l’industrie. Ces campagnes ont sensibilisé les consommateurs aux problèmes liés à l’IA et à la technologie qu’ils utilisent dans leur vie "
"quotidienne, des moteurs de recherche aux réseaux sociaux en passant par les sonnettes vidéo et les voitures connectées. En juillet 2023, Slack a mis en place une fonction de blocage suite à une "
"campagne de la société civile <a id=\"a1\">initiée par Mozilla</a>. En septembre 2023, YouTube a annoncé qu’il donnerait aux chercheurs de la société civile accès à des données cruciales, à l’issue "
"d’une <a id=\"a2\">campagne menée pendant plusieurs années par Mozilla</a>. Le même mois, l’Alliance for Automotive Innovation a plaidé en faveur d’une loi fédérale sur la confidentialité aux États-"
"Unis, suite à la pression publique suscitée par la série de rapports *<a id=\"a3\">Confidentialité non incluse</a> de Mozilla, qui s’est récemment penchée sur les <a id=\"a4\">problèmes de "
"confidentialité liés aux voitures connectées</a>. Nous avons également lancé une nouvelle saison de notre <a id=\"a5\">podcast IRL</a> en 2023, axée sur les développeurs d’IA qui mettent sur le "
"marché des produits responsables."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Beyond advocacy, we’re also seeing new consumer products coming to market built on trustworthy AI principles. Established companies like <a id=\"a1\">Intel</a> and <a id=\"a2\">Adobe</a>, startups "
"like <a id=\"a3\">Reality Defender</a>, and research organizations like the <a id=\"a4\">MIT Media Lab</a> are working on ways to identify deepfakes, certify image authenticity and fight <a "
"id=\"a5\">dis- and mis-information</a>. Twilio has introduced an <a id=\"a6\">AI Nutrition Facts</a> initiative, offering a consumer-friendly way to understand how an AI product uses their data. "
"Google’s DeepMind group also beta launched <a id=\"a7\">SynthID</a>, a tool for watermarking and identifying AI-generated content, in August 2023."
msgstr ""
"Au-delà des campagnes de plaidoyer et de sensibilisation, nous assistons à l’émergence de nouveaux produits grand public fondés sur les principes d’une IA digne de confiance. Des entreprises bien "
"établies comme <a id=\"a1\">Intel</a> et <a id=\"a2\">Adobe</a>, des start-up telles que <a id=\"a3\">Reality Defender</a>, et des institutions de recherche comme le <a id=\"a4\">MIT Media Lab</a> "
"travaillent sur des moyens d’identifier les deepfakes, de certifier l’authenticité des images et de lutter contre la <a id=\"a5\">désinformation et la mésinformation</a>. Twilio a lancé l’initiative"
" <a id=\"a6\">AI Nutrition Facts</a>, qui offre aux consommateurs une façon conviviale de comprendre comment un produit d’IA utilise leurs données. De son côté, en août 2023, le groupe DeepMind de "
"Google a également lancé en version bêta <a id=\"a7\">SynthID</a>, un outil permettant d’identifier et de marquer les contenus générés par IA."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"In May 2023, Mozilla acquired <a id=\"a1\">Fakespot</a>, a company that protects consumers by using AI to detect fraudulent product reviews and third-party sellers in real-time. Our technology "
"analyzes billions of consumer reviews to quickly identify suspicious activity and then recommend better alternatives to consumers. In late 2023, we launched <a id=\"a2\">Fakespot Chat</a>, which "
"uses the power of generative AI to quickly answer shoppers’ product questions, saving consumers time and money."
msgstr ""
"En mai 2023, Mozilla a acquis <a id=\"a1\">Fakespot</a>, une entreprise qui protège les consommateurs en utilisant l’IA pour détecter en temps réel les faux avis de produits et les vendeurs tiers. "
"Sa technologie analyse des milliards d’avis de consommateurs pour identifier rapidement les activités suspectes et recommander de meilleures alternatives. Fin 2023, nous avons lancé <a "
"id=\"a2\">Fakespot Chat</a>, qui utilise la puissance de l’IA générative pour répondre rapidement aux questions des acheteurs sur les produits, aidant ainsi les consommateurs à gagner du temps et "
"économiser de l’argent."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid "Work to be Done"
msgstr "Ce qu’il reste à accomplir"

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"Though we’ve seen <a id=\"a1\">positive momentum</a> to give workers more of a say in the introduction of AI tools and systems in the workplace, most casual users of generative AI tools are not "
"thinking critically about whether these systems are trustworthy or not. Since there are few well-known alternatives to popular tools based on closed models, many consumers may feel forced to choose "
"the tools from the companies whose technology is already embedded in their daily lives."
msgstr ""
"Bien que nous ayons constaté <a id=\"a1\">une dynamique positive</a> pour donner aux travailleurs plus de voix dans l’intégration des outils d’IA sur le lieu de travail, la plupart des utilisateurs "
"occasionnels ne se posent pas de questions quant à la fiabilité de ces systèmes. Comme il existe peu d’alternatives connues aux outils populaires basés sur des modèles fermés, de nombreux "
"consommateurs peuvent se sentir obligés de choisir les outils des entreprises dont la technologie est déjà intégrée dans leur quotidien."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"We can’t blame consumers for choosing the most convenient tools that appear to be trustworthy, especially when there are limited alternatives. The open source community must continue building AI "
"technology to give people better options. Civil society organizations must keep sounding the alarm on the potential for unchecked AI to cause real-world harm, and funding better alternatives. And "
"regulators must preserve a competitive marketplace with strong consumer protections, giving the broader AI ecosystem the necessary guardrails to thrive."
msgstr ""
"Difficile de leur reprocher de choisir les outils les plus pratiques qui semblent a priori dignes de confiance, surtout lorsqu’il existe peu d’alternatives. La communauté « open source » doit "
"continuer à développer des technologies d’IA pour proposer aux utilisateurs de meilleures options. Les organisations de la société civile doivent continuer à alerter sur le potentiel de nuisance des"
" IA non contrôlées et poursuivre le financement de meilleures alternatives. Enfin, les régulateurs doivent tout faire pour maintenir un marché concurrentiel doté de systèmes de protection pour les "
"consommateurs, et fournir ainsi à l’écosystème de l’IA les garde-fous nécessaires pour se développer."

msgctxt "body.2d2a9b8c-c0df-4618-8a03-669d635fb0e5"
msgid ""
"At Mozilla, we’re working to build more trustworthy AI technologies into our own consumer products in the coming years, and are expanding our crowdsourced investigative research into how TikTok’s "
"recommendation algorithm works. We’ll also need to continue raising consumer awareness of the AI privacy risks and encourage demand for more privacy-preserving approaches used in AI products."
msgstr ""
"Chez Mozilla, nous travaillons à intégrer des technologies d’IA plus fiables dans nos produits grand public dans les années à venir, et nous élargissons nos recherches participatives sur le "
"fonctionnement de l’algorithme de recommandation de TikTok. Nous devrons également continuer à sensibiliser les consommateurs aux risques que l’IA fait peser sur la confidentialité et à encourager "
"la demande de méthodes préservant la vie privée dans les produits d’IA."

msgctxt "body.893bbf68-8dca-44fd-98b4-46cd39f124e7.quote"
msgid "A well-informed public is a <b>crucial piece</b> of the AI accountability puzzle."
msgstr "Un public bien informé joue un <b>rôle essentiel</b> dans le puzzle de la responsabilité de l’IA."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid "Strengthening AI Regulations and Incentives"
msgstr "Renforcer les réglementations et les incitations en matière d’IA"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"The final lever in our original paper focused on the need for governments around the world to develop the vision, skills, and capacities required to effectively regulate AI. Though industry norms "
"and consumer demand play a major role in advancing trustworthy AI, we won’t get far without policies to incentivize more responsible practices, and legal mechanisms to hold companies accountable."
msgstr ""
"Le dernier levier abordé dans notre rapport original soulignait la nécessité pour les gouvernements du monde entier de développer une vision, des compétences et des capacités afin de réguler "
"efficacement l’IA. Bien que les normes de l’industrie et la demande des consommateurs jouent un rôle crucial dans la promotion d’une IA digne de confiance, nous ne pourrons pas avancer sans "
"politiques visant à encourager des pratiques plus responsables et des mécanismes juridiques contraignant les entreprises à rendre compte de leurs actes."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid "Positive Progress"
msgstr "Des progrès positifs"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Our fellow advocates and researchers have been clamoring for action on AI-related regulation for years, but the generative AI boom has made these calls impossible to ignore. Widespread consumer "
"awareness of AI has put more pressure on lawmakers to get up to speed. There’s more momentum than ever behind global policy efforts to develop and implement effective and thoughtful AI regulations."
msgstr ""
"Nos collègues chercheurs défendent depuis des années l’idée d’une réglementation nécessaire de l’IA. Mais le boom de l’IA générative a rendu ces appels impossibles à ignorer. La prise de conscience "
"massive des consommateurs à l’égard de l’IA met davantage de pression sur les législateurs pour qu’ils passent à la vitesse supérieure. Résultat : il existe aujourd’hui un élan plus fort que jamais "
"derrière les efforts politiques mondiaux visant à élaborer et à mettre en œuvre des réglementations efficaces et réfléchies en matière d’IA."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"The EU is moving more quickly than some other regions. Lawmakers there have agreed in principle on the <a id=\"a1\">EU AI Act</a>, a first-of-its-kind piece of legislation originally proposed in "
"April 2021. The framework takes a predominantly risk-based approach to regulating AI, with separate rules for the most powerful general-purpose AI models. Though there are some limitations to this "
"approach, the EU AI Act is set to become the most comprehensive AI law in the world, and will have significant impacts on <a id=\"a2\">global AI governance</a> efforts. The law will complement other"
" recent European technology laws including the <a id=\"a3\">Digital Services Act (DSA)</a> and the <a id=\"a4\">Digital Markets Act (DMA)</a>."
msgstr ""
"L’UE avance plus rapidement que certaines autres régions du monde. Le Parlement européen vient d’approuver une loi sur l’encadrement de l’IA baptisée <a id=\"a1\">EU AI Act</a>, la première du "
"genre, proposée en avril 2021. Ce cadre législatif adopte une approche principalement basée sur les risques pour réguler l’IA, avec des règles spécifiques pour les modèles d’IA les plus puissants. "
"Bien qu’il y ait certaines limites à cette approche, l’EU AI Act est à l’heure actuelle la loi sur l’IA la plus complète au monde et elle aura des impacts significatifs sur les efforts menés <a "
"id=\"a2\">partout dans le monde pour la gouvernance de l’IA.</a> Cette loi vient compléter d’autres lois technologiques récemment adoptées au niveau européen, notamment le <a id=\"a3\">règlement sur"
" les services numériques (DSA)</a> ou le <a id=\"a4\">règlement sur les marchés numériques (DMA)</a>."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Since its inception, our policy and advocacy teams played a key role in the development of the EU AI Act. Working with our allies, we successfully pushed for more transparency, binding rules for "
"foundation models, and targeted due diligence obligations along the AI value chain. However, the work isn't done yet. We’ll continue to advocate to make it a success until the law is fully "
"implemented."
msgstr ""
"Nos équipes en charge des actions politiques ont joué un rôle clé dans le développement de l’EU AI Act, et ce dès les premiers jours. En travaillant avec nos alliés, nous avons réussi à obtenir plus"
" de transparence, des règles contraignantes pour les modèles fondamentaux ainsi que des obligations ciblées de diligence raisonnable tout au long de la chaîne de valeur de l’IA. Mais le travail est "
"encore loin d’être terminé. Aux États-Unis, où sont basés bon nombre des plus grands noms de l’IA,"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"In the U.S., where many of the biggest names in AI are headquartered, the regulatory discussion is starting to pick up. The Biden Administration is looking to move from voluntary AI safety "
"commitments toward concrete rules. In October 2023, President Biden released his <a id=\"a1\">Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence</a> with directives to enhance "
"safety, privacy, equity, and competition — providing a welcome move to ensure AI development comes with sufficient regulatory guardrails. In November 2023, Vice President Harris announced <a "
"id=\"a2\">draft policy guidance</a> to mitigate risks when the federal government uses AI, putting the federal government’s purchasing power behind shaping better AI norms in industry."
msgstr ""
"la discussion réglementaire commence également à s’intensifier. L’administration Biden cherche à passer d’engagements volontaires en matière de sécurité de l’IA à des règles concrètes. En "
"octobre 2023, le président Biden a publié une <a id=\"a1\">ordonnance exécutive pour une IA sûre, sécurisée et digne de confiance</a>. Comprenant des directives pour renforcer la sécurité, la "
"confidentialité, l’équité et la concurrence, elle permet de garantir que le développement de l’IA sera accompagné de garde-fous réglementaires suffisants. En novembre 2023, la vice-présidente "
"Kamala Harris a annoncé des <a id=\"a2\">mesures provisoires</a> pour limiter les risques lors de l’utilisation de l’IA par les services fédéraux. Une décision qui a fait passer le développement de "
"meilleures normes pour l’IA avant le pouvoir d’achat du gouvernement."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Though the U.S. has failed to bring comprehensive privacy legislation to fruition, lawmakers are eager to get AI regulation right. In addition to the voluntary commitments AI companies made at the "
"White House in summer 2023, Senate Majority Leader Chuck Schumer held a <a id=\"a1\">series of closed-door AI Insight Forums</a> for lawmakers, featuring tech CEOs, researchers, and civil rights "
"leaders. It’s crucial that a broad diversity of voices are heard in these forums and it‘s encouraging that the policy community is seeking out AI expertise, including from Mozilla and <a "
"id=\"a2\">its fellows</a>, to develop better legislation."
msgstr ""
"Bien que les États-Unis n’aient pas réussi à adopter une législation exhaustive sur la confidentialité, les législateurs sont bel et bien désireux de réglementer correctement l’IA. En plus des "
"engagements pris par les entreprises du secteur de l’IA à la Maison-Blanche à l’été 2023, le leader de la majorité au Sénat, Chuck Schumer, a organisé une <a id=\"a1\">série de forums d’information "
"sur l’IA à huis clos</a> pour les législateurs, auxquels ont participé des PDG d’entreprises technologiques, des chercheurs et des leaders des droits civiques. Ces forums doivent absolument donner "
"la parole à une grande diversité de personnes, et il est encourageant de voir que les groupes politiques sollicitent des experts de l’IA, y compris Mozilla et <a id=\"a2\">ses partenaires</a>, pour "
"élaborer une réglementation plus efficace."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"In Mozilla’s <a id=\"a1\">written statement</a> for the forum, we highlighted the need for AI policy to center privacy, openness, and transparency as the backbone of responsible regulation. We urged"
" policymakers to look beyond a binary notion of open versus closed AI. A balanced environment where both ecosystems can flourish will fuel innovation, ensure competitiveness, and protect people’s "
"rights and safety while mitigating potential risks. We also emphasized the need for lawmakers to champion privacy in AI technologies by default, with comprehensive privacy legislation like the "
"proposed American Data Privacy and Protection Act at the forefront."
msgstr ""
"Dans une <a id=\"a1\">déclaration écrite</a> rédigée spécialement pour le forum, nous avons souligné l’importance de placer la vie privée, l’ouverture et la transparence au cœur des politiques en "
"matière d’IA, et d’en faire les bases d’une réglementation responsable. Nous avons invité les décideurs politiques à aller au-delà d’une simple vision binaire qui oppose IA ouverte et IA fermée. Et "
"nous avons plaidé pour un environnement équilibré, où les deux écosystèmes peuvent prospérer, favoriser l’innovation, garantir la libre concurrence mais aussi protéger les droits et la sécurité des "
"individus, tout en limitant les risques potentiels. Nous avons également insisté sur la nécessité pour les législateurs de défendre par défaut la protection de la vie privée dans les technologies "
"d’IA, avec des lois sur la vie privée comme l’American Data Privacy and Protection Act."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Our leaders are also offering their expertise in the U.K. Mozilla.ai gave oral evidence to the U.K.’s House of Lords Communications and Digital Committee as part of their inquiry into LLMs. In our "
"remarks, we emphasized the role that open approaches to AI can play in innovation, the market failures preventing smaller players from accessing computing resources like GPUs, and the need for more "
"government investment in AI infrastructure to promote competition. We also discussed the importance of digital education for enterprises, schools, and civil services on what these models are capable"
" of, and how to deploy them safely in various contexts."
msgstr ""
"Nos responsables apportent également leur expertise au Royaume-Uni. Mozilla.ai a ainsi témoigné devant la Commission des Communications et du Numérique de la chambre des Lords du Royaume-Uni, dans "
"le cadre de son enquête sur les LLM. Au cours de notre intervention, nous avons mis en avant le rôle que jouent les approches ouvertes de l’IA dans l’innovation, les lacunes du marché qui empêchent "
"les acteurs de plus petite taille d’accéder à des ressources informatiques comme les GPU, et la nécessité pour les gouvernements d’investir davantage dans les infrastructures d’IA pour promouvoir "
"une concurrence libre. Enfin, nous avons souligné l’importance de l’éducation numérique pour les entreprises, les écoles et les services publics, afin de mieux comprendre les capacités de ces "
"modèles et d’apprendre à les déployer en toute sécurité dans différents contextes."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid "Work to be Done"
msgstr "Ce qu’il reste à accomplir"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Regulation is needed to make AI more trustworthy and mitigate the risks of the technology. At the same time, regulators need to be mindful of the impact such rules will have on competition and "
"openness in AI. Any regulatory framework should ensure that the AI market remains open to competition and innovation from companies challenging the industry behemoths. To do so, it must <a "
"id=\"a1\">safeguard openness and open source</a>."
msgstr ""
"Une réglementation est indispensable pour rendre l’IA digne de confiance et limiter les risques liés à cette technologie. Dans le même temps, les régulateurs doivent être conscients de l’impact "
"qu’auront de telles règles sur la concurrence et l’ouverture dans le domaine de l’IA. Les futurs cadres réglementaires devraient garantir que le marché de l’IA reste ouvert à la concurrence et à "
"l’innovation, pour permettre aux entreprises de défier les géants du secteur. Pour ce faire, ils doivent avant toute chose <a id=\"a1\">préserver le caractère ouvert de l’IA et garantir "
"l’utilisation de code open source</a>."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Openness and transparency are key if we want the benefits of AI to reach the majority of humanity, rather than seeing them applied only to use cases where profit is the primary motivator. Recent "
"global policy discussions on openness have lacked nuance — partly due to <a id=\"a1\">outsized influence</a> from big tech incumbents <a id=\"a2\">trying to shape regulatory discussions</a> to their"
" benefit. Makers of proprietary models have cited hypothetical catastrophic threats as the most important issues for lawmakers to focus on, neglecting existing AI harms like bias and discrimination."
" In October 2023, we and more than 1,800 signatories pushed back on this dynamic in our <a id=\"a3\">Joint Statement on AI Safety and Openness</a>:"
msgstr ""
"L’ouverture et la transparence sont essentielles si nous voulons que les avantages de l’IA profitent à la majorité des humains et ne soient pas uniquement appliqués dans un but commercial. Partout "
"dans le monde, les récentes discussions politiques sur l’ouverture de l’IA ont cruellement manqué de nuance. La raison ? <a id=\"a1\">L’influence disproportionnée</a> des grands acteurs de la "
"technologie, qui cherchent <a id=\"a2\">à faire tourner les discussions réglementaires à leur avantage</a>. Les fabricants de modèles propriétaires ont cité de potentielles menaces catastrophiques "
"et les ont désignées comme les problèmes les plus importants sur lesquels les législateurs devraient se concentrer, passant totalement sous silence les dommages actuels de l’IA tels que les biais et"
" la discrimination. En octobre 2023, nous avons contesté cette vision avec plus de 1 800 signataires dans une <a id=\"a3\">Déclaration commune sur la sécurité et l’ouverture de l’IA</a>:"

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Yes, openly available models come with risks and vulnerabilities — AI models can be abused by malicious actors or deployed by ill-equipped developers. However, we have seen time and time again that "
"the same holds true for proprietary technologies — and that increasing public access and scrutiny makes technology safer, not more dangerous. The idea that tight and proprietary control of "
"foundational AI models is the only path to protecting us from society-scale harm is naive at best, dangerous at worst."
msgstr ""
"Oui, les modèles disponibles en open source comportent des risques et des vulnérabilités. Ils peuvent être détournés par des acteurs malveillants ou déployés par des développeurs mal équipés. Mais "
"nous avons constaté encore et encore que cela est également vrai pour les technologies propriétaires. Et que rendre une technologie publique la rend plus sûre, et non pas plus risquée. L’idée selon "
"laquelle un contrôle strict et propriétaire des modèles d’IA fondamentaux est le seul moyen de nous protéger contre les dommages à l’échelle de la société est au mieux naïve, au pire dangereuse."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"There are government-led processes that can help us sort through some of these bigger questions on open source governance and regulation. As directed in the Biden Administration’s executive order, "
"the U.S. Department of Commerce’s National Telecommunications and Information Administration (NTIA) <a id=\"a1\">is reviewing</a> both the risks and benefits of openly available LLM model weights, "
"inviting public comments to inform potential regulatory approaches. Mozilla intends to submit a response to the associated request for comment to inform NTIA’s approach to this issue."
msgstr ""
"Des processus gouvernementaux existent d’ores et déjà pour nous aider à aborder les questions plus importantes encore de la gouvernance et la réglementation du code open source. Conformément à "
"l’ordonnance exécutive de l’administration Biden, la National Telecommunications and Information Administration (NTIA) du Département du Commerce des États-Unis <a id=\"a1\">examine actuellement</a>"
" les risques et les avantages des modèles LLM disponibles en open source. Et elle invite le public à donner son avis pour éclairer les éventuelles approches réglementaires. Mozilla prévoit de "
"répondre à cette demande pour aider la NTIA à mieux aborder cette question."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"When paired with consumer protections and strong rules to prevent anti-competitive practices, openness spurs innovation and accelerates competition by providing common resources for the ecosystem at"
" large. Competition spurs investments, new jobs, and better choices for companies and consumers. To extend the benefits of the AI boom beyond big tech, lawmakers must prioritize enforcing and "
"strengthening existing competition rules to better meet the challenges of today."
msgstr ""
"Lorsqu’elle est associée à des mécanismes de protection des consommateurs et des règles strictes pour éviter les pratiques anticoncurrentielles, l’ouverture stimule l’innovation et accélère la "
"concurrence en fournissant des ressources communes à l’ensemble de l’écosystème. La concurrence stimule les investissements et la création d’emplois, et offre de meilleures options aux entreprises "
"et aux consommateurs. Mais pour étendre les avantages de l’essor de l’IA au-delà des géants de la tech et mieux répondre aux défis actuels, les législateurs doivent faire de l’application et du "
"renforcement de règles concurrentielles existantes une priorité."

msgctxt "body.f4eed945-8349-40d1-b2f4-e534a03d3227"
msgid ""
"Additionally, while lawmakers educate themselves on the intricacies of the AI landscape, bad actors are poised to weaponize generative AI tools to sow disinformation and political unrest — a harm "
"that is happening right now. With more than 40 national elections scheduled for 2024, policymakers must move more quickly to address this year’s threats. We must use the opportunity to study and "
"engage with AI’s impacts on global politics, and strengthen our systems for the next set of elections. To that end, Mozilla is highlighting the work of researchers around the world who are "
"uncovering inequities in how platforms approach global elections. We’re spotlighting the ‘copy-and-paste’ policy approach platforms tend to take to global elections, particularly for countries in "
"the Global Majority, and showing the devastating impact such decisions can have on a country’s information ecosystem, especially where democratic institutions are relatively fragile."
msgstr ""
"De plus, tandis que les législateurs se familiarisent avec l’IA et ses subtilités, des acteurs malveillants transforment des outils d’IA générative à des fins de désinformation et de déstabilisation"
" politique. Plus de 40 élections nationales sont prévues en 2024. Les décideurs politiques doivent donc agir plus rapidement pour faire face à ces menaces. De notre côté, nous devons saisir cette "
"opportunité pour mieux étudier les impacts de l’IA sur la politique mondiale et renforcer nos systèmes en prévision des prochaines échéances électorales. C’est pour cela que Mozilla met en avant le "
"travail de chercheurs du monde entier révélant des inégalités dans la manière dont les plateformes abordent les élections partout dans le monde. Nous attirons l’attention sur l’approche «  copier-"
"coller » que les plateformes ont tendance à adopter lors des élections, en particulier pour les pays africains, asiatiques ou latins. Et nous démontrons l’impact dévastateur que ces décisions "
"peuvent avoir sur l’écosystème informationnel de tout un pays, surtout là où les institutions démocratiques sont fragiles."

msgctxt "body.88c348fd-0985-4337-845d-cb6e5870be0c.quote"
msgid "Any regulatory framework should ensure that the AI market remains open to <b>competition and innovation</b> from companies challenging the industry behemoths."
msgstr ""
"Les futurs cadres réglementaires devraient garantir que le marché de l’IA reste ouvert à <b>la concurrence et à l’innovation</b>, pour permettre aux entreprises de défier les géants du secteur."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "The Path Forward for Trustworthy AI"
msgstr "Vers une IA digne de confiance"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"The AI landscape is moving more quickly than ever, and the trustworthy AI ecosystem is growing alongside it. To build on the positive momentum we’ve seen in the last three years, we must take "
"targeted action across each of our four key levers: industry norms, new tech and products, consumer demand and regulations and incentives."
msgstr ""
"Le paysage de l’IA évolue à une vitesse jamais vue et l’écosystème de l’IA digne de confiance se développe en parallèle. Pour capitaliser sur la dynamique positive que nous avons observée au cours "
"des trois dernières années, nous devons prendre des mesures ciblées sur chacun de nos quatre leviers clés : les normes de l’industrie, les nouvelles technologies et produits, la demande des "
"consommateurs, ainsi que la réglementation et les incitations."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "Next Steps for Mozilla"
msgstr "Les prochaines étapes pour Mozilla"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"We will continue our work to earn users’ trust in AI across the entire Mozilla project, focusing on openness as our guiding principle. By scaling the potential of open source approaches and "
"advocating for fair, open markets, we can realize our vision of a trustworthy AI landscape with agency and accountability at the center."
msgstr ""
"Nous allons poursuivre notre action pour que les utilisateurs aient confiance en l’IA, en faisant de l’ouverture notre fil directeur. En réalisant le potentiel des approches open source et en "
"plaidant en faveur de marchés équitables et ouverts, nous pourrons faire de l’IA digne de confiance une réalité. Une réalité qui repose sur la capacité d’action et le principe de responsabilité."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "Here’s what’s next on our to-do list:"
msgstr "Voici nos objectifs :"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Shift the public narrative on (trustworthy) AI.</b> We have an opportunity to unlock huge benefits from AI — and an urgent need to tackle tough questions about social ills and closed markets. "
"Mozilla will work with activists, builders and policymakers to make sure this more nuanced story about AI breaks through. We’re working with civil society organizations around the globe to build "
"sustained political power and shift the narrative. We’re also spotlighting the voices of responsible builders, technology leaders, and innovators to help them set the AI agenda in media coverage, "
"policy debates, and popular culture."
msgstr ""
"<b>Faire évoluer le discours public sur l’IA (digne de confiance)</b> Nous avons l’opportunité de tirer parti des avantages exponentiels de l’IA et un besoin urgent de répondre à des questions "
"difficiles sur les problématiques sociétales et les marchés fermés. Mozilla travaillera avec des militants, des constructeurs et des décideurs politiques pour veiller à ce que cette histoire plus "
"nuancée sur l’IA trouve un écho. Nous collaborons d’ores et déjà avec des organisations de la société civile dans le monde entier pour faire évoluer le discours. Et nous mettons également en lumière"
" les voix des développeurs, des leaders technologiques et des innovateurs responsables pour les aider à établir l’ordre de jour de l’IA dans les médias, les débats politiques et la culture "
"populaire."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Make open source generative AI more trustworthy — and mainstream.</b> Open source generative AI is gaining momentum. Our goal is to ensure open source models are trustworthy, safe, helpful and "
"easy to use. Mozilla projects like the Communal AI small language model platform, the Common Voice dataset, and llamafile are local and more accessible models aimed squarely at this goal."
msgstr ""
"<b>Rendre l’IA générative open source plus digne de confiance et plus grand public.</b> L’IA générative open source gagne du terrain. Notre objectif est de garantir que les modèles open source "
"soient fiables, sûrs, utiles et faciles à utiliser. Des projets initiés par Mozilla comme la plateforme des petits modèles de langage Communal AI, l’ensemble de données Common Voice et llamafile "
"sont des modèles locaux et plus accessibles servant directement cet objectif."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Empower consumers — and give them real choices</b>. In an era when AI is becoming intricately woven into the fabric of our daily lives, we must champion products that prioritize and exemplify the"
" highest standards of privacy, security, and transparency. By drawing on the invaluable insights gained from technologies like Fakespot, we’re deepening our dedication to integrating cutting-edge AI"
" capabilities that genuinely empower consumers within our product suite. We’re expanding the impact of these efforts through initiatives like <a id=\"a1\">*Privacy Not Included</a>, which are "
"instrumental in equipping consumers with the essential knowledge to make enlightened product choices."
msgstr ""
"<b>Donner du pouvoir aux consommateurs et leur offrir de vrais choix.</b> À une époque où l’IA est de plus en plus intégrée dans nos vies quotidiennes, nous devons défendre des produits qui "
"privilégient et illustrent les normes les plus élevées en matière de confidentialité, de sécurité et de transparence. Grâce aux précieuses informations obtenues via des technologies comme Fakespot, "
"nous allons plus loin dans notre engagement à intégrer dans notre gamme de produits des capacités d’IA de pointe qui donnent réellement du pouvoir aux consommateurs. Et nous augmentons l’impact de "
"ces efforts grâce à des initiatives comme <a id=\"a1\">*Confidentialité non incluse</a>, essentielles pour aider les consommateurs à faire des choix éclairés en matière de produits."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Invest in the trustworthy + open source AI ecosystem.</b> No single company or organization can serve as a counterweight to big tech — but a community can. We will continue to expand our "
"investment in startups, open source projects, and nonprofits building trustworthy AI, both through direct investment and through thoughtful grantmaking. Properly resourced, this ecosystem has the "
"potential to challenge the big players and push AI in a better direction."
msgstr ""
"<b>Investir dans l’écosystème d’une IA digne de confiance et open source.</b> Aucune entreprise ou organisation seule ne peut faire le poids face aux géants de la tech, mais c’est à la portée d’une "
"communauté. C’est pourquoi nous poursuivrons et étendrons nos investissements dans les start-up, les projets open source et les organisations à but non lucratif qui développent une IA digne de "
"confiance. Nous le ferons à la fois via des investissements directs ou via l’octroi de subventions. Avec les ressources adéquates, cet écosystème peut défier les grands acteurs et faire prendre une "
"meilleure direction à l’IA."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Help regulators develop and roll out pragmatic AI regulation.</b> The EU AI Act, the U.S. Executive Order on AI, and similar initiatives in other countries show policymakers are serious about "
"trustworthy AI. Mozilla is increasing its resources to help policymakers roll out regulation and policies that are helpful and pragmatic from both policy and operational perspectives. This work "
"includes publishing research on topics like open source AI models, competition, and privacy that policymakers can draw on, convening policymakers to share expertise and experience, and spotlighting "
"positive policy advancements around the globe."
msgstr ""
"<b>Aider les régulateurs à élaborer et mettre en œuvre une réglementation pragmatique de l’IA.</b> Le EU AI Act, l’ordonnance exécutive sur l’IA aux États-Unis et des initiatives similaires dans "
"d’autres pays montrent que les décideurs politiques prennent très au sérieux l’IA digne de confiance. Mozilla a donc décidé d’augmenter les ressources allouées pour aider les décideurs politiques à "
"mettre en œuvre des réglementations et des politiques à la fois utiles et pragmatiques, tant du point de vue politique qu’opérationnel. Cela passe notamment par la publication de recherches sur des "
"sujets tels que les modèles d’IA open source, la concurrence et la vie privée sur lesquels les décideurs politiques peuvent s’appuyer. Cela inclut également des rencontres avec des décideurs "
"politiques pour partager notre expertise et notre expérience, et présenter des avancées positives en matière de politique dans le monde entier."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "Next Steps for the Trustworthy AI Ecosystem"
msgstr "Les prochaines étapes pour l’écosystème de l’IA digne de confiance"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid "We’re committed to doing our part, but we can’t make trustworthy AI a reality without working together across the entire tech ecosystem. Here’s how you can get involved:"
msgstr ""
"Vous le savez, chez Mozilla nous ne sommes jamais les derniers à nous engager. Mais nous ne pouvons pas faire de l’IA digne de confiance une réalité sans travailler avec vous dans tout l’écosystème "
"technologique. Voici ce que vous pouvez faire :"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Builders: Seek out — and contribute to — trustworthy open source AI projects.</b> Instead of reaching for the most well-known proprietary models, take advantage of advancements in open source "
"LLMs, and learn from curated resources like our <a id=\"a1\">AI Guide</a>. As you develop new tools, engage with builders, users, and researchers from a wide range of backgrounds to widen your "
"perspective. Understanding how AI will impact people who don’t think like you will make your project or product that much better."
msgstr ""
"<b>Développeurs : cherchez et participez à des projets d’IA open source dignes de confiance.</b> Plutôt que de vous tourner vers les modèles propriétaires les plus connus, profitez des avancées dans"
" les LLM open source, et formez-vous grâce à des ressources comme notre <a id=\"a1\">Guide sur l’IA</a>. Lorsque vous créez de nouveaux outils, échangez avec d’autres développeurs, mais aussi des "
"utilisateurs et des chercheurs issus de divers milieux pour bénéficier d’autres points de vue et découvrir de nouvelles perspectives. Comprendre comment l’IA affectera les personnes qui ne pensent "
"pas comme vous rendra votre projet ou produit encore meilleur."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Consumers: Be critical — and know there are choices you can make.</b> Consumers can’t control who builds AI, but they can choose more trustworthy products when available, and demand them when "
"they aren’t. We know that public pressure can drive change, even within the most powerful companies on Earth. Look past the “cool factor” of new AI tools and read up on the pros and cons before you "
"experiment. Accessible guides like our <a id=\"a1\">*Privacy Not Included</a> series offer clear comparisons in plain language to help you make informed decisions about everything from voice "
"assistants to smart home products."
msgstr ""
"<b>Consommateurs : exercez un regard critique, et ne perdez pas de vue que vous avez le choix.</b> Les consommateurs ne peuvent pas choisir les entreprises qui développent l’IA, mais ils peuvent "
"choisir les produits les plus dignes de confiance lorsqu’ils sont disponibles, et les exiger lorsqu’ils ne le sont pas. Nous en avons sans cesse la preuve : la pression publique peut entraîner des "
"changements, même au sein des entreprises les plus puissantes au monde. Apprenez à voir plus loin que « l’image cool » des nouveaux outils d’IA, et pesez le pour et les contre avant d’essayer un "
"produit ou un service. Des guides comme <a id=\"a1\">*Confidentialité non incluse</a> offrent des comparatifs clairs dans un langage simple pour vous aider à prendre des décisions avisées sur à peu "
"près tout, des assistants vocaux aux accessoires connectés pour la maison."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Policymakers: Prioritize openness and accountability in new rules for AI.</b> Big tech is <a id=\"a1\">pushing for LLM licensing</a> regulations, ostensibly as a security measure. But we know "
"from experience that limiting who can access or benefit from new digital technologies does not make us safer. Openness and accountability can be an antidote, and policymakers must shape legislation "
"accordingly."
msgstr ""
"<b>Décideurs politiques : donnez la priorité à l’ouverture et la responsabilité dans les nouvelles réglementations concernant l’IA.</b> Les géants de la tech font pression pour <a id=\"a1\">une "
"réglementation des LLM par le biais de licences</a>, en prétextant un impératif de sécurité. Mais nous savons par expérience que limiter les personnes, les entreprises ou les organisations qui "
"peuvent accéder ou bénéficier des nouvelles technologies numériques ne garantit nullement plus de sécurité. En revanche, les principes d’ouverture et de responsabilité peuvent fonctionner, et c’est "
"aux décideurs politiques qu’il revient d’adapter la législation en conséquence."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Civil Society Advocates: Look for intersections between AI and issues your communities care about.</b> Whether an organization focuses on human rights, climate justice, LGBTQ+ rights, or racial "
"justice, AI is relevant. <a id=\"a1\">Philanthropy can offset the influence of tech incumbents</a> by supporting the smaller players pioneering AI approaches that uplift society, not just stock "
"prices. Focus grantmaking on projects that center agency, transparency, and accountability in AI, and look to those that connect to the work you’re already doing."
msgstr ""
"<b>Militants de la société civile : visez les points de convergence entre l’IA et les problèmes qui préoccupent vos communautés.</b> Que votre organisation s’occupe des droits de l’homme, de la "
"justice climatique, des droits LGBTQ+ ou encore de la justice raciale, l’IA est un choix pertinent. <a id=\"a1\">La philanthropie peut contre-balancer l’influence des géants de la tech</a>, "
"notamment en soutenant les petits acteurs qui explorent des approches d’IA qui tirent vers le haut la société tout entière, pas seulement le cours des actions en bourse. Concentrez vos efforts et "
"vos actions sur le financement de projets qui placent la capacité d’agir, la transparence et la responsabilité au cœur de l’IA, et entrez en contact avec toutes les personnes et toutes les "
"organisations en lien avec votre travail."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Investors: Fund companies, organizations and projects focused on Trustworthy AI.</b> It’s tempting to put your money on the big industry leaders, but alternative AI business models that put user "
"privacy and well-being first present a massive opportunity. Whether you’re a venture capitalist, an institutional investor or a philanthropist, financially supporting the growth of the trustworthy "
"AI ecosystem will help mitigate AI risks while spreading the returns beyond big tech."
msgstr ""
"<b>Investisseurs : financez les entreprises, les organisations et les projets axés sur l’IA digne de confiance.</b> Il peut être tentant de placer votre argent sur les grands leaders du secteur, "
"mais les modèles économiques d’IA alternatifs qui donnent la priorité à la vie privée et au bien-être des utilisateurs représentent une formidable opportunité. Que vous soyez un fonds "
"d’investissement en capital-risque, un investisseur institutionnel ou encore un philanthrope, soutenir financièrement la croissance de l’écosystème d’IA digne de confiance peut contribuer à limiter "
"les risques liés à l’IA tout en répartissant les retours bien au-delà des géants de la technologie."

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"AI will impact every corner of the world. To make sure it delivers on its promise for humanity, we must continue activating a broad coalition of technologists, activists, legislators, and everyday "
"citizens with diverse perspectives.There is still much to do, but with a movement grounded in openness, agency, and accountability, a more trustworthy AI landscape is within reach. Let’s get to "
"work."
msgstr ""
"À plus ou moins court terme, l’IA impactera chaque parcelle du globe. Pour garantir qu’elle tienne ses promesses pour l’humanité, nous devons continuer à réunir des technologues, des militants, des "
"législateurs et des citoyens ordinaires pour former une large coalition aux perspectives diverses. Il reste encore beaucoup à faire mais, avec un mouvement ancré dans des principes comme "
"l’ouverture, la capacité d’action et la responsabilité, l’IA plus digne de confiance est à notre portée. À nous de jouer !"

msgctxt "body.0faa1298-6d9f-4f8f-a0bf-bb1fd48d7a42"
msgid ""
"<b>Please email us at</b> <a id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> to provide any input on the report and/or to highlight your favorite examples of AI being used in ways that build "
"trust and improve people’s lives.</b>"
msgstr ""
"<b>Envoyez-nous un e-mail à l’adresse</b> <a id=\"a1\"><b>AIPaper@mozillafoundation.org</b></a><b> pour nous donner votre avis sur le rapport et partager vos exemples favoris illustrant une "
"utilisation de l’IA qui favorise la confiance et améliore le quotidien des individus.</b>"

msgctxt "body.b642b40e-f1bb-4063-9ea9-804558e7b856.quote"
msgid "With a movement grounded in openness, agency, and accountability, a more trustworthy AI landscape is <b>within reach.</b>"
msgstr "Avec un mouvement ancré dans des principes comme l’ouverture, la capacité d’action et la responsabilité, l’IA plus digne de confiance est <b>à notre portée</b>."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "Further Reading"
msgstr "Ressources complémentaires"

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>This is the real lesson to take away from the OpenAI debacle</b></a><b>, Fast Company (op-ed), December 2023</b>: In an op-ed, Mozilla’s Mark Surman explains how OpenAI’s November "
"governance battle points to the need for public institutions that prioritize humanity's interests over profit, especially in the AI era, despite the failure of OpenAI's nonprofit model."
msgstr ""
"<a id=\"a1\"><b>This is the real lesson to take away from the OpenAI debacle</b></a><b>, Fast Company (tribune libre), décembre 2023</b> : dans une tribune, Mark Surman de Mozilla explique comment "
"la bataille pour la gouvernance d’OpenAI souligne le besoin d’institutions publiques qui privilégient les intérêts publics plutôt que le profit, en particulier à l’ère de l’IA, malgré l’échec du "
"modèle à but non lucratif d’OpenAI."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>When AI doesn’t speak your language</b></a><b>, Coda, October 2023:</b> Highlights the challenges minority languages face with AI, where better technology could simultaneously "
"support language use and increase surveillance."
msgstr ""
"<a id=\"a1\"><b>When AI doesn’t speak your language</b></a><b>, Coda, octobre 2023 :</b> une mise en lumière des défis auxquels sont confrontées les langues minoritaires avec l’IA, alors qu’une "
"meilleure technologie pourrait à la fois soutenir l’utilisation de ces langues et accroître la surveillance."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>AI’s Present Matters More Than Its Imagined Future</b></a><b>, The Atlantic (op-ed), October 2023</b>: Mozilla Fellow Inioluwa Deborah Raji writes about her experience attending one "
"of Sen. Chuck Schumer’s AI Insight Forums, and why present-day harms are more urgent than hypothetical existential AI risks."
msgstr ""
"<a id=\"a1\"><b>AI’s Present Matters More Than Its Imagined Future</b></a><b>, The Atlantic (tribune libre), octobre 2023</b>: Inioluwa Deborah Raji, une chercheuse associée à Mozilla, revient sur "
"sa participation à l’un des forums de réflexion sur l’IA organisés par le sénateur Chuck Schumer, et explique pourquoi les préjudices actuels sont plus urgents que les risques existentiels "
"hypothétiques de l’IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>How should regulators think about \"AI\"?</b></a><b>, Dr. Emily M. Bender (video), October 2023</b><b><i>:</i></b> Dr. Bender spoke at a virtual roundtable on AI in the workplace "
"convened by Congressman Bobby Scott, breaking down the six different kinds of automation and providing recommendations for AI regulation."
msgstr ""
"<a id=\"a1\"><b>How should regulators think about &quot;AI&quot;?</b></a><b>, Emily M. Bender (vidéo), octobre 2023</b><b><i> :</i></b> Mme Bender a pris la parole lors d’une table ronde virtuelle "
"au sujet de l’IA sur le lieu de travail, organisée par le membre du Congrès américain Bobby Scott. À cette occasion, elle a présenté les six types d’automatisation et fourni des recommandations pour"
" la réglementation de l’IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>The battle over Open-Source AI</b></a><b>, Ben’s Bites (newsletter), October 2023</b>: This piece summarizes where well-known AI companies stand on the issue of regulating advanced "
"open source AI software."
msgstr ""
"<a id=\"a1\"><b>The battle over Open-Source AI</b></a><b>, Ben’s Bites (newsletter), octobre 2023</b>: cet article résume la position des grandes entreprises de l’IA sur la question de la régulation"
" des logiciels avancés d’IA open source."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>Artificial Intelligence: Advancing Innovation Towards the National Interest</b></a><b>, Clément Delangue, Hugging Face (written congressional testimony), June 2023:</b> In his "
"testimony, Hugging Face’s CEO emphasizes the importance of open AI innovation and the need for mechanisms that ensure AI is safe, transparent, and aligns with national interests."
msgstr ""
"<a id=\"a1\"><b>Artificial Intelligence: Advancing Innovation Towards the National Interest</b></a><b>, Clément Delangue, Hugging Face (version écrite de son témoignage devant le Congrès), "
"juin 2023 :</b> dans son témoignage, le PDG de Hugging Face met l’accent sur l’importance de l’innovation en matière d’IA ouverte et sur la nécessité de mettre en place des mécanismes garantissant "
"que l’IA est sûre, transparente et conforme aux intérêts nationaux."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>We tested ChatGPT in Bengali, Kurdish, and Tamil. It failed.</b></a>, <b>Rest of World, September 2023</b>: Rest of World's testing revealed ChatGPT’s struggles with many "
"underrepresented languages. The system often makes up words and fails at logic and basic information retrieval, highlighting gaps in AI training data and the need for tailored language support."
msgstr ""
"<a id=\"a1\"><b>We tested ChatGPT in Bengali, Kurdish, and Tamil. It failed.</b></a>, <b>Rest of World, septembre 2023</b> : les tests de Rest of World ont révélé les difficultés de ChatGPT avec de "
"nombreuses langues sous-représentées. Le système invente fréquemment des mots et échoue dans la logique et la récupération d’informations de base, mettant en lumière les lacunes dans les données "
"d’entraînement de l’IA et le besoin d’un support linguistique adapté."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>The Battle Over Books3 Could Change AI Forever</b></a><b>, WIRED, September 2023:</b> This piece details the battle over the Books3 training data set, which was created from a vast "
"collection of copyrighted literary works and is now at the center of disputes between open-access advocates and copyright holders fighting for control and compensation."
msgstr ""
"<a id=\"a1\"><b>The Battle Over Books3 Could Change AI Forever</b></a><b>, WIRED, septembre 2023 :</b> cet article revient sur la bataille autour de l’ensemble de données d’entraînement Books3, créé"
" à partir d’une vaste collection d’œuvres littéraires protégées par des droits d’auteur. Il est actuellement au centre de litiges entre les défenseurs d’un accès libre et les détenteurs de droits "
"d’auteur qui se battent pour leurs droits au contrôle et à une compensation financière."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>LoRA Fine-tuning Efficiently Undoes Safety Training from Llama 2-Chat 70B</b></a>,<b> LessWrong, October 2023:</b> This study demonstrates how AI models can be easily manipulated to "
"undo safety training, raising concerns about the risks of public model releases."
msgstr ""
"<a id=\"a1\"><b>LoRA Fine-tuning Efficiently Undoes Safety Training from Llama 2-Chat 70B</b></a>,<b> LessWrong, octobre 2023 :</b> cette étude démontre comment les modèles d’IA peuvent être "
"facilement manipulés pour désactiver leurs mécanismes de sécurité, ce qui soulève des préoccupations majeures concernant leurs versions publiques."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>Removing RLHF Protections in GPT-4 via Fine-Tuning</b></a><b>, University of Illinois Urbana-Champaign and Stanford University, November 2023:</b> This study reveals that attackers "
"can remove reinforcement learning with human feedback (RLHF) protections in language models like GPT-4, highlighting the need for enhanced protection against potential misuse."
msgstr ""
"<a id=\"a1\"><b>Removing RLHF Protections in GPT-4 via Fine-Tuning</b></a><b>, University of Illinois Urbana-Champaign and Stanford University, novembre 2023 :</b> cette étude révèle que des "
"attaquants peuvent supprimer les protections de l’apprentissage par renforcement avec retour humain (RLHF) dans les modèles de langage comme GPT-4, mettant en évidence le besoin d’une protection "
"renforcée contre de potentiels détournements."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>AI Red-Teaming Is Not a One-Stop Solution to AI Harms</b></a><b>, Data &amp; Society, October 2023</b>: This policy brief argues that while AI red-teaming can identify specific "
"technical vulnerabilities, it must be paired with other accountability tools, including algorithmic impact assessments, external audits, and public consultation."
msgstr ""
"<a id=\"a1\"><b>AI Red-Teaming Is Not a One-Stop Solution to AI Harms</b></a><b>, Data &amp; Society, octobre 2023</b> : ce document politique soutient que, même si des évaluations de la "
"cybersécurité d’une IA peuvent identifier des vulnérabilités techniques précises, elles doivent être associées à d’autres outils de responsabilisation, comme des évaluations de l’impact de "
"l’algorithme, des audits externes et des consultations publiques."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>DeepMind reportedly lost a yearslong bid to win more independence from Google</b></a>, <b>The Verge, May 2021</b>: Google rejected DeepMind’s request for greater autonomy and "
"nonprofit status, due to the AI subsidiary's ongoing financial losses and Google's desire to commercialize its AI research."
msgstr ""
"<a id=\"a1\"><b>DeepMind reportedly lost a yearslong bid to win more independence from Google</b></a>, <b>The Verge, mai 2021</b> : Google a rejeté la demande de DeepMind d’acquérir plus d’autonomie"
" ainsi que le statut d’organisation à but non lucratif, en raison des pertes financières continues de la filiale en intelligence artificielle et du désir de Google de commercialiser ses recherches "
"en IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>These fake images reveal how AI amplifies our worst stereotypes</b></a><b>, The Washington Post, November 2023</b>: AI image generators like Stable Diffusion and DALL-E continue to "
"perpetuate disturbing stereotypes related to gender and race despite attempts to detoxify their training data, illustrating the urgent issue of inherent bias in AI systems."
msgstr ""
"<a id=\"a1\"><b>These fake images reveal how AI amplifies our worst stereotypes</b></a><b>, The Washington Post, novembre 2023</b> : les générateurs d’images basées sur l’IA comme Stable Diffusion "
"et DALL-E perpétuent des stéréotypes perturbants liés au genre et aux origines ethniques, malgré des tentatives de « détoxification » de leurs données d’entraînement. Une situation qui illustre bien"
" le problème urgent du biais inhérent dans les systèmes d’IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>OpenAI is getting trolled for its name after refusing to be open about its A.I.</b></a><b>, Fortune, March 2023:</b> Fortune details the criticism OpenAI has faced for its use of "
"“open” language despite its focus on proprietary, closed source models."
msgstr ""
"<a id=\"a1\"><b>OpenAI is getting trolled for its name after refusing to be open about its A.I.</b></a><b>, Fortune, mars 2023 :</b> le magazine Fortune détaille les critiques auxquelles OpenAI a "
"été confronté pour son utilisation d’un langage « ouvert » malgré son orientation vers des modèles propriétaires à code source fermé."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid ""
"<a id=\"a1\"><b>Meta can call Llama 2 open source as much as it likes, but that doesn't mean it is</b></a><b>, The Register (op-ed), July 2023:</b> Steven J. Vaughan-Nichols argues that Meta's "
"release of Llama 2 under a \"community license\" falls short of open-source principles, making the company’s use of the term more about marketing than the principles of the open-source community."
msgstr ""
"<a id=\"a1\"><b>Meta can call Llama 2 open source as much as it likes, but that doesn’t mean it is</b></a><b>, The Register (tribune libre), juillet 2023</b> : Steven J. Vaughan-Nichols affirme que "
"la publication de Llama 2 par Meta sous une « licence communautaire » ne respecte pas les principes du code source ouvert, faisant de l’utilisation de ce terme par l’entreprise davantage une "
"question de marketing que de respect des principes de la communauté du code source ouvert."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "Additional Links"
msgstr "Liens complémentaires"

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "<a id=\"a1\"><b>AI Incident Database</b></a><b>:</b> Indexing the collective history of harms by AI"
msgstr "<a id=\"a1\"><b>AI Incident Database</b></a><b> :</b> un inventaire des préjudices engendrés par l’IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "<a id=\"a1\"><b>Algorithmic Justice League Harm Collection Tool</b></a><b>:</b> Allows users to report AI harms, biases and triumphs"
msgstr "<a id=\"a1\"><b>Algorithmic Justice League Harm Collection Tool</b></a><b> :</b> permet aux utilisateurs de signaler les préjudices, les biais mais aussi les réussites de l’IA."

msgctxt "body.3c43e73a-872c-46da-8b37-dcd8bc276373"
msgid "<a id=\"a1\"><b>The Data Provenance Initiative:</b></a> Audit of large scale datasets"
msgstr "<a id=\"a1\"><b>The Data Provenance Initiative :</b></a> une évaluation des ensembles de données à grande échelle"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Appendix - Additional Mozilla Trustworthy AI Projects"
msgstr "Annexe - Autres projets de Mozilla pour une IA digne de confiance"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Changing AI Development Norms"
msgstr "Changer les normes de développement de l’IA"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Responsible Computing Challenge</b></a><b>:</b> In 2023, Mozilla provided $2.7M to universities in Kenya, India, and the US to add responsible computing to their curricula. The "
"result: thousands of students — the AI builders of tomorrow — wrestling with ethical issues in tech."
msgstr ""
"<a id=\"a1\"><b>Responsible Computing Challenge</b></a><b> :</b> en 2023, Mozilla a alloué 2,7 millions de dollars à des universités situées au Kenya, en Inde et aux États-Unis pour qu’elles "
"intègrent l’informatique responsable à leurs programmes d’études. Résultat : des milliers d’étudiants — les futurs développeurs de l’IA — se confrontent actuellement aux questions éthiques de la "
"technologie."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Is that Even Legal? guide</b></a>: Mozilla is educating AI builders on how to develop trustworthy AI systems within existing regulatory frameworks around the world. Our guide offers "
"data governance research and advice for builders in Germany, India, Kenya and the U.S."
msgstr ""
"<a id=\"a1\"><b>Guide « Is that Even Legal? »</b></a> : Mozilla forme les développeurs sur la façon de créer des systèmes d’IA fiables et conformes aux cadres réglementaires établis dans le monde "
"entier. Notre guide propose des études sur la gouvernance des données ainsi que des conseils destinés aux développeurs basés en Allemagne, en Inde, au Kenya et aux États-Unis."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Africa Innovation Mradi</b></a><b>:</b> This program leverages Mozilla’s role as stewards of the open web to promote innovation grounded in the unique needs of users in the African "
"region beginning with East and Southern Africa."
msgstr ""
"<a id=\"a1\"><b>Africa Innovation Mradi</b></a><b> :</b> ce programme tire parti du rôle de Mozilla en tant que coordinateur du web ouvert pour promouvoir des innovations basées sur les besoins des "
"utilisateurs africains, en commençant par l’Afrique de l’Est et l’Afrique australe."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Trustworthy AI Fellowships</b></a><b>:</b> Long before ChatGPT, Mozilla Trustworthy AI Fellows were studying AI’s flaws, limits, and potential. Since 2019, more than 50 "
"Fellows have explored the impacts of AI on society."
msgstr ""
"<a id=\"a1\"><b>Mozilla Trustworthy AI Fellowships</b></a><b> :</b> bien avant ChatGPT, les titulaires de bourse Mozilla experts en IA digne de confiance étudiaient les défauts, les limites et le "
"potentiel de l’IA. Depuis 2019, plus de 50 titulaires de bourse ont exploré les impacts de l’IA sur la société."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Festival (MozFest)</b></a>: Too often, the most pressing decisions about AI get made in silos. Mozfest is Mozilla’s antidote to this problem. The event convenes and connects "
"thousands of activists, engineers, philanthropists, and policymakers from around the world to build and envision more trustworthy AI."
msgstr ""
"<a id=\"a1\"><b>Mozilla Festival (MozFest)</b></a> : trop souvent, les décisions les plus pressantes concernant l’IA sont prises de manière cloisonnée. Mozfest est l’antidote de Mozilla à ce "
"problème. L’événement réunit et met en contact des milliers de militants, d’ingénieurs, de philanthropes et de décideurs du monde entier pour construire et imaginer une IA plus fiable."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Lelapa AI</b></a><b>:</b> Mozilla Ventures invested in Lelapa AI, a South African-based that just launched its first product: Vulavula, a new AI tool that converts voice to text and "
"detects names of people and places in written text in four South African languages. Lelapa’s CEO, <a id=\"a2\">Pelonomi Moila</a>, was recently named to the TIME100 in AI."
msgstr ""
"<a id=\"a1\"><b>Lelapa AI</b></a><b> :</b> Mozilla Ventures a investi dans la société Lelapa AI, basée en Afrique du Sud. Celle-ci vient de lancer son premier produit, Vulavula, un nouvel outil d’IA"
" qui convertit la voix en texte et détecte les noms de personnes et des lieux dans des textes écrits dans quatre langues sud-africaines. La PDG de Lelapa, <a id=\"a2\">Pelonomi Moila</a>, a "
"récemment figuré dans le classement TIME100 des personnes les plus influentes dans le domaine de l’IA."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Building New Tech and Products"
msgstr "Créer de nouvelles technologies et de nouveaux produits"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Responsible AI Challenge</b></a><b>:</b> In May 2023, Mozilla hosted an event with 175 attendees, 7 workshops, and 3 keynote speakers to explore how our Trustworthy AI principles "
"could be used to provide a playbook for builders. The event awarded $100K in prizes to challenge winners who pitched Responsible AI projects."
msgstr ""
"<a id=\"a1\"><b>Responsible AI Challenge</b></a><b> :</b> en mai 2023, Mozilla a organisé un événement avec 175 participants, 7 ateliers et 3 grands conférenciers pour explorer de quelles façons nos"
" principes d’une IA digne de confiance pourraient servir de guide pratique pour les développeurs. L’événement a attribué 100 000 dollars aux gagnants des défis qui ont présenté des projets d’IA "
"responsable."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Internet Ecosystem (MIECO)</b></a><b>:</b> MIECO funds innovators building a healthier internet experience. Supported projects include llamafile, which makes open source "
"large language models much more accessible to both developers and end users."
msgstr ""
"<a id=\"a1\"><b>Mozilla Internet Ecosystem (MIECO)</b></a><b> :</b> une source de financement pour les innovateurs qui contribuent à développer une expérience internet plus saine. L’un des projets "
"soutenus est llamafile, qui facilite l’accès des grands modèles de langage open source aux développeurs et aux utilisateurs finaux."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "<a id=\"a1\"><b>Mozilla AI Guide</b></a><b>:</b> A community-driven resource where developers can come together to pioneer and drive generative AI innovations."
msgstr ""
"<a id=\"a1\"><b>Mozilla AI Guide</b></a><b> :</b> une ressource créée par et pour la communauté Mozilla, dans laquelle les développeurs peuvent se rassembler pour explorer et stimuler des "
"innovations en matière d’IA générative."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Common Voice</b></a><b>:</b> The world’s largest multilingual, open-source dataset, Common Voice is used by researchers, academics, and developers around the world to train "
"voice-enabled technology and ultimately make it more inclusive and accessible."
msgstr ""
"<a id=\"a1\"><b>Mozilla Common Voice</b></a><b> :</b> le plus grand ensemble de données open source multilingue au monde, utilisé par des chercheurs, des universitaires et des développeurs du monde "
"entier pour entraîner des technologies vocales et les rendre plus inclusives et accessibles."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Technology Fund (MTF)</b></a>: Since 2022, MTF has supported open source projects that explore how AI impacts issues ranging from bias to climate change. One notable project,"
" Countering Tenant Screening, exposes bias and discrimination within the AI-powered screening services used by landlords."
msgstr ""
"<a id=\"a1\"><b>Mozilla Technology Fund (MTF)</b></a> : depuis 2022, MTF soutient des projets open source qui explorent les impacts de l’IA sur un grand nombre de questions allant de la partialité "
"au changement climatique. Countering Tenant Screening en est l’un des projets notables. Il a mis en lumière les biais et les discriminations présents dans un service de présélection de locataires "
"alimenté par l’IA et utilisé par les propriétaires."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Data Futures Lab (DFL):</b></a> The race to collect data to build and test AI Models has raised new legal and ethical questions about the source and ownership of data. "
"Mozilla’s Data Futures Lab incubates products and platforms radically redesigning what trustworthy data stewardship looks like."
msgstr ""
"<a id=\"a1\"><b>Mozilla Data Futures Lab (DFL) :</b></a> la course à la collecte de données pour construire et tester des modèles d’IA a soulevé de nouvelles questions légales et éthiques concernant"
" l’origine et la propriété des données. Le Mozilla Data Futures Lab est un incubateur de produits et de plateformes qui visent à redéfinir la gestion responsable des données."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla.ai</b></a><b>:</b> Mozilla has been a key contributor to the NeurIPS 2023 <a id=\"a2\">Large Language Model Efficiency Challenge</a>, the Conference on Knowledge Discovery "
"and Data Mining (KDD)’s <a id=\"a3\">workshop</a> on the evaluation of recommender systems, and <a id=\"a4\">research</a> on new ways to efficiently perform few-shot classification on top of closed "
"models like chatGPT."
msgstr ""
"<a id=\"a1\"><b>Mozilla.ai</b></a><b> :</b> Mozilla a joué un rôle important dans le défi <a id=\"a2\">Large Language Model Efficiency Challenge</a> NeurIPS 2023, dans <a id=\"a3\">l’atelier "
"Conference on Knowledge Discovery and Data Mining (KDD)</a> sur l’évaluation des systèmes de recommandation, ainsi que dans la <a id=\"a4\">recherche</a> de nouvelles méthodes pour réaliser "
"efficacement la classification de modèles fermés comme ChatGPT."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Themis AI</b></a>: Mozilla Ventures invested in Themis AI, a Cambridge, MA-based company that spun out of MIT's CSAIL. Themis tackles bias and uncertainty in AI models and has "
"developed a tool, CAPSA, that can automatically estimate uncertainty for any ML model."
msgstr ""
"<a id=\"a1\"><b>Themis AI</b></a>, une start-up située à Cambridge dans le Massachusetts et issue du CSAIL du MIT, a bénéficié d’un investissement de la part de Mozilla Ventures. Themis, qui a pour "
"vocation de s’attaquer aux biais et aux incertitudes dans les modèles d’IA, a développé un outil nommé CAPSA, capable d’estimer automatiquement le niveau d’incertitude de n’importe quel modèle "
"d’apprentissage automatique."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Raising Consumer Awareness"
msgstr "Sensibiliser les consommateurs"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>*Privacy Not Included</b></a>: *PNI guides expose the realities and risks of connected devices. The 2023 guide focused on cars and generated unprecedented attention: citing our "
"research, US Senator Ed Markey wrote to 14 car companies in the US demanding information about their collection, use and sales of personal data."
msgstr ""
"<a id=\"a1\"><b>*Confidentialité non incluse</b></a> : les guides *Confidentialité non incluse dévoilent les réalités et les risques des appareils connectés. Un guide de 2023 portant sur les "
"voitures a suscité une attention inédite. En citant nos recherches, le sénateur américain Ed Markey a écrit à 14 constructeurs automobiles aux États-Unis pour obtenir des informations sur leurs "
"activités de collecte, d’utilisation et de vente de données personnelles."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>IRL Podcast</b></a>: The latest season of IRL showcased global trustworthy AI innovators from civil society, industry, and policy — connecting the issues they care about to AI. The "
"goal was to remind IRL’s growing audience that there’s no taking the human out of the algorithm. There have been over 100,000 downloads of IRL since Season 7 launched in October 2023."
msgstr ""
"<a id=\"a1\"><b>IRL Podcast</b></a> : la dernière saison du podcast IRL a mis en avant des innovateurs en IA digne de confiance venus des quatre coins du monde et issus de la société civile, de "
"l’industrie ou encore de la sphère politique. L’objectif de chaque épisode ? Établir un lien entre l’IA et les problématiques qui leur tiennent à cœur, pour rappeler à l’audience toujours plus "
"nombreuse du podcast que l’humain ne peut être dissocié de l’algorithme. Depuis le lancement de la saison 7, en octobre 2023, IRL a été téléchargé plus de 100 000 fois."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Philanthropic Advocacy</b></a><b>:</b> In 2023, Mozilla participated in <a id=\"a2\">a collaboration with Vice President Kamala Harris’ office on philanthropy’s role in AI</a> "
"alongside other leading foundations. We also published a set of <a id=\"a3\">AI Funding Principles</a> that draw on our 4+ years of funding trustworthy AI."
msgstr ""
"<a id=\"a1\"><b>Philanthropic Advocacy</b></a><b> :</b> en 2023, <a id=\"a2\">Mozilla s’est associé au bureau de la vice-présidente Kamala Harris pour discuter du rôle de la philanthropie dans le "
"domaine de l’IA</a>, aux côtés d’autres fondations de premier plan. Nous avons également publié un ensemble de <a id=\"a3\">principes relatifs au financement de l’IA</a>, en nous appuyant sur plus "
"de 4 ans d’expérience dans le financement de l’IA digne de confiance."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Open Source Research and Investigation Team</b></a>: The OSRI team uses crowdsourced data to make opaque and influential AI systems more transparent and accountable. The team has "
"produced several <a id=\"a2\">original research</a> reports into YouTube’s recommendation algorithm."
msgstr ""
"<a id=\"a1\"><b>Open Source Research and Investigation Team</b></a> : l’équipe OSRI exploite des données de crowdsourcing pour rendre les systèmes d’IA opaques et influents plus transparents et plus"
" responsables. L’équipe a notamment produit plusieurs <a id=\"a2\">rapports de recherche originaux</a> sur l’algorithme de recommandation de YouTube."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Mozilla Innovation Week</b></a>: In December 2023, Mozilla shared a behind-the-scenes view of some of our AI-driven explorations–including Solo, MemoryCache, AI Guide, "
"llamafile–broadcasting on our AI Discord and the Mozilla Developer YouTube channel. The goal was to share transparently what we’re working on and what we hope to accomplish."
msgstr ""
"<a id=\"a1\"><b>Mozilla Innovation Week</b></a> : en décembre 2023, Mozilla a présenté les coulisses de certaines de ses initiatives autour de l’IA, y compris Solo, MemoryCache, AI Guide ou "
"llamafile. Ces vidéos sont diffusées sur notre serveur Discord dédié à l’IA et sur la chaîne YouTube des développeurs de Mozilla. L’objectif : partager de manière transparente nos travaux en cours "
"et nos objectifs."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>MemoryCache</b></a>: This Mozilla Innovation Project is an early exploration project that augments an on-device, personal model with local files saved from the browser to reflect a "
"more personalized and tailored experience through the lens of privacy and agency."
msgstr ""
"<a id=\"a1\"><b>MemoryCache</b></a> : ce projet innovant de Mozilla offre une solution qui permet d’enrichir un modèle personnel sur un appareil avec des fichiers enregistrés localement depuis le "
"navigateur. Résultat : une expérience plus personnalisée sans faire de sacrifice ni sur l’autonomie ni sur la vie privée."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid "Strengthening AI Regulations and Incentives"
msgstr "Renforcer les réglementations et les incitations en matière d’IA"

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>Joint Statement on AI Safety and Openness</b></a><b>:</b> Signed by over 1,800 scientists, policymakers, engineers, activists, entrepreneurs, educators and journalists, this open "
"letter calls on global lawmakers to embrace openness, transparency, and broad access to mitigate harms from AI systems."
msgstr ""
"<a id=\"a1\"><b>Joint Statement on AI Safety and Openness</b></a><b> :</b> signée par plus de 1 800 scientifiques, décideurs, ingénieurs, militants, entrepreneurs, enseignants et journalistes, cette"
" lettre ouverte appelle les législateurs du monde entier à adopter les principes d’ouverture, de transparence et d’accès pour atténuer les préjudices causés par les systèmes d’IA."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>C2PA Standard</b></a><b>:</b> Mozilla Ventures’ portfolio company <a id=\"a2\">Truepic</a> — a key member of the <a id=\"a3\">C2PA</a> — advocates for an open technical standard for "
"content verification, including for generative AI. The C2PA standard will allow publishers, creators and consumers to have the ability to trace the origin of AI-generated content."
msgstr ""
"<a id=\"a1\"><b>Norme C2PA</b></a><b> :</b> <a id=\"a2\">Truepic</a>, la société de gestion de portefeuille de Mozilla Ventures et un membre important du <a id=\"a3\">C2PA</a>, plaide en faveur "
"d’une norme technique ouverte pour la vérification des contenus, y compris pour ceux issus des IA génératives. La norme C2PA offrira aux éditeurs, aux créateurs et aux consommateurs la possibilité "
"de retracer l’origine des contenus générés par l’IA."

msgctxt "body.7632d812-7a94-4279-86df-41c8c5515287"
msgid ""
"<a id=\"a1\"><b>EU and US Advocacy Campaigns</b></a>: Mozilla <a id=\"a2\">engaged extensively</a> on the EU’s AI Act and with policymakers in the United States around <a id=\"a3\">AI risk "
"management</a> and <a id=\"a4\">accountability</a>."
msgstr ""
"<a id=\"a1\"><b>EU and US Advocacy Campaigns</b></a> : Mozilla s’est <a id=\"a2\">fortement impliqué</a> dans l’AI Act de l’UE et a travaillé avec les décideurs politiques aux États-Unis sur la <a "
"id=\"a3\">gestion des risques liés à l’IA</a> et les problématiques de <a id=\"a4\">responsabilisation</a>."

msgctxt "body.bd3ff6e5-def4-424a-96c7-e3856c898baa"
msgid ""
"Thank you to the following contributors: J. Bob Alotta, Ashley Boyd, Ian Carmichael, Moez Draief, Max Gahntz, Linda Griffin, Stephen Hood, Saoud Khalifah, Santiago Martorana, Mohamed Nanabhay, "
"Alondra Nelson, Kasia Odrozek, Becca Ricks, Victor Storchan, Udbhav Tiwari, Imo Udom, Suba Vasudevan, and Claire Woodcock."
msgstr ""
"Merci aux contributeurs suivants : J. Bob Alotta, Ashley Boyd, Ian Carmichael, Moez Draief, Max Gahntz, Linda Griffin, Stephen Hood, Saoud Khalifah, Santiago Martorana, Mohamed Nanabhay, Alondra "
"Nelson, Kasia Odrozek, Becca Ricks, Victor Storchan, Udbhav Tiwari, Imo Udom, Suba Vasudevan et Claire Woodcock."
